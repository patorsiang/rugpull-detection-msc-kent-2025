{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5522b31",
   "metadata": {},
   "source": [
    "# Baseline Model using Byte Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618ae76",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c98a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04893973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTETomek\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2e63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd().parents[2]\n",
    "DATA_PATH = os.path.join(PATH, 'data/processed/byte_freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77dea9b",
   "metadata": {},
   "source": [
    "## List Traditional ML model to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ab6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "models = {\n",
    "  # MultiOutputClassifier Wrappers\n",
    "  \"MultiOutputClassifier(LogisticRegression())\": MultiOutputClassifier(LogisticRegression()),\n",
    "  \"MultiOutputClassifier(DecisionTreeClassifier())\": MultiOutputClassifier(DecisionTreeClassifier()),\n",
    "  \"MultiOutputClassifier(RandomForestClassifier())\": MultiOutputClassifier(RandomForestClassifier()),\n",
    "  \"MultiOutputClassifier(AdaBoostClassifier())\": MultiOutputClassifier(AdaBoostClassifier()),\n",
    "  \"MultiOutputClassifier(ExtraTreesClassifier())\": MultiOutputClassifier(ExtraTreesClassifier()),\n",
    "  \"MultiOutputClassifier(XGBClassifier())\": MultiOutputClassifier(XGBClassifier()),\n",
    "  \"MultiOutputClassifier(LGBMClassifier())\": MultiOutputClassifier(LGBMClassifier()),\n",
    "  \"MultiOutputClassifier(SVC())\": MultiOutputClassifier(SVC()),\n",
    "  \"MultiOutputClassifier(GaussianNB())\": MultiOutputClassifier(GaussianNB()),\n",
    "  \"MultiOutputClassifier(KNeighborsClassifier())\": MultiOutputClassifier(KNeighborsClassifier()),\n",
    "  \"MultiOutputClassifier(SGDClassifier())\": MultiOutputClassifier(SGDClassifier()),\n",
    "  \"MultiOutputClassifier(MLPClassifier())\": MultiOutputClassifier(MLPClassifier()),\n",
    "\n",
    "  # OneVsRestClassifier Wrappers\n",
    "  \"OneVsRestClassifier(LogisticRegression())\": OneVsRestClassifier(LogisticRegression()),\n",
    "  \"OneVsRestClassifier(DecisionTreeClassifier())\": OneVsRestClassifier(DecisionTreeClassifier()),\n",
    "  \"OneVsRestClassifier(RandomForestClassifier())\": OneVsRestClassifier(RandomForestClassifier()),\n",
    "  \"OneVsRestClassifier(AdaBoostClassifier())\": OneVsRestClassifier(AdaBoostClassifier()),\n",
    "  \"OneVsRestClassifier(ExtraTreesClassifier())\": OneVsRestClassifier(ExtraTreesClassifier()),\n",
    "  \"OneVsRestClassifier(XGBClassifier())\": OneVsRestClassifier(XGBClassifier()),\n",
    "  \"OneVsRestClassifier(LGBMClassifier())\": OneVsRestClassifier(LGBMClassifier()),\n",
    "  \"OneVsRestClassifier(SVC())\": OneVsRestClassifier(SVC()),\n",
    "  \"OneVsRestClassifier(GaussianNB())\": OneVsRestClassifier(GaussianNB()),\n",
    "  \"OneVsRestClassifier(KNeighborsClassifier())\": OneVsRestClassifier(KNeighborsClassifier()),\n",
    "  \"OneVsRestClassifier(SGDClassifier())\": OneVsRestClassifier(SGDClassifier()),\n",
    "  \"OneVsRestClassifier(MLPClassifier())\": OneVsRestClassifier(MLPClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5732d05",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d0a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, 'dataset.csv')).set_index('address')\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'features.json'), \"r\") as f:\n",
    "    features = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'labels.json'), \"r\") as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4714201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "address",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mint",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "leak",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "limit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "60",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "80",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "52",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "04",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "36",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "61",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "00",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "db",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "57",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "35",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "01",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "90",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "63",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "16",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "06",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "de",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "03",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "09",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "70",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "18",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "72",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "02",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "67",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "85",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "42",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "96",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "68",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "66",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "84",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "82",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "48",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "71",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5b",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "95",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "41",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "05",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "62",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3e",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "f2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "15",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "21",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "56",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "51",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "81",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "83",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "91",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "19",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "92",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "73",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ea",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "07",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "77",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ef",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "97",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "54",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "89",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "29",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ab",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "0f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "74",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "22",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "99",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "47",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "37",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "4d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "58",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "df",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "33",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "55",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "08",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ce",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "87",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "46",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "86",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "69",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "b0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "aa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "28",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5a",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "93",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "94",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "88",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "59",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "98",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "45",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "17",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "43",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fe",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "32",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "44",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "39",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "53",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "49",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "da",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "af",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "64",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "65",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "79",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2a",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "78",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "c1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ca",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "76",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "75",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "a8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ac",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ba",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ee",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "38",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4b",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3f",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "be",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7e",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "27",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9e",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1c7e862e-55d6-4209-a58a-9ec9df2697a2",
       "rows": [
        [
         "0x93023f1d3525e273f291b6f76d2f5027a39bf302",
         "1",
         "0",
         "1",
         "410",
         "84",
         "55.0",
         "134.0",
         "73.0",
         "15",
         "11.0",
         "289.0",
         "70.0",
         "0.0",
         "70",
         "8.0",
         "1.0",
         "201.0",
         "105.0",
         "46.0",
         "14.0",
         "50.0",
         "8.0",
         "21",
         "2.0",
         "75.0",
         "33.0",
         "7.0",
         "14.0",
         "3.0",
         "5.0",
         "5.0",
         "8.0",
         "4.0",
         "37.0",
         "8.0",
         "0.0",
         "6.0",
         "2.0",
         "38.0",
         "39.0",
         "3.0",
         "2.0",
         "18.0",
         "4.0",
         "28.0",
         "6.0",
         "2.0",
         "16.0",
         "16.0",
         "3.0",
         "9.0",
         "34.0",
         "4.0",
         "31.0",
         "104.0",
         "3.0",
         "6.0",
         "80.0",
         "8.0",
         "0.0",
         "5.0",
         "3.0",
         "3.0",
         "168",
         "9.0",
         "4.0",
         "4.0",
         "5.0",
         "2.0",
         "13.0",
         "4.0",
         "2.0",
         "4.0",
         "4.0",
         "0.0",
         "4.0",
         "24.0",
         "2.0",
         "5",
         "9.0",
         "4.0",
         "1.0",
         "35",
         "1.0",
         "7.0",
         "3.0",
         "138.0",
         "38.0",
         "132.0",
         "105.0",
         "39.0",
         "48.0",
         "0.0",
         "7.0",
         "5.0",
         "8.0",
         "23.0",
         "2",
         "29",
         "1.0",
         "3.0",
         "5.0",
         "19.0",
         "1.0",
         "6.0",
         "3.0",
         "0.0",
         "2.0",
         "6.0",
         "10.0",
         "8.0",
         "2.0",
         "6.0",
         "0.0",
         "1.0",
         "30.0",
         "2.0",
         "19.0",
         "2.0",
         "2.0",
         "1.0",
         "25.0",
         "26.0",
         "6.0",
         "1.0",
         "1.0",
         "1.0",
         "2.0",
         "4",
         "4.0",
         "10.0",
         "6.0",
         "4.0",
         "3.0",
         "1.0",
         "6.0",
         "8.0",
         "11.0",
         "12.0",
         "22.0",
         "1.0",
         "2.0",
         "1.0",
         "6.0",
         "2.0",
         "3.0",
         "5.0",
         "1.0",
         "1.0",
         "2.0",
         "1.0",
         "5.0",
         "7.0",
         "14.0",
         "16.0",
         "8.0",
         "15.0",
         "8.0",
         "1.0",
         "0.0",
         "4.0",
         "74.0",
         "6.0",
         "14.0",
         "3.0",
         "3.0",
         "3.0",
         "6.0",
         "5.0",
         "5.0",
         "6.0",
         "4.0",
         "6",
         "12.0",
         "7.0",
         "6.0",
         "2.0",
         "1.0",
         "17.0",
         "3.0",
         "0.0",
         "2.0",
         "1.0",
         "10.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "6.0",
         "12.0",
         "13.0",
         "1.0",
         "0.0",
         "2.0",
         "11.0",
         "3.0",
         "16.0",
         "1.0",
         "9.0",
         "1.0",
         "2.0",
         "9.0",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "1.0",
         "1.0",
         "2.0",
         "29.0",
         "40.0",
         "59.0",
         "11.0",
         "1.0",
         "1.0",
         "0.0",
         "4.0",
         "3.0",
         "2.0",
         "0.0",
         "2.0",
         "8.0",
         "3.0",
         "0.0",
         "16.0",
         "1.0",
         "3.0",
         "4.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "2.0",
         "20.0",
         "7.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "5.0",
         "0.0",
         "0.0",
         "5.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "8.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "2.0",
         "0.0",
         "2.0",
         "1.0"
        ],
        [
         "0x2753dce37a7edb052a77832039bcc9aa49ad8b25",
         "0",
         "0",
         "1",
         "668",
         "123",
         "79.0",
         "188.0",
         "85.0",
         "25",
         "22.0",
         "420.0",
         "118.0",
         "4.0",
         "103",
         "8.0",
         "11.0",
         "286.0",
         "161.0",
         "88.0",
         "24.0",
         "119.0",
         "46.0",
         "30",
         "2.0",
         "107.0",
         "61.0",
         "15.0",
         "20.0",
         "4.0",
         "7.0",
         "4.0",
         "12.0",
         "18.0",
         "17.0",
         "10.0",
         "3.0",
         "5.0",
         "2.0",
         "45.0",
         "75.0",
         "4.0",
         "4.0",
         "32.0",
         "6.0",
         "31.0",
         "4.0",
         "1.0",
         "31.0",
         "13.0",
         "3.0",
         "12.0",
         "51.0",
         "5.0",
         "50.0",
         "134.0",
         "5.0",
         "8.0",
         "99.0",
         "1.0",
         "4.0",
         "4.0",
         "7.0",
         "4.0",
         "228",
         "3.0",
         "6.0",
         "19.0",
         "5.0",
         "2.0",
         "19.0",
         "8.0",
         "3.0",
         "3.0",
         "6.0",
         "1.0",
         "1.0",
         "40.0",
         "2.0",
         "2",
         "8.0",
         "3.0",
         "6.0",
         "68",
         "2.0",
         "11.0",
         "2.0",
         "189.0",
         "58.0",
         "175.0",
         "149.0",
         "52.0",
         "61.0",
         "6.0",
         "16.0",
         "8.0",
         "26.0",
         "30.0",
         "2",
         "46",
         "1.0",
         "5.0",
         "5.0",
         "17.0",
         "2.0",
         "17.0",
         "5.0",
         "4.0",
         "5.0",
         "10.0",
         "10.0",
         "3.0",
         "5.0",
         "5.0",
         "1.0",
         "3.0",
         "46.0",
         "1.0",
         "14.0",
         "7.0",
         "2.0",
         "2.0",
         "13.0",
         "35.0",
         "5.0",
         "2.0",
         "5.0",
         "7.0",
         "2.0",
         "7",
         "6.0",
         "21.0",
         "9.0",
         "9.0",
         "8.0",
         "3.0",
         "3.0",
         "26.0",
         "33.0",
         "12.0",
         "32.0",
         "4.0",
         "6.0",
         "4.0",
         "8.0",
         "5.0",
         "2.0",
         "2.0",
         "5.0",
         "11.0",
         "1.0",
         "5.0",
         "7.0",
         "8.0",
         "23.0",
         "3.0",
         "12.0",
         "29.0",
         "13.0",
         "2.0",
         "1.0",
         "6.0",
         "142.0",
         "3.0",
         "47.0",
         "5.0",
         "9.0",
         "6.0",
         "2.0",
         "7.0",
         "2.0",
         "4.0",
         "8.0",
         "5",
         "17.0",
         "8.0",
         "8.0",
         "1.0",
         "6.0",
         "33.0",
         "5.0",
         "8.0",
         "8.0",
         "2.0",
         "11.0",
         "1.0",
         "0.0",
         "8.0",
         "2.0",
         "3.0",
         "37.0",
         "21.0",
         "15.0",
         "5.0",
         "4.0",
         "1.0",
         "14.0",
         "0.0",
         "20.0",
         "3.0",
         "7.0",
         "10.0",
         "8.0",
         "7.0",
         "9.0",
         "14.0",
         "12.0",
         "7.0",
         "3.0",
         "2.0",
         "3.0",
         "39.0",
         "49.0",
         "69.0",
         "12.0",
         "1.0",
         "9.0",
         "1.0",
         "6.0",
         "1.0",
         "2.0",
         "3.0",
         "5.0",
         "6.0",
         "1.0",
         "1.0",
         "26.0",
         "6.0",
         "6.0",
         "5.0",
         "2.0",
         "9.0",
         "5.0",
         "1.0",
         "4.0",
         "37.0",
         "8.0",
         "3.0",
         "2.0",
         "5.0",
         "3.0",
         "2.0",
         "2.0",
         "12.0",
         "2.0",
         "5.0",
         "2.0",
         "9.0",
         "3.0",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "2.0",
         "3.0",
         "2.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "0x94b7d24552933f50a5a5705c446528806dcea381",
         "0",
         "0",
         "0",
         "17",
         "6",
         "1.0",
         "3.0",
         "0.0",
         "2",
         "0.0",
         "0.0",
         "41.0",
         "0.0",
         "2",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "20.0",
         "1.0",
         "2.0",
         "1",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "1.0",
         "0.0",
         "0.0",
         "2",
         "0.0",
         "0.0",
         "1.0",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "2",
         "3",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "2.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "2.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093",
         "0",
         "0",
         "0",
         "505",
         "163",
         "100.0",
         "132.0",
         "48.0",
         "12",
         "17.0",
         "489.0",
         "613.0",
         "9.0",
         "98",
         "20.0",
         "1.0",
         "183.0",
         "244.0",
         "41.0",
         "1867.0",
         "110.0",
         "13.0",
         "39",
         "5.0",
         "87.0",
         "47.0",
         "3.0",
         "15.0",
         "3.0",
         "8.0",
         "10.0",
         "10.0",
         "29.0",
         "5.0",
         "23.0",
         "0.0",
         "6.0",
         "3.0",
         "18.0",
         "56.0",
         "5.0",
         "6.0",
         "4.0",
         "4.0",
         "24.0",
         "13.0",
         "1.0",
         "7.0",
         "7.0",
         "2.0",
         "5.0",
         "53.0",
         "0.0",
         "7.0",
         "102.0",
         "3.0",
         "4.0",
         "324.0",
         "12.0",
         "1.0",
         "6.0",
         "0.0",
         "3.0",
         "375",
         "13.0",
         "2.0",
         "8.0",
         "18.0",
         "6.0",
         "22.0",
         "6.0",
         "4.0",
         "1.0",
         "9.0",
         "11.0",
         "0.0",
         "6.0",
         "3.0",
         "8",
         "9.0",
         "0.0",
         "30.0",
         "70",
         "1.0",
         "10.0",
         "29.0",
         "280.0",
         "82.0",
         "176.0",
         "178.0",
         "53.0",
         "160.0",
         "27.0",
         "52.0",
         "22.0",
         "30.0",
         "57.0",
         "27",
         "137",
         "3.0",
         "7.0",
         "12.0",
         "18.0",
         "1.0",
         "7.0",
         "4.0",
         "4.0",
         "1.0",
         "31.0",
         "15.0",
         "6.0",
         "1.0",
         "14.0",
         "14.0",
         "4.0",
         "25.0",
         "2.0",
         "12.0",
         "3.0",
         "3.0",
         "2.0",
         "11.0",
         "11.0",
         "12.0",
         "7.0",
         "19.0",
         "0.0",
         "3.0",
         "5",
         "9.0",
         "15.0",
         "6.0",
         "6.0",
         "3.0",
         "4.0",
         "14.0",
         "25.0",
         "16.0",
         "16.0",
         "52.0",
         "5.0",
         "5.0",
         "5.0",
         "8.0",
         "28.0",
         "2.0",
         "6.0",
         "11.0",
         "11.0",
         "7.0",
         "3.0",
         "10.0",
         "6.0",
         "26.0",
         "0.0",
         "12.0",
         "1.0",
         "23.0",
         "1.0",
         "4.0",
         "13.0",
         "38.0",
         "6.0",
         "19.0",
         "7.0",
         "4.0",
         "7.0",
         "4.0",
         "17.0",
         "5.0",
         "10.0",
         "12.0",
         "10",
         "12.0",
         "4.0",
         "4.0",
         "5.0",
         "16.0",
         "0.0",
         "1.0",
         "3.0",
         "7.0",
         "1.0",
         "9.0",
         "4.0",
         "8.0",
         "0.0",
         "1.0",
         "4.0",
         "5.0",
         "7.0",
         "3.0",
         "21.0",
         "2.0",
         "2.0",
         "3.0",
         "1.0",
         "2.0",
         "8.0",
         "6.0",
         "13.0",
         "8.0",
         "9.0",
         "26.0",
         "4.0",
         "22.0",
         "2.0",
         "3.0",
         "2.0",
         "14.0",
         "17.0",
         "11.0",
         "29.0",
         "3.0",
         "15.0",
         "38.0",
         "10.0",
         "6.0",
         "3.0",
         "3.0",
         "8.0",
         "2.0",
         "9.0",
         "5.0",
         "6.0",
         "8.0",
         "13.0",
         "2.0",
         "11.0",
         "1.0",
         "2.0",
         "9.0",
         "0.0",
         "3.0",
         "12.0",
         "7.0",
         "5.0",
         "32.0",
         "13.0",
         "0.0",
         "6.0",
         "2.0",
         "4.0",
         "3.0",
         "2.0",
         "1.0",
         "15.0",
         "3.0",
         "8.0",
         "2.0",
         "13.0",
         "2.0",
         "4.0",
         "4.0",
         "2.0",
         "4.0",
         "3.0",
         "1.0",
         "1.0"
        ],
        [
         "0x10f6f2b97f3ab29583d9d38babf2994df7220c21",
         "1",
         "0",
         "1",
         "735",
         "213",
         "122.0",
         "159.0",
         "81.0",
         "19",
         "54.0",
         "721.0",
         "1046.0",
         "6.0",
         "118",
         "10.0",
         "7.0",
         "311.0",
         "415.0",
         "53.0",
         "2315.0",
         "154.0",
         "19.0",
         "54",
         "11.0",
         "113.0",
         "44.0",
         "7.0",
         "11.0",
         "9.0",
         "9.0",
         "12.0",
         "8.0",
         "14.0",
         "7.0",
         "13.0",
         "10.0",
         "34.0",
         "3.0",
         "28.0",
         "60.0",
         "4.0",
         "6.0",
         "9.0",
         "13.0",
         "45.0",
         "6.0",
         "7.0",
         "12.0",
         "11.0",
         "9.0",
         "12.0",
         "58.0",
         "11.0",
         "12.0",
         "180.0",
         "7.0",
         "15.0",
         "515.0",
         "7.0",
         "3.0",
         "6.0",
         "11.0",
         "1.0",
         "537",
         "13.0",
         "5.0",
         "10.0",
         "3.0",
         "8.0",
         "34.0",
         "6.0",
         "7.0",
         "1.0",
         "5.0",
         "32.0",
         "2.0",
         "12.0",
         "9.0",
         "5",
         "8.0",
         "1.0",
         "25.0",
         "114",
         "4.0",
         "13.0",
         "62.0",
         "416.0",
         "106.0",
         "255.0",
         "258.0",
         "104.0",
         "214.0",
         "12.0",
         "20.0",
         "39.0",
         "18.0",
         "73.0",
         "22",
         "135",
         "3.0",
         "4.0",
         "7.0",
         "17.0",
         "1.0",
         "15.0",
         "4.0",
         "2.0",
         "4.0",
         "6.0",
         "5.0",
         "9.0",
         "2.0",
         "7.0",
         "21.0",
         "5.0",
         "53.0",
         "5.0",
         "6.0",
         "13.0",
         "1.0",
         "3.0",
         "3.0",
         "18.0",
         "23.0",
         "3.0",
         "25.0",
         "2.0",
         "2.0",
         "11",
         "10.0",
         "18.0",
         "4.0",
         "7.0",
         "3.0",
         "8.0",
         "1.0",
         "22.0",
         "5.0",
         "16.0",
         "49.0",
         "2.0",
         "6.0",
         "2.0",
         "2.0",
         "10.0",
         "5.0",
         "4.0",
         "6.0",
         "9.0",
         "14.0",
         "3.0",
         "37.0",
         "9.0",
         "46.0",
         "8.0",
         "14.0",
         "2.0",
         "30.0",
         "13.0",
         "2.0",
         "11.0",
         "27.0",
         "13.0",
         "12.0",
         "6.0",
         "5.0",
         "8.0",
         "27.0",
         "9.0",
         "9.0",
         "6.0",
         "30.0",
         "22",
         "20.0",
         "6.0",
         "13.0",
         "2.0",
         "12.0",
         "8.0",
         "8.0",
         "5.0",
         "12.0",
         "3.0",
         "16.0",
         "22.0",
         "1.0",
         "2.0",
         "7.0",
         "3.0",
         "26.0",
         "9.0",
         "9.0",
         "5.0",
         "3.0",
         "5.0",
         "7.0",
         "4.0",
         "18.0",
         "3.0",
         "11.0",
         "3.0",
         "3.0",
         "12.0",
         "3.0",
         "9.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "23.0",
         "31.0",
         "41.0",
         "10.0",
         "3.0",
         "11.0",
         "2.0",
         "14.0",
         "0.0",
         "3.0",
         "0.0",
         "23.0",
         "13.0",
         "28.0",
         "4.0",
         "44.0",
         "2.0",
         "3.0",
         "2.0",
         "0.0",
         "3.0",
         "2.0",
         "2.0",
         "26.0",
         "18.0",
         "8.0",
         "3.0",
         "8.0",
         "4.0",
         "1.0",
         "1.0",
         "5.0",
         "20.0",
         "7.0",
         "8.0",
         "3.0",
         "0.0",
         "6.0",
         "5.0",
         "3.0",
         "0.0",
         "18.0",
         "2.0",
         "11.0",
         "3.0",
         "2.0",
         "0.0",
         "19.0",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 259,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mint</th>\n",
       "      <th>leak</th>\n",
       "      <th>limit</th>\n",
       "      <th>60</th>\n",
       "      <th>80</th>\n",
       "      <th>40</th>\n",
       "      <th>52</th>\n",
       "      <th>04</th>\n",
       "      <th>36</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>f6</th>\n",
       "      <th>3f</th>\n",
       "      <th>d4</th>\n",
       "      <th>e7</th>\n",
       "      <th>be</th>\n",
       "      <th>f0</th>\n",
       "      <th>e4</th>\n",
       "      <th>7e</th>\n",
       "      <th>27</th>\n",
       "      <th>9e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x93023f1d3525e273f291b6f76d2f5027a39bf302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>84</td>\n",
       "      <td>55.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2753dce37a7edb052a77832039bcc9aa49ad8b25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>668</td>\n",
       "      <td>123</td>\n",
       "      <td>79.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>25</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x94b7d24552933f50a5a5705c446528806dcea381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>163</td>\n",
       "      <td>100.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x10f6f2b97f3ab29583d9d38babf2994df7220c21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>735</td>\n",
       "      <td>213</td>\n",
       "      <td>122.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mint  leak  limit   60   80  \\\n",
       "address                                                                   \n",
       "0x93023f1d3525e273f291b6f76d2f5027a39bf302     1     0      1  410   84   \n",
       "0x2753dce37a7edb052a77832039bcc9aa49ad8b25     0     0      1  668  123   \n",
       "0x94b7d24552933f50a5a5705c446528806dcea381     0     0      0   17    6   \n",
       "0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093     0     0      0  505  163   \n",
       "0x10f6f2b97f3ab29583d9d38babf2994df7220c21     1     0      1  735  213   \n",
       "\n",
       "                                               40     52    04  36    10  ...  \\\n",
       "address                                                                   ...   \n",
       "0x93023f1d3525e273f291b6f76d2f5027a39bf302   55.0  134.0  73.0  15  11.0  ...   \n",
       "0x2753dce37a7edb052a77832039bcc9aa49ad8b25   79.0  188.0  85.0  25  22.0  ...   \n",
       "0x94b7d24552933f50a5a5705c446528806dcea381    1.0    3.0   0.0   2   0.0  ...   \n",
       "0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093  100.0  132.0  48.0  12  17.0  ...   \n",
       "0x10f6f2b97f3ab29583d9d38babf2994df7220c21  122.0  159.0  81.0  19  54.0  ...   \n",
       "\n",
       "                                             f6    3f    d4   e7    be   f0  \\\n",
       "address                                                                       \n",
       "0x93023f1d3525e273f291b6f76d2f5027a39bf302  0.0   8.0   0.0  1.0   0.0  2.0   \n",
       "0x2753dce37a7edb052a77832039bcc9aa49ad8b25  4.0   3.0   2.0  2.0   2.0  3.0   \n",
       "0x94b7d24552933f50a5a5705c446528806dcea381  0.0   0.0   0.0  0.0   0.0  0.0   \n",
       "0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093  2.0  13.0   2.0  4.0   4.0  2.0   \n",
       "0x10f6f2b97f3ab29583d9d38babf2994df7220c21  3.0   0.0  18.0  2.0  11.0  3.0   \n",
       "\n",
       "                                             e4   7e    27   9e  \n",
       "address                                                          \n",
       "0x93023f1d3525e273f291b6f76d2f5027a39bf302  2.0  0.0   2.0  1.0  \n",
       "0x2753dce37a7edb052a77832039bcc9aa49ad8b25  2.0  2.0   1.0  0.0  \n",
       "0x94b7d24552933f50a5a5705c446528806dcea381  0.0  0.0   0.0  0.0  \n",
       "0xe0b9d4146aad6936cbfcbe4dae47e34aab96b093  4.0  3.0   1.0  1.0  \n",
       "0x10f6f2b97f3ab29583d9d38babf2994df7220c21  2.0  0.0  19.0  4.0  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc02200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['60', '80', '40', '52', '04']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af91f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mint', 'leak', 'limit']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196a65d",
   "metadata": {},
   "source": [
    "## Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86f3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7ea05",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e9fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6a512",
   "metadata": {},
   "source": [
    "### Apply SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce7084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resampled shapes: (234, 256) (234, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_resampled = pd.DataFrame()\n",
    "y_train_resampled = pd.DataFrame()\n",
    "\n",
    "for i, label in enumerate(y_train.columns):\n",
    "    smt = SMOTETomek(random_state=42)\n",
    "    X_res, y_res = smt.fit_resample(X_train, y_train[label])\n",
    "\n",
    "    df_X_res = pd.DataFrame(X_res)\n",
    "    df_y_res = pd.DataFrame(y_res, columns=[label])\n",
    "\n",
    "    # Concatenate features and label to one DF\n",
    "    df_res = pd.concat([df_X_res, df_y_res], axis=1)\n",
    "\n",
    "    # Append and fill missing values with 0 (i.e., assume the label wasn't assigned)\n",
    "    X_train_resampled = pd.concat([X_train_resampled, df_res], axis=0)\n",
    "\n",
    "# After all labels processed, separate X and y again\n",
    "X_train_resampled = X_train_resampled.drop_duplicates().reset_index(drop=True)\n",
    "y_train_resampled = X_train_resampled[y_train.columns].fillna(0).astype(int)\n",
    "X_train_resampled = X_train_resampled.drop(columns=y_train.columns)\n",
    "\n",
    "print(\"✅ Resampled shapes:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "\n",
    "label_counts = y_train_resampled[[\"mint\", \"leak\", \"limit\"]].sum()\n",
    "\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"Set2\")\n",
    "plt.title(\"Multi-label Distribution per Scam Type\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of Addresses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363d121",
   "metadata": {},
   "source": [
    "## Run all models and collect reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd4e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_all_ml(X_train, y_train, X_test):\n",
    "    report_list = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Generate classification report (as dict)\n",
    "        report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        # Average scores across all labels (macro average)\n",
    "        avg_scores = report_dict[\"macro avg\"]\n",
    "\n",
    "        report_list.append({\n",
    "            \"Model\": name,\n",
    "            \"Precision\": avg_scores[\"precision\"],\n",
    "            \"Recall\": avg_scores[\"recall\"],\n",
    "            \"F1-score\": avg_scores[\"f1-score\"]\n",
    "        })\n",
    "\n",
    "    df_report = pd.DataFrame(report_list)\n",
    "    df_report = df_report.sort_values(\"F1-score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5e9be",
   "metadata": {},
   "source": [
    "## Show report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34c5c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_multilabel_confusion_matrix(y_test, y_pred):\n",
    "    # Ensure y_test and y_pred are binary numeric arrays\n",
    "    y_test_array = np.array(y_test, dtype=int)\n",
    "    y_pred_array = np.array(y_pred, dtype=int)\n",
    "\n",
    "    # Generate multi-label confusion matrix again using numeric arrays\n",
    "    conf_matrices_fixed = multilabel_confusion_matrix(y_test_array, y_pred_array)\n",
    "\n",
    "    # Plot each confusion matrix again to confirm it's fixed\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    for i, (cm, label) in enumerate(zip(conf_matrices_fixed, y.columns)):\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "        axes[i].set_title(f'Confusion Matrix: {label}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bf4c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 39, number of negative: 195\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 47, number of negative: 187\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200855 -> initscore=-1.380961\n",
      "[LightGBM] [Info] Start training from score -1.380961\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 31, number of negative: 203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.132479 -> initscore=-1.879219\n",
      "[LightGBM] [Info] Start training from score -1.879219\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 39, number of negative: 195\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 47, number of negative: 187\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200855 -> initscore=-1.380961\n",
      "[LightGBM] [Info] Start training from score -1.380961\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 31, number of negative: 203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9703\n",
      "[LightGBM] [Info] Number of data points in the train set: 234, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.132479 -> initscore=-1.879219\n",
      "[LightGBM] [Info] Start training from score -1.879219\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "80416dd2-baec-4168-bdae-e392add6e8a8",
       "rows": [
        [
         "0",
         "OneVsRestClassifier(KNeighborsClassifier())",
         "0.8333333333333334",
         "0.3518518518518518",
         "0.4712121212121212"
        ],
        [
         "1",
         "MultiOutputClassifier(KNeighborsClassifier())",
         "0.8333333333333334",
         "0.3518518518518518",
         "0.4712121212121212"
        ],
        [
         "2",
         "MultiOutputClassifier(DecisionTreeClassifier())",
         "0.5",
         "0.27777777777777773",
         "0.35000000000000003"
        ],
        [
         "3",
         "OneVsRestClassifier(GaussianNB())",
         "0.38888888888888884",
         "0.25925925925925924",
         "0.30501089324618735"
        ],
        [
         "4",
         "MultiOutputClassifier(GaussianNB())",
         "0.38888888888888884",
         "0.25925925925925924",
         "0.30501089324618735"
        ],
        [
         "5",
         "OneVsRestClassifier(MLPClassifier())",
         "0.5",
         "0.2222222222222222",
         "0.3"
        ],
        [
         "6",
         "OneVsRestClassifier(XGBClassifier())",
         "0.3333333333333333",
         "0.2222222222222222",
         "0.26666666666666666"
        ],
        [
         "7",
         "MultiOutputClassifier(XGBClassifier())",
         "0.3333333333333333",
         "0.2222222222222222",
         "0.26666666666666666"
        ],
        [
         "8",
         "MultiOutputClassifier(SGDClassifier())",
         "0.16666666666666666",
         "0.2222222222222222",
         "0.19047619047619047"
        ],
        [
         "9",
         "OneVsRestClassifier(SVC())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "10",
         "OneVsRestClassifier(LGBMClassifier())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "11",
         "MultiOutputClassifier(SVC())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "12",
         "MultiOutputClassifier(AdaBoostClassifier())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "13",
         "MultiOutputClassifier(LGBMClassifier())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "14",
         "OneVsRestClassifier(AdaBoostClassifier())",
         "0.3333333333333333",
         "0.1111111111111111",
         "0.16666666666666666"
        ],
        [
         "15",
         "OneVsRestClassifier(SGDClassifier())",
         "0.16666666666666666",
         "0.1111111111111111",
         "0.13333333333333333"
        ],
        [
         "16",
         "MultiOutputClassifier(MLPClassifier())",
         "0.3333333333333333",
         "0.07407407407407407",
         "0.12121212121212122"
        ],
        [
         "17",
         "OneVsRestClassifier(DecisionTreeClassifier())",
         "0.16666666666666666",
         "0.05555555555555555",
         "0.08333333333333333"
        ],
        [
         "18",
         "MultiOutputClassifier(LogisticRegression())",
         "0.3333333333333333",
         "0.037037037037037035",
         "0.06666666666666667"
        ],
        [
         "19",
         "OneVsRestClassifier(LogisticRegression())",
         "0.3333333333333333",
         "0.037037037037037035",
         "0.06666666666666667"
        ],
        [
         "20",
         "MultiOutputClassifier(ExtraTreesClassifier())",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "MultiOutputClassifier(RandomForestClassifier())",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "OneVsRestClassifier(RandomForestClassifier())",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "OneVsRestClassifier(ExtraTreesClassifier())",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 24
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneVsRestClassifier(KNeighborsClassifier())</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.471212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultiOutputClassifier(KNeighborsClassifier())</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.471212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiOutputClassifier(DecisionTreeClassifier())</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneVsRestClassifier(GaussianNB())</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.305011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultiOutputClassifier(GaussianNB())</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.305011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OneVsRestClassifier(MLPClassifier())</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OneVsRestClassifier(XGBClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultiOutputClassifier(XGBClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultiOutputClassifier(SGDClassifier())</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OneVsRestClassifier(SVC())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OneVsRestClassifier(LGBMClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultiOutputClassifier(SVC())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiOutputClassifier(AdaBoostClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiOutputClassifier(LGBMClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OneVsRestClassifier(AdaBoostClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OneVsRestClassifier(SGDClassifier())</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MultiOutputClassifier(MLPClassifier())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OneVsRestClassifier(DecisionTreeClassifier())</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultiOutputClassifier(LogisticRegression())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OneVsRestClassifier(LogisticRegression())</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MultiOutputClassifier(ExtraTreesClassifier())</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultiOutputClassifier(RandomForestClassifier())</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OneVsRestClassifier(RandomForestClassifier())</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OneVsRestClassifier(ExtraTreesClassifier())</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Model  Precision    Recall  \\\n",
       "0       OneVsRestClassifier(KNeighborsClassifier())   0.833333  0.351852   \n",
       "1     MultiOutputClassifier(KNeighborsClassifier())   0.833333  0.351852   \n",
       "2   MultiOutputClassifier(DecisionTreeClassifier())   0.500000  0.277778   \n",
       "3                 OneVsRestClassifier(GaussianNB())   0.388889  0.259259   \n",
       "4               MultiOutputClassifier(GaussianNB())   0.388889  0.259259   \n",
       "5              OneVsRestClassifier(MLPClassifier())   0.500000  0.222222   \n",
       "6              OneVsRestClassifier(XGBClassifier())   0.333333  0.222222   \n",
       "7            MultiOutputClassifier(XGBClassifier())   0.333333  0.222222   \n",
       "8            MultiOutputClassifier(SGDClassifier())   0.166667  0.222222   \n",
       "9                        OneVsRestClassifier(SVC())   0.333333  0.111111   \n",
       "10            OneVsRestClassifier(LGBMClassifier())   0.333333  0.111111   \n",
       "11                     MultiOutputClassifier(SVC())   0.333333  0.111111   \n",
       "12      MultiOutputClassifier(AdaBoostClassifier())   0.333333  0.111111   \n",
       "13          MultiOutputClassifier(LGBMClassifier())   0.333333  0.111111   \n",
       "14        OneVsRestClassifier(AdaBoostClassifier())   0.333333  0.111111   \n",
       "15             OneVsRestClassifier(SGDClassifier())   0.166667  0.111111   \n",
       "16           MultiOutputClassifier(MLPClassifier())   0.333333  0.074074   \n",
       "17    OneVsRestClassifier(DecisionTreeClassifier())   0.166667  0.055556   \n",
       "18      MultiOutputClassifier(LogisticRegression())   0.333333  0.037037   \n",
       "19        OneVsRestClassifier(LogisticRegression())   0.333333  0.037037   \n",
       "20    MultiOutputClassifier(ExtraTreesClassifier())   0.000000  0.000000   \n",
       "21  MultiOutputClassifier(RandomForestClassifier())   0.000000  0.000000   \n",
       "22    OneVsRestClassifier(RandomForestClassifier())   0.000000  0.000000   \n",
       "23      OneVsRestClassifier(ExtraTreesClassifier())   0.000000  0.000000   \n",
       "\n",
       "    F1-score  \n",
       "0   0.471212  \n",
       "1   0.471212  \n",
       "2   0.350000  \n",
       "3   0.305011  \n",
       "4   0.305011  \n",
       "5   0.300000  \n",
       "6   0.266667  \n",
       "7   0.266667  \n",
       "8   0.190476  \n",
       "9   0.166667  \n",
       "10  0.166667  \n",
       "11  0.166667  \n",
       "12  0.166667  \n",
       "13  0.166667  \n",
       "14  0.166667  \n",
       "15  0.133333  \n",
       "16  0.121212  \n",
       "17  0.083333  \n",
       "18  0.066667  \n",
       "19  0.066667  \n",
       "20  0.000000  \n",
       "21  0.000000  \n",
       "22  0.000000  \n",
       "23  0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_smote = get_report_all_ml(X_train_resampled, y_train_resampled, X_test)\n",
    "df_report_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50af35fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = models[df_report_smote['Model'][0]]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "display_multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85a888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14, number of negative: 41\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254545 -> initscore=-1.074515\n",
      "[LightGBM] [Info] Start training from score -1.074515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6, number of negative: 49\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109091 -> initscore=-2.100061\n",
      "[LightGBM] [Info] Start training from score -2.100061\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 21, number of negative: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381818 -> initscore=-0.481838\n",
      "[LightGBM] [Info] Start training from score -0.481838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 14, number of negative: 41\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254545 -> initscore=-1.074515\n",
      "[LightGBM] [Info] Start training from score -1.074515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6, number of negative: 49\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109091 -> initscore=-2.100061\n",
      "[LightGBM] [Info] Start training from score -2.100061\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 21, number of negative: 34\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2947\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 253\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381818 -> initscore=-0.481838\n",
      "[LightGBM] [Info] Start training from score -0.481838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b19c7733-e319-42e2-af2a-05cac47bac87",
       "rows": [
        [
         "0",
         "OneVsRestClassifier(AdaBoostClassifier())",
         "0.9523809523809524",
         "0.611111111111111",
         "0.7388888888888889"
        ],
        [
         "1",
         "MultiOutputClassifier(GaussianNB())",
         "0.7685185185185185",
         "0.5740740740740741",
         "0.6518518518518518"
        ],
        [
         "2",
         "OneVsRestClassifier(GaussianNB())",
         "0.7685185185185185",
         "0.5740740740740741",
         "0.6518518518518518"
        ],
        [
         "3",
         "MultiOutputClassifier(XGBClassifier())",
         "0.9333333333333332",
         "0.4259259259259259",
         "0.5793650793650793"
        ],
        [
         "4",
         "OneVsRestClassifier(XGBClassifier())",
         "0.9333333333333332",
         "0.4259259259259259",
         "0.5793650793650793"
        ],
        [
         "5",
         "MultiOutputClassifier(LGBMClassifier())",
         "0.9333333333333332",
         "0.4259259259259259",
         "0.5523809523809524"
        ],
        [
         "6",
         "OneVsRestClassifier(LGBMClassifier())",
         "0.9333333333333332",
         "0.4259259259259259",
         "0.5523809523809524"
        ],
        [
         "7",
         "OneVsRestClassifier(MLPClassifier())",
         "0.6111111111111112",
         "0.40740740740740744",
         "0.4814814814814814"
        ],
        [
         "8",
         "MultiOutputClassifier(AdaBoostClassifier())",
         "0.6190476190476191",
         "0.38888888888888884",
         "0.47222222222222215"
        ],
        [
         "9",
         "MultiOutputClassifier(SGDClassifier())",
         "0.38095238095238093",
         "0.5555555555555555",
         "0.4513457556935818"
        ],
        [
         "10",
         "OneVsRestClassifier(KNeighborsClassifier())",
         "0.48333333333333334",
         "0.4259259259259259",
         "0.4456140350877193"
        ],
        [
         "11",
         "MultiOutputClassifier(KNeighborsClassifier())",
         "0.48333333333333334",
         "0.4259259259259259",
         "0.4456140350877193"
        ],
        [
         "12",
         "MultiOutputClassifier(MLPClassifier())",
         "0.5555555555555555",
         "0.2962962962962963",
         "0.37777777777777777"
        ],
        [
         "13",
         "MultiOutputClassifier(LogisticRegression())",
         "0.4047619047619048",
         "0.2962962962962963",
         "0.3416666666666666"
        ],
        [
         "14",
         "OneVsRestClassifier(LogisticRegression())",
         "0.4047619047619048",
         "0.2962962962962963",
         "0.3416666666666666"
        ],
        [
         "15",
         "MultiOutputClassifier(SVC())",
         "0.6666666666666666",
         "0.20370370370370372",
         "0.2888888888888889"
        ],
        [
         "16",
         "OneVsRestClassifier(SVC())",
         "0.6666666666666666",
         "0.20370370370370372",
         "0.2888888888888889"
        ],
        [
         "17",
         "MultiOutputClassifier(ExtraTreesClassifier())",
         "0.5555555555555555",
         "0.1851851851851852",
         "0.27777777777777773"
        ],
        [
         "18",
         "MultiOutputClassifier(RandomForestClassifier())",
         "0.5555555555555555",
         "0.2037037037037037",
         "0.273015873015873"
        ],
        [
         "19",
         "MultiOutputClassifier(DecisionTreeClassifier())",
         "0.5",
         "0.1851851851851852",
         "0.2692307692307692"
        ],
        [
         "20",
         "OneVsRestClassifier(RandomForestClassifier())",
         "0.5",
         "0.1851851851851852",
         "0.2692307692307692"
        ],
        [
         "21",
         "OneVsRestClassifier(SGDClassifier())",
         "0.27777777777777773",
         "0.2962962962962963",
         "0.25071225071225073"
        ],
        [
         "22",
         "OneVsRestClassifier(DecisionTreeClassifier())",
         "0.35555555555555557",
         "0.1851851851851852",
         "0.23232323232323235"
        ],
        [
         "23",
         "OneVsRestClassifier(ExtraTreesClassifier())",
         "0.6666666666666666",
         "0.0925925925925926",
         "0.1619047619047619"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 24
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneVsRestClassifier(AdaBoostClassifier())</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.738889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultiOutputClassifier(GaussianNB())</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.651852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneVsRestClassifier(GaussianNB())</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.651852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultiOutputClassifier(XGBClassifier())</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OneVsRestClassifier(XGBClassifier())</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultiOutputClassifier(LGBMClassifier())</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.552381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OneVsRestClassifier(LGBMClassifier())</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.552381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OneVsRestClassifier(MLPClassifier())</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultiOutputClassifier(AdaBoostClassifier())</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultiOutputClassifier(SGDClassifier())</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.451346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OneVsRestClassifier(KNeighborsClassifier())</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.445614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultiOutputClassifier(KNeighborsClassifier())</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.445614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiOutputClassifier(MLPClassifier())</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiOutputClassifier(LogisticRegression())</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.341667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OneVsRestClassifier(LogisticRegression())</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.341667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultiOutputClassifier(SVC())</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OneVsRestClassifier(SVC())</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultiOutputClassifier(ExtraTreesClassifier())</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultiOutputClassifier(RandomForestClassifier())</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.273016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MultiOutputClassifier(DecisionTreeClassifier())</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OneVsRestClassifier(RandomForestClassifier())</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>OneVsRestClassifier(SGDClassifier())</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.250712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OneVsRestClassifier(DecisionTreeClassifier())</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.232323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OneVsRestClassifier(ExtraTreesClassifier())</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.161905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Model  Precision    Recall  \\\n",
       "0         OneVsRestClassifier(AdaBoostClassifier())   0.952381  0.611111   \n",
       "1               MultiOutputClassifier(GaussianNB())   0.768519  0.574074   \n",
       "2                 OneVsRestClassifier(GaussianNB())   0.768519  0.574074   \n",
       "3            MultiOutputClassifier(XGBClassifier())   0.933333  0.425926   \n",
       "4              OneVsRestClassifier(XGBClassifier())   0.933333  0.425926   \n",
       "5           MultiOutputClassifier(LGBMClassifier())   0.933333  0.425926   \n",
       "6             OneVsRestClassifier(LGBMClassifier())   0.933333  0.425926   \n",
       "7              OneVsRestClassifier(MLPClassifier())   0.611111  0.407407   \n",
       "8       MultiOutputClassifier(AdaBoostClassifier())   0.619048  0.388889   \n",
       "9            MultiOutputClassifier(SGDClassifier())   0.380952  0.555556   \n",
       "10      OneVsRestClassifier(KNeighborsClassifier())   0.483333  0.425926   \n",
       "11    MultiOutputClassifier(KNeighborsClassifier())   0.483333  0.425926   \n",
       "12           MultiOutputClassifier(MLPClassifier())   0.555556  0.296296   \n",
       "13      MultiOutputClassifier(LogisticRegression())   0.404762  0.296296   \n",
       "14        OneVsRestClassifier(LogisticRegression())   0.404762  0.296296   \n",
       "15                     MultiOutputClassifier(SVC())   0.666667  0.203704   \n",
       "16                       OneVsRestClassifier(SVC())   0.666667  0.203704   \n",
       "17    MultiOutputClassifier(ExtraTreesClassifier())   0.555556  0.185185   \n",
       "18  MultiOutputClassifier(RandomForestClassifier())   0.555556  0.203704   \n",
       "19  MultiOutputClassifier(DecisionTreeClassifier())   0.500000  0.185185   \n",
       "20    OneVsRestClassifier(RandomForestClassifier())   0.500000  0.185185   \n",
       "21             OneVsRestClassifier(SGDClassifier())   0.277778  0.296296   \n",
       "22    OneVsRestClassifier(DecisionTreeClassifier())   0.355556  0.185185   \n",
       "23      OneVsRestClassifier(ExtraTreesClassifier())   0.666667  0.092593   \n",
       "\n",
       "    F1-score  \n",
       "0   0.738889  \n",
       "1   0.651852  \n",
       "2   0.651852  \n",
       "3   0.579365  \n",
       "4   0.579365  \n",
       "5   0.552381  \n",
       "6   0.552381  \n",
       "7   0.481481  \n",
       "8   0.472222  \n",
       "9   0.451346  \n",
       "10  0.445614  \n",
       "11  0.445614  \n",
       "12  0.377778  \n",
       "13  0.341667  \n",
       "14  0.341667  \n",
       "15  0.288889  \n",
       "16  0.288889  \n",
       "17  0.277778  \n",
       "18  0.273016  \n",
       "19  0.269231  \n",
       "20  0.269231  \n",
       "21  0.250712  \n",
       "22  0.232323  \n",
       "23  0.161905  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = get_report_all_ml(X_train, y_train, X_test)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e2e93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = models[df_report['Model'][0]]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "display_multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90538d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mint, f1-score: 0.7543859649122806\n",
      "leak, f1-score: 0.8782608695652174\n",
      "limit, f1-score: 0.7083333333333333\n"
     ]
    }
   ],
   "source": [
    "labels = y.columns.tolist()  # assuming y is a pandas DataFrame\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    report_dict = classification_report(y_test[label], y_pred[:, i], output_dict=True)\n",
    "    f1 = report_dict[\"macro avg\"][\"f1-score\"]\n",
    "    print(f\"{label}, f1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb1747",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "940ad128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(trial, base):\n",
    "    match base:\n",
    "        case \"LogisticRegression\":\n",
    "            return LogisticRegression(\n",
    "                C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "                max_iter=trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "                solver=\"lbfgs\",\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        case \"DecisionTreeClassifier\":\n",
    "            return DecisionTreeClassifier(\n",
    "                max_depth=trial.suggest_int(\"max_depth\", 5, 50),\n",
    "                min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "                min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        case \"RandomForestClassifier\":\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                max_depth=trial.suggest_int(\"max_depth\", 5, 50),\n",
    "                min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "                min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "        case \"AdaBoostClassifier\":\n",
    "            return AdaBoostClassifier(\n",
    "                n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        case \"ExtraTreesClassifier\":\n",
    "            return ExtraTreesClassifier(\n",
    "                n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                max_depth=trial.suggest_int(\"max_depth\", 5, 50),\n",
    "                min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "                min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "        case \"XGBClassifier\":\n",
    "            return XGBClassifier(\n",
    "                n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "                learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "                subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=\"logloss\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "        case \"LGBMClassifier\":\n",
    "            return LGBMClassifier(\n",
    "                n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "                learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "                subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "        case \"SVC\":\n",
    "            return SVC(\n",
    "                C=trial.suggest_float(\"C\", 0.1, 10.0),\n",
    "                kernel=trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\"]),\n",
    "                gamma=trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "                probability=True\n",
    "            )\n",
    "\n",
    "        case \"GaussianNB\":\n",
    "            return GaussianNB()  # No major hyperparameters to tune\n",
    "\n",
    "        case \"KNeighborsClassifier\":\n",
    "            return KNeighborsClassifier(\n",
    "                n_neighbors=trial.suggest_int(\"n_neighbors\", 1, 20),\n",
    "                weights=trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "                p=trial.suggest_int(\"p\", 1, 2)  # 1 = manhattan, 2 = euclidean\n",
    "            )\n",
    "\n",
    "        case \"SGDClassifier\":\n",
    "            return SGDClassifier(\n",
    "                loss=trial.suggest_categorical(\"loss\", [\"hinge\", \"log_loss\", \"modified_huber\"]),\n",
    "                penalty=trial.suggest_categorical(\"penalty\", [\"l2\", \"l1\", \"elasticnet\"]),\n",
    "                alpha=trial.suggest_float(\"alpha\", 1e-6, 1e-1, log=True),\n",
    "                max_iter=trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        case \"MLPClassifier\":\n",
    "            return MLPClassifier(\n",
    "                hidden_layer_sizes=trial.suggest_categorical(\"hidden_layer_sizes\", [(100,), (50, 50), (100, 50)]),\n",
    "                activation=trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "                solver=trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"]),\n",
    "                alpha=trial.suggest_float(\"alpha\", 1e-6, 1e-1, log=True),\n",
    "                learning_rate=trial.suggest_categorical(\"learning_rate\", [\"constant\", \"adaptive\"]),\n",
    "                max_iter=trial.suggest_int(\"max_iter\", 300, 1000),\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        case _:\n",
    "            raise NotImplementedError(f\"No tuning config for: {base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d05cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_name(df_report=df_report):\n",
    "    model_name = df_report['Model'][0]\n",
    "    wrapper_name = model_name.split(\"(\")[0]\n",
    "    base = model_name[model_name.find(\"(\")+1 : model_name.find(\")\")-1]\n",
    "    return wrapper_name, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfca1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    wrapper_name, base = get_best_model_name()\n",
    "\n",
    "    estimator = get_estimator(trial, base)\n",
    "\n",
    "    if \"MultiOutputClassifier\" in wrapper_name:\n",
    "        model = MultiOutputClassifier(estimator)\n",
    "    elif \"OneVsRestClassifier\" in wrapper_name:\n",
    "        model = OneVsRestClassifier(estimator)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown wrapper: {wrapper_name}\")\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring=make_scorer(f1_score, average='macro', zero_division=0),\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a775cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 14:44:21,452] A new study created in memory with name: no-name-bcd49f82-92c6-4db0-a333-9416014f5bde\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:33,002] Trial 0 finished with value: 0.46886936592818945 and parameters: {'n_estimators': 991, 'learning_rate': 0.0019332889125904633}. Best is trial 0 with value: 0.46886936592818945.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:35,937] Trial 1 finished with value: 0.3439775910364146 and parameters: {'n_estimators': 234, 'learning_rate': 0.0017203232715685638}. Best is trial 0 with value: 0.46886936592818945.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:41,051] Trial 2 finished with value: 0.49254449254449256 and parameters: {'n_estimators': 617, 'learning_rate': 0.0543030596830994}. Best is trial 2 with value: 0.49254449254449256.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:42,751] Trial 3 finished with value: 0.3439775910364146 and parameters: {'n_estimators': 273, 'learning_rate': 0.0019798695389803864}. Best is trial 2 with value: 0.49254449254449256.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:48,605] Trial 4 finished with value: 0.5587042224297126 and parameters: {'n_estimators': 904, 'learning_rate': 0.004278969588414963}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:51,729] Trial 5 finished with value: 0.5201058201058201 and parameters: {'n_estimators': 516, 'learning_rate': 0.09354414655666159}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:44:58,883] Trial 6 finished with value: 0.5452460756382326 and parameters: {'n_estimators': 756, 'learning_rate': 0.004263755808522507}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:01,615] Trial 7 finished with value: 0.4711079044412378 and parameters: {'n_estimators': 221, 'learning_rate': 0.06877968431392362}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:09,614] Trial 8 finished with value: 0.461319544652878 and parameters: {'n_estimators': 828, 'learning_rate': 0.16823503768533055}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:15,762] Trial 9 finished with value: 0.47190155523488864 and parameters: {'n_estimators': 897, 'learning_rate': 0.13956080236894708}. Best is trial 4 with value: 0.5587042224297126.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:19,031] Trial 10 finished with value: 0.5590970394891963 and parameters: {'n_estimators': 513, 'learning_rate': 0.011099367883960596}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:21,975] Trial 11 finished with value: 0.5153259957181526 and parameters: {'n_estimators': 486, 'learning_rate': 0.013365431897346286}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:25,782] Trial 12 finished with value: 0.46153410859293215 and parameters: {'n_estimators': 634, 'learning_rate': 0.010365216315764298}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:28,225] Trial 13 finished with value: 0.48738788444670805 and parameters: {'n_estimators': 401, 'learning_rate': 0.0054838185370160095}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:32,856] Trial 14 finished with value: 0.5130911934833503 and parameters: {'n_estimators': 715, 'learning_rate': 0.026871417126329115}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:35,193] Trial 15 finished with value: 0.46886936592818945 and parameters: {'n_estimators': 385, 'learning_rate': 0.0054338133208451525}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:40,967] Trial 16 finished with value: 0.4798121268709505 and parameters: {'n_estimators': 955, 'learning_rate': 0.028041613156824175}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:43,282] Trial 17 finished with value: 0.3439775910364146 and parameters: {'n_estimators': 376, 'learning_rate': 0.00107766817381948}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:43,993] Trial 18 finished with value: 0.2990040460628696 and parameters: {'n_estimators': 110, 'learning_rate': 0.00783947694520709}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:47,774] Trial 19 finished with value: 0.512025012025012 and parameters: {'n_estimators': 624, 'learning_rate': 0.023030313093756794}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:52,542] Trial 20 finished with value: 0.5324255628177196 and parameters: {'n_estimators': 754, 'learning_rate': 0.0033384933053710792}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:45:57,723] Trial 21 finished with value: 0.5340128644050213 and parameters: {'n_estimators': 835, 'learning_rate': 0.004296876043690493}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:02,375] Trial 22 finished with value: 0.5324255628177196 and parameters: {'n_estimators': 732, 'learning_rate': 0.0034032647181992644}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:07,823] Trial 23 finished with value: 0.5047439851361419 and parameters: {'n_estimators': 891, 'learning_rate': 0.008134866635165628}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:12,715] Trial 24 finished with value: 0.5248498052419621 and parameters: {'n_estimators': 797, 'learning_rate': 0.016495549632083793}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:17,199] Trial 25 finished with value: 0.46886936592818945 and parameters: {'n_estimators': 676, 'learning_rate': 0.002719370059632468}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:20,713] Trial 26 finished with value: 0.5494449631704533 and parameters: {'n_estimators': 541, 'learning_rate': 0.006855451026970172}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:24,305] Trial 27 finished with value: 0.5153259957181526 and parameters: {'n_estimators': 563, 'learning_rate': 0.014147740184093751}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:27,324] Trial 28 finished with value: 0.5384559521814424 and parameters: {'n_estimators': 478, 'learning_rate': 0.007693733810986544}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:31,081] Trial 29 finished with value: 0.4941317941317942 and parameters: {'n_estimators': 566, 'learning_rate': 0.0368035671146313}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:33,313] Trial 30 finished with value: 0.30694055399937753 and parameters: {'n_estimators': 317, 'learning_rate': 0.0020739290621367684}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:39,854] Trial 31 finished with value: 0.5424864895453131 and parameters: {'n_estimators': 990, 'learning_rate': 0.0051527779793907255}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:42,942] Trial 32 finished with value: 0.5497976968565204 and parameters: {'n_estimators': 447, 'learning_rate': 0.010669045853594072}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:45,880] Trial 33 finished with value: 0.5111733582321817 and parameters: {'n_estimators': 439, 'learning_rate': 0.010282396286015847}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:49,366] Trial 34 finished with value: 0.5154943458865028 and parameters: {'n_estimators': 549, 'learning_rate': 0.006472589643846248}. Best is trial 10 with value: 0.5590970394891963.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:51,566] Trial 35 finished with value: 0.5596742400663969 and parameters: {'n_estimators': 330, 'learning_rate': 0.018596170524858884}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:53,566] Trial 36 finished with value: 0.5501282305203873 and parameters: {'n_estimators': 317, 'learning_rate': 0.017394782142826457}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:55,121] Trial 37 finished with value: 0.5548907882241215 and parameters: {'n_estimators': 196, 'learning_rate': 0.041067029009665114}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:46:56,953] Trial 38 finished with value: 0.5165864636452872 and parameters: {'n_estimators': 162, 'learning_rate': 0.044312288205196546}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:00,186] Trial 39 finished with value: 0.46786546786546784 and parameters: {'n_estimators': 252, 'learning_rate': 0.05446962948910716}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:03,027] Trial 40 finished with value: 0.5393020196941766 and parameters: {'n_estimators': 194, 'learning_rate': 0.08429426067305451}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:07,152] Trial 41 finished with value: 0.5476190476190476 and parameters: {'n_estimators': 300, 'learning_rate': 0.01960248035333705}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:10,717] Trial 42 finished with value: 0.5010360010360011 and parameters: {'n_estimators': 344, 'learning_rate': 0.03424195602380553}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:12,059] Trial 43 finished with value: 0.533772364164521 and parameters: {'n_estimators': 148, 'learning_rate': 0.019351731384954152}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:14,027] Trial 44 finished with value: 0.5587042224297126 and parameters: {'n_estimators': 268, 'learning_rate': 0.012600122124918706}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:15,744] Trial 45 finished with value: 0.5452460756382326 and parameters: {'n_estimators': 221, 'learning_rate': 0.012407778561229895}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:17,602] Trial 46 finished with value: 0.4597883597883598 and parameters: {'n_estimators': 247, 'learning_rate': 0.05875654204000241}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:18,351] Trial 47 finished with value: 0.4849267653189222 and parameters: {'n_estimators': 106, 'learning_rate': 0.1210330403789252}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:19,628] Trial 48 finished with value: 0.5486852290773859 and parameters: {'n_estimators': 187, 'learning_rate': 0.026527596850901516}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:21,690] Trial 49 finished with value: 0.5331890331890333 and parameters: {'n_estimators': 287, 'learning_rate': 0.03656005446110579}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:24,007] Trial 50 finished with value: 0.5062350866272435 and parameters: {'n_estimators': 370, 'learning_rate': 0.010021570963540796}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:26,203] Trial 51 finished with value: 0.5596742400663969 and parameters: {'n_estimators': 337, 'learning_rate': 0.016686567463659704}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:28,614] Trial 52 finished with value: 0.5596742400663969 and parameters: {'n_estimators': 351, 'learning_rate': 0.015187831190940294}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:31,063] Trial 53 finished with value: 0.5522045855379188 and parameters: {'n_estimators': 345, 'learning_rate': 0.02213011038517591}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:33,713] Trial 54 finished with value: 0.5173461977383546 and parameters: {'n_estimators': 396, 'learning_rate': 0.014834551776477228}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:36,727] Trial 55 finished with value: 0.5501282305203873 and parameters: {'n_estimators': 447, 'learning_rate': 0.027093673621483277}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:38,631] Trial 56 finished with value: 0.5477152114407017 and parameters: {'n_estimators': 279, 'learning_rate': 0.012356916305079594}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:41,477] Trial 57 finished with value: 0.5384559521814424 and parameters: {'n_estimators': 419, 'learning_rate': 0.00847431365375092}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:44,794] Trial 58 finished with value: 0.2990040460628696 and parameters: {'n_estimators': 504, 'learning_rate': 0.001625492229943155}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:49,452] Trial 59 finished with value: 0.5151675485008819 and parameters: {'n_estimators': 696, 'learning_rate': 0.017372118592967847}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:53,745] Trial 60 finished with value: 0.5119127423048991 and parameters: {'n_estimators': 657, 'learning_rate': 0.004527312723479844}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:55,278] Trial 61 finished with value: 0.484900284900285 and parameters: {'n_estimators': 225, 'learning_rate': 0.044621509859595836}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:57,599] Trial 62 finished with value: 0.507469654528478 and parameters: {'n_estimators': 343, 'learning_rate': 0.022885117905966167}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:47:59,444] Trial 63 finished with value: 0.5001843472431707 and parameters: {'n_estimators': 270, 'learning_rate': 0.030802111344494624}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:00,929] Trial 64 finished with value: 0.5384559521814424 and parameters: {'n_estimators': 201, 'learning_rate': 0.01520465014376816}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:01,911] Trial 65 finished with value: 0.3484989955578191 and parameters: {'n_estimators': 138, 'learning_rate': 0.012046445139400676}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:04,547] Trial 66 finished with value: 0.5028199832121402 and parameters: {'n_estimators': 370, 'learning_rate': 0.006205916285218917}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:08,824] Trial 67 finished with value: 0.516464363523187 and parameters: {'n_estimators': 594, 'learning_rate': 0.008871429992537193}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:15,001] Trial 68 finished with value: 0.5452460756382326 and parameters: {'n_estimators': 911, 'learning_rate': 0.0029562694652157996}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:18,243] Trial 69 finished with value: 0.3439775910364146 and parameters: {'n_estimators': 477, 'learning_rate': 0.001085191694544286}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:20,244] Trial 70 finished with value: 0.48272217978100335 and parameters: {'n_estimators': 309, 'learning_rate': 0.1899348102430166}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:22,421] Trial 71 finished with value: 0.5179073649661885 and parameters: {'n_estimators': 330, 'learning_rate': 0.023181468785585743}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:24,753] Trial 72 finished with value: 0.5543832347753916 and parameters: {'n_estimators': 357, 'learning_rate': 0.018808001389023152}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:27,558] Trial 73 finished with value: 0.5424864895453131 and parameters: {'n_estimators': 415, 'learning_rate': 0.01983953439797608}. Best is trial 35 with value: 0.5596742400663969.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:29,307] Trial 74 finished with value: 0.5753708890963792 and parameters: {'n_estimators': 258, 'learning_rate': 0.014383548425403904}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:31,033] Trial 75 finished with value: 0.5582090386011954 and parameters: {'n_estimators': 238, 'learning_rate': 0.010902442747899189}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:32,745] Trial 76 finished with value: 0.5409250879839115 and parameters: {'n_estimators': 245, 'learning_rate': 0.011371777299268002}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:34,623] Trial 77 finished with value: 0.5255472559394128 and parameters: {'n_estimators': 264, 'learning_rate': 0.009692119721741544}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:40,474] Trial 78 finished with value: 0.5248498052419621 and parameters: {'n_estimators': 823, 'learning_rate': 0.014764852398380619}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:42,667] Trial 79 finished with value: 0.5059064029652265 and parameters: {'n_estimators': 293, 'learning_rate': 0.007213247962778541}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:47,182] Trial 80 finished with value: 0.5151675485008819 and parameters: {'n_estimators': 589, 'learning_rate': 0.013689141650527651}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:48,592] Trial 81 finished with value: 0.32998047703930056 and parameters: {'n_estimators': 172, 'learning_rate': 0.009015222839856698}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:50,414] Trial 82 finished with value: 0.5384559521814424 and parameters: {'n_estimators': 213, 'learning_rate': 0.01656563750219267}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:52,269] Trial 83 finished with value: 0.5253968253968254 and parameters: {'n_estimators': 230, 'learning_rate': 0.04417919800052829}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:54,947] Trial 84 finished with value: 0.554790235182392 and parameters: {'n_estimators': 326, 'learning_rate': 0.013272059233088702}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:57,101] Trial 85 finished with value: 0.32998047703930056 and parameters: {'n_estimators': 259, 'learning_rate': 0.005870817970327275}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:58,626] Trial 86 finished with value: 0.44109158815041166 and parameters: {'n_estimators': 176, 'learning_rate': 0.011319730620996222}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:48:59,671] Trial 87 finished with value: 0.5180294650882886 and parameters: {'n_estimators': 128, 'learning_rate': 0.07568049595888918}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:01,877] Trial 88 finished with value: 0.3138188608776844 and parameters: {'n_estimators': 286, 'learning_rate': 0.003920311999819512}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:05,752] Trial 89 finished with value: 0.48087032792915146 and parameters: {'n_estimators': 521, 'learning_rate': 0.031098584635610948}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:08,685] Trial 90 finished with value: 0.5052910052910052 and parameters: {'n_estimators': 390, 'learning_rate': 0.020541568771288828}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:10,868] Trial 91 finished with value: 0.5526534830456399 and parameters: {'n_estimators': 305, 'learning_rate': 0.012931169271172117}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:13,314] Trial 92 finished with value: 0.5543832347753916 and parameters: {'n_estimators': 333, 'learning_rate': 0.01559858811330345}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:15,625] Trial 93 finished with value: 0.5176465509798843 and parameters: {'n_estimators': 325, 'learning_rate': 0.025450310406198308}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:18,254] Trial 94 finished with value: 0.5304312608234177 and parameters: {'n_estimators': 358, 'learning_rate': 0.007557154933306861}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:19,673] Trial 95 finished with value: 0.5311028114949684 and parameters: {'n_estimators': 204, 'learning_rate': 0.10016023407943199}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:21,396] Trial 96 finished with value: 0.4792509596431165 and parameters: {'n_estimators': 237, 'learning_rate': 0.010331175047033235}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:24,258] Trial 97 finished with value: 0.5067641871563441 and parameters: {'n_estimators': 421, 'learning_rate': 0.01723375292156897}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:26,031] Trial 98 finished with value: 0.3138188608776844 and parameters: {'n_estimators': 271, 'learning_rate': 0.004882874565956421}. Best is trial 74 with value: 0.5753708890963792.\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 14:49:31,088] Trial 99 finished with value: 0.5153259957181526 and parameters: {'n_estimators': 770, 'learning_rate': 0.01399448047917704}. Best is trial 74 with value: 0.5753708890963792.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)  # You can increase n_trials for better tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "650f5d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (macro F1): 0.5753708890963792\n",
      "Best trial params: {'n_estimators': 258, 'learning_rate': 0.014383548425403904}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score (macro F1):\", study.best_value)\n",
    "print(\"Best trial params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca109792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model name\n",
    "wrapper_name, base = get_best_model_name()\n",
    "\n",
    "# Get best tuned estimator\n",
    "best_base_model = get_estimator(study.best_trial, base)\n",
    "\n",
    "# Wrap it again\n",
    "if \"MultiOutputClassifier\" in wrapper_name:\n",
    "    best_model_tuned = MultiOutputClassifier(best_base_model)\n",
    "elif \"OneVsRestClassifier\" in wrapper_name:\n",
    "    best_model_tuned = OneVsRestClassifier(best_base_model)\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown wrapper: {wrapper_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e73b32a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.014383548425403904,\n",
       "                                                 n_estimators=258,\n",
       "                                                 random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneVsRestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.014383548425403904,\n",
       "                                                 n_estimators=258,\n",
       "                                                 random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(learning_rate=0.014383548425403904, n_estimators=258,\n",
       "                   random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(learning_rate=0.014383548425403904, n_estimators=258,\n",
       "                   random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.014383548425403904,\n",
       "                                                 n_estimators=258,\n",
       "                                                 random_state=42))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b76cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f03d6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mint       0.75      0.50      0.60         6\n",
      "        leak       1.00      0.67      0.80         3\n",
      "       limit       0.60      0.33      0.43         9\n",
      "\n",
      "   micro avg       0.73      0.44      0.55        18\n",
      "   macro avg       0.78      0.50      0.61        18\n",
      "weighted avg       0.72      0.44      0.55        18\n",
      " samples avg       0.50      0.38      0.39        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcbcf328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABb4AAAGGCAYAAAC0fZerAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjJ0lEQVR4nO3de5yM9f//8eesw9jYXYfWruMirFPO0pJQSkI23ygpS1RKhY20PsqprMiplFNlfZR0RAeqjfDpg3IsOshZyjplaRdDu/P7o5/5NHaXmZ2duea69nH/3K7b7TPvuWber2ttnq7XdbI5nU6nAAAAAAAAAACwiBCjCwAAAAAAAAAAoCDR+AYAAAAAAAAAWAqNbwAAAAAAAACApdD4BgAAAAAAAABYCo1vAAAAAAAAAICl0PgGAAAAAAAAAFgKjW8AAAAAAAAAgKXQ+AYAAAAAAAAAWAqNbwAAAAAAAACApdD4hins2rVLt956qyIiImSz2bR06dIC/f79+/fLZrMpJSWlQL/XzNq1a6d27doZXcYV2Ww2jRkzxugyAAD/H5kdeIHI7NWrV8tms2n16tV+myMlJUU2m02bNm3y2xwAgL+R14FnVF737dtX1apVK9B5zNIvAGh8w2N79uzRww8/rBo1aqhEiRIKDw9X69atNWPGDJ09e9avcyckJGj79u16/vnntXDhQjVv3tyv8wVS3759ZbPZFB4enuvPcdeuXbLZbLLZbHrxxRe9/v7ff/9dY8aM0bZt2wqgWmuZMGFCgf8DDwCCAZntH2Q2AKAgkdf+QV4HHj8TBKuiRhcAc/j000/Vo0cP2e129enTRw0aNND58+f19ddfa/jw4frhhx80d+5cv8x99uxZrV+/Xv/617/02GOP+WWOmJgYnT17VsWKFfPL919J0aJFdebMGX388cfq2bOn23tvvfWWSpQooXPnzuXru3///XeNHTtW1apVU+PGjT3+3BdffJGv+QLt7NmzKlo0f3+VTZgwQXfddZfi4+MLtigAMBCZ7V9kNgCgIJDX/kVe/8+8efOUnZ1doN956bbk92cC+BuNb1zRvn37dM899ygmJkarVq1ShQoVXO8NGjRIu3fv1qeffuq3+Y8dOyZJKl26tN/msNlsKlGihN++/0rsdrtat26tt99+O0coL1q0SJ07d9YHH3wQkFrOnDmjq666SsWLFw/IfL4y8s8NAIINme1/ZDYAwFfktf+R1//jj4MP/NsDZsGtTnBFkyZNUkZGhl5//XW3QL6oZs2aGjx4sOv1X3/9pfHjx+uaa66R3W5XtWrVNHLkSDkcDrfPVatWTV26dNHXX3+t6667TiVKlFCNGjX073//27XOmDFjFBMTI0kaPny4bDab695Ued2nasyYMbLZbG5jqampuuGGG1S6dGmVKlVKsbGxGjlypOv9vO4/tmrVKrVp00YlS5ZU6dKl1a1bN/3000+5zrd792717dtXpUuXVkREhPr166czZ87k/YO9xL333qsVK1YoPT3dNbZx40bt2rVL9957b471//jjDw0bNkzXXnutSpUqpfDwcHXq1Enfffeda53Vq1erRYsWkqR+/fq5Lue6uJ3t2rVTgwYNtHnzZt1444266qqrXD+XS+/ZlZCQoBIlSuTY/o4dO6pMmTL6/fffXWN79uzRnj17rrjNF+/l+fXXX+uJJ55QZGSkSpcurYcffljnz59Xenq6+vTpozJlyqhMmTJ66qmn5HQ63b7j0nt8e/rnYbPZlJmZqQULFrh+Ln379r1izQAQzMhsMlvyT2bn5ZtvvtFtt92miIgIXXXVVWrbtq3++9//uq1z4MABPfroo4qNjVVoaKjKlSunHj16aP/+/Vf8/pMnT+q6665T5cqVtXPnznzXCQDBhLwmr6XA5fWlf64X/2xefPFFvfLKK6pRo4auuuoq3Xrrrfr111/ldDo1fvx4Va5cWaGhoerWrZv++OMPt+/857Zc6WcCGInGN67o448/Vo0aNdSqVSuP1h8wYICeffZZNW3aVNOmTVPbtm2VnJyse+65J8e6u3fv1l133aVbbrlFU6ZMUZkyZdS3b1/98MMPkqTu3btr2rRpkqRevXpp4cKFmj59ulf1//DDD+rSpYscDofGjRunKVOm6I477sixU3apL7/8Uh07dtTRo0c1ZswYJSYmat26dWrdunWuO2o9e/bUn3/+qeTkZPXs2VMpKSkaO3asx3V2795dNptNH374oWts0aJFqlOnjpo2bZpj/b1792rp0qXq0qWLpk6dquHDh2v79u1q27atKyDr1q2rcePGSZIeeughLVy4UAsXLtSNN97o+p4TJ06oU6dOaty4saZPn6727dvnWt+MGTMUGRmphIQEZWVlSZLmzJmjL774Qi+//LIqVqzoWvfmm2/WzTff7PG2P/7449q1a5fGjh2rO+64Q3PnztUzzzyjrl27KisrSxMmTNANN9ygyZMna+HChR5955X+PBYuXCi73a42bdq4fi4PP/ywxzUDQDAis8lsyb+Z/U+rVq3SjTfeqNOnT2v06NGaMGGC0tPTddNNN+nbb791rbdx40atW7dO99xzj1566SUNHDhQK1euVLt27S7bwDh+/LhuuukmHTlyRGvWrFFsbGy+6gSAYENek9dS4PI6L2+99ZZeffVVPf7443ryySe1Zs0a9ezZU6NGjdJnn32mESNG6KGHHtLHH3+sYcOG5fk9nvxMAMM4gcs4deqUU5KzW7duHq2/bds2pyTngAED3MaHDRvmlORctWqVaywmJsYpybl27VrX2NGjR512u9355JNPusb27dvnlOScPHmy23cmJCQ4Y2JictQwevRo5z9/tadNm+aU5Dx27FiedV+cY/78+a6xxo0bO8uXL+88ceKEa+y7775zhoSEOPv06ZNjvgceeMDtO++8805nuXLl8pzzn9tRsmRJp9PpdN51113Om2++2el0Op1ZWVnO6Oho59ixY3P9GZw7d86ZlZWVYzvsdrtz3LhxrrGNGzfm2LaL2rZt65TknD17dq7vtW3b1m3s888/d0pyPvfcc869e/c6S5Uq5YyPj8/x2ZiYmFz/bC41f/58pyRnx44dndnZ2a7xuLg4p81mcw4cONA19tdffzkrV66coyZJztGjR7tee/PnUbJkSWdCQsIV6wQAMyCzyex/KujM/uqrr5ySnF999ZXT6XQ6s7OznbVq1cqR4WfOnHFWr17decstt7iNXWr9+vVOSc5///vfrrGL/y7YuHGj8/Dhw8769es7a9So4dy/f/8V6wMAsyCvyet/8ndeO505/1wvbntkZKQzPT3dNZ6UlOSU5GzUqJHzwoULrvFevXo5ixcv7jx37lye23K5nwlgJM74xmWdPn1akhQWFubR+suXL5ckJSYmuo0/+eSTkpTjPmX16tVTmzZtXK8jIyMVGxurvXv35rvmS128b9myZcs8fqDD4cOHtW3bNvXt21dly5Z1jTds2FC33HKLazv/aeDAgW6v27RpoxMnTrh+hp649957tXr1aqWlpWnVqlVKS0vL9RIs6e97loWE/P2fcFZWlk6cOOG6xGzLli0ez2m329WvXz+P1r311lv18MMPa9y4cerevbtKlCihOXPm5Fhv//79Hl2+fFH//v3dLp1r2bKlnE6n+vfv7xorUqSImjdv7vHvRkH8eQCAmZDZZPY/+SuzL9q2bZvrUvETJ07o+PHjOn78uDIzM3XzzTdr7dq1rj/D0NBQ1+cuXLigEydOqGbNmipdunSu23/o0CG1bdtWFy5c0Nq1a12X5AOAFZDX5PU/+TuvL6dHjx6KiIhwvW7ZsqUk6b777lPRokXdxs+fP6/ffvutQOcHAoHGNy4rPDxckvTnn396tP6BAwcUEhKimjVruo1HR0erdOnSOnDggNt41apVc3xHmTJldPLkyXxWnNPdd9+t1q1ba8CAAYqKitI999yjd99997IBfbHO3C6prVu3rmvH7p8u3ZYyZcpIklfbcvvttyssLEzvvPOO3nrrLbVo0SLHz/Ki7OxsTZs2TbVq1ZLdbtfVV1+tyMhIff/99zp16pTHc1aqVMmrB1O8+OKLKlu2rLZt26aXXnpJ5cuX9/izebn0Z3cxfKtUqZJj3NOfZ0H8eQCAmZDZZPal/JHZF+3atUvS3/cnjYyMdFtee+01ORwO17adPXtWzz77rKpUqeK2/enp6blu//3336+jR49qzZo1qlSpUoHVDADBgLwmry/lz7y+HG/2wyX2pWFONL5xWeHh4apYsaJ27Njh1ecuffBFXooUKZLruPOSBxh6M8fFe2NdFBoaqrVr1+rLL7/U/fffr++//1533323brnllhzr+sKXbbnIbrere/fuWrBggZYsWZLnkWhJmjBhghITE3XjjTfqzTff1Oeff67U1FTVr1/f46PukvtZWJ7YunWrjh49Kknavn27V5/NS14/u9zGPf15FsSfBwCYCZntOTLbdxfrnjx5slJTU3NdSpUqJenvZ3k8//zz6tmzp95991198cUXSk1NVbly5XLd/u7duys9PV0zZswo0JoBIBiQ154jr/3Lm/1wiX1pmFPRK6+Cwq5Lly6aO3eu1q9fr7i4uMuuGxMTo+zsbO3atUt169Z1jR85ckTp6ekFeqlqmTJl3J7OfNGlR7wlKSQkxPUwiKlTp2rChAn617/+pa+++kodOnTIdTskaefOnTne+/nnn3X11VerZMmSvm9ELu6991698cYbCgkJyfVhJRe9//77at++vV5//XW38fT0dF199dWu157+A8kTmZmZ6tevn+rVq6dWrVpp0qRJuvPOO11PcDabgvzZAEAwILPdkdn+y+xrrrlG0t8NnNz+XP7p/fffV0JCgqZMmeIaO3fuXK6/E9LfjfKaNWvq2WefVUREhJ5++ukCqRkAggV57Y68Nv8+NvvWCFac8Y0reuqpp1SyZEkNGDBAR44cyfH+nj17XGfk3H777ZKU46nQU6dOlSR17ty5wOq65pprdOrUKX3//feuscOHD2vJkiVu6/3xxx85Ptu4cWNJksPhyPW7K1SooMaNG2vBggVuwb9jxw598cUXru30h/bt22v8+PGaOXOmoqOj81yvSJEiOY64vvfeeznuu3XxHw957Vx6Y8SIETp48KAWLFigqVOnqlq1akpISMjxc9yzZ4/27Nnj83z+VrJkyQL5uQBAsCCz013jZLZ/M7tZs2a65ppr9OKLLyojIyPH+8eOHXP9/9y2/+WXX77sWYHPPPOMhg0bpqSkJM2aNcvr+gAgmJHX6a5x8toa+9gF+TMBChJnfOOKrrnmGi1atEh333236tatqz59+qhBgwY6f/681q1bp/fee099+/aVJDVq1EgJCQmaO3eu0tPT1bZtW3377bdasGCB4uPj1b59+wKr65577tGIESN055136oknntCZM2c0a9Ys1a5d2+3BE+PGjdPatWvVuXNnxcTE6OjRo3r11VdVuXJl3XDDDXl+/+TJk9WpUyfFxcWpf//+Onv2rF5++WVFRERozJgxBbYdlwoJCdGoUaOuuF6XLl00btw49evXT61atdL27dv11ltvqUaNGm7rXXPNNSpdurRmz56tsLAwlSxZUi1btlT16tW9qmvVqlV69dVXNXr0aDVt2lSSNH/+fLVr107PPPOMJk2a5Fr35ptvlqQCf/hGQWvWrJm+/PJLTZ06VRUrVlT16tVdD/QAADMis8lsKTCZHRISotdee02dOnVS/fr11a9fP1WqVEm//fabvvrqK4WHh+vjjz92bf/ChQsVERGhevXqaf369fryyy9Vrly5y84xefJknTp1SoMGDVJYWJjuu+8+r2oEgGBFXpPXkrX2sQvqZwIUNBrf8Mgdd9yh77//XpMnT9ayZcs0a9Ys2e12NWzYUFOmTNGDDz7oWve1115TjRo1lJKSoiVLlig6OlpJSUkaPXp0gdZUrlw5LVmyRImJiXrqqadUvXp1JScna9euXW6hfMcdd2j//v164403dPz4cV199dVq27atxo4d6/YE40t16NBBn332mUaPHq1nn31WxYoVU9u2bfXCCy8ExV/eI0eOVGZmphYtWqR33nlHTZs21aeffprjcuBixYppwYIFSkpK0sCBA/XXX39p/vz5Xm3Dn3/+qQceeEBNmjTRv/71L9d4mzZtNHjwYE2ZMkXdu3fX9ddfX2DbFwhTp07VQw89pFGjRuns2bNKSEig8Q3A9MhsMjtQmd2uXTutX7/edRZdRkaGoqOj1bJlSz388MOu9WbMmKEiRYrorbfe0rlz59S6dWt9+eWX6tix4xXnmD17tjIyMtSvXz+FhYWpW7duPtcNAMGAvCavrbSPXRA/E8AfbE7uTg8AAAAAAAAAsBDu8Q0AAAAAAAAAsBQa3wAAAAAAAAAAS6HxDQAAAAAAAACwFBrfAABcolq1arLZbDmWQYMGGV0aAAAAAACm89tvv+m+++5TuXLlFBoaqmuvvVabNm267GdWr16tpk2bym63q2bNmkpJSfFqzqI+1AsAgCVt3LhRWVlZrtc7duzQLbfcoh49ehhYFQAAAAAA5nPy5Em1bt1a7du314oVKxQZGaldu3apTJkyeX5m37596ty5swYOHKi33npLK1eu1IABA1ShQgV17NjRo3ltTqfTWVAbAQCAFQ0ZMkSffPKJdu3aJZvNZnQ5AAAAAACYxtNPP63//ve/+s9//uPxZ0aMGKFPP/1UO3bscI3dc889Sk9P12effebRd3CrEwBAoeFwOHT69Gm3xeFwXPYz58+f15tvvqkHHniApjcAAAAAAPJu//qjjz5S8+bN1aNHD5UvX15NmjTRvHnzLvv969evV4cOHdzGOnbsqPXr13tcoyVvdRLa5DGjSwB8cnLjTKNLAHxSwk/p4uvf7yO6Xa2xY8e6jY0ePVpjxozJ8zNLly5Venq6+vbt69PcyIm8htmR1zC7YM3rs1v5byvYrN+dbnQJgE+aVCttdAmAT4Ixs73Zv967d69mzZqlxMREjRw5Uhs3btQTTzyh4sWLKyEhIdfvT0tLU1RUlNtYVFSUTp8+rbNnzyo0NPSKNVqy8Q0AQG6SkpKUmJjoNma32y/7mddff12dOnVSxYoV/VkaAAAAAACm4c3+dXZ2tpo3b64JEyZIkpo0aaIdO3Zo9uzZeTa+CwKNbwCAedh8u0OX3W6/YqP7nw4cOKAvv/xSH374oU/zAgBQqPiY1wAAIEB8yGxv9q8rVKigevXquY3VrVtXH3zwQZ6fiY6O1pEjR9zGjhw5ovDwcI/O9pZofAMAzCTA99ieP3++ypcvr86dOwd0XgAATI1nYgAAYA4ByuzWrVtr586dbmO//PKLYmJi8vxMXFycli9f7jaWmpqquLg4j+flUDwAwDxsIb4tXsjOztb8+fOVkJCgokU5TgwAgMcCmNcAAMAHAcrroUOHasOGDZowYYJ2796tRYsWae7cuRo0aJBrnaSkJPXp08f1euDAgdq7d6+eeuop/fzzz3r11Vf17rvvaujQoR7Py78qAADmYbP5tnjhyy+/1MGDB/XAAw/4aWMAALCoAOY1AADwQYDyukWLFlqyZInefvttNWjQQOPHj9f06dPVu3dv1zqHDx/WwYMHXa+rV6+uTz/9VKmpqWrUqJGmTJmi1157TR07dvR4Xk5hAwCYRwDPArv11lvldDoDNh8AAJbBWdsAAJhDADO7S5cu6tKlS57vp6Sk5Bhr166dtm7dmu85aXwDAMyDs8AAAAh+5DUAAOZg8czmUDwAAAAAAAAAwFI44xsAYB5cOg0AQPAjrwEAMAeLZzaNbwCAeVj8MiwAACyBvAYAwBwsntk0vgEA5mHxo9EAAFgCeQ0AgDlYPLNpfAMAzMPiR6MBALAE8hoAAHOweGbT+AYAmIfFj0YDAGAJ5DUAAOZg8cy29tYBAAAAAAAAAAodzvgGAJiHxS/DAgDAEshrAADMweKZTeMbAGAeFr8MCwAASyCvAQAwB4tnNo1vAIB5WDyUAQCwBPIaAABzsHhm0/gGAJhHiLUvwwIAwBLIawAAzMHimU3jGwBgHhY/Gg0AgCWQ1wAAmIPFM9vaWwcAAAAAAAAAKHQ44xsAYB4Wf+I0AACWQF4DAGAOFs9sGt8AAPOw+GVYAABYAnkNAIA5WDyzaXwDAMzD4kejAQCwBPIaAABzsHhmW7utDwCwFluIbwsAAPC/AOb12rVr1bVrV1WsWFE2m01Lly51e9/pdOrZZ59VhQoVFBoaqg4dOmjXrl0FuLEAAJiYxfevzVElAADS30ejfVkAAID/BTCvMzMz1ahRI73yyiu5vj9p0iS99NJLmj17tr755huVLFlSHTt21Llz5wpiSwEAMDeL719zqxMAgHmY5KgyAACFWgDzulOnTurUqVOu7zmdTk2fPl2jRo1St27dJEn//ve/FRUVpaVLl+qee+4JWJ0AAAQli+9jW3vrAAAAAACm4nA4dPr0abfF4XB4/T379u1TWlqaOnTo4BqLiIhQy5YttX79+oIsGQAABCEa3wAA8+BWJwAABD8f8zo5OVkRERFuS3JystdlpKWlSZKioqLcxqOiolzvAQBQqFl8/5pbnQAAzMPil2EBAGAJPuZ1UlKSEhMT3cbsdrtP3wkAAHJh8X1sGt8AAPMwyVFlAAAKNR/z2m63F0ijOzo6WpJ05MgRVahQwTV+5MgRNW7c2OfvBwDA9Cy+j23ttj4AwFpsIb4tAADA/4Ikr6tXr67o6GitXLnSNXb69Gl98803iouLK7B5AAAwrSDIa3/ijG8AgHmYJFwBACjUApjXGRkZ2r17t+v1vn37tG3bNpUtW1ZVq1bVkCFD9Nxzz6lWrVqqXr26nnnmGVWsWFHx8fEBqxEAgKBl8X1sGt8AAAAAAFPatGmT2rdv73p98d7gCQkJSklJ0VNPPaXMzEw99NBDSk9P1w033KDPPvtMJUqUMKpkAAAQINZu6wMArMWXJ05b/N5lAAAEjQDmdbt27eR0OnMsKSkp/78Um8aNG6e0tDSdO3dOX375pWrXru2HjQYAwIQClNdjxoyRzWZzW+rUqZPn+ikpKTnWz89Ba874BgCYh8UvwwIAwBLIawAAzCGAmV2/fn19+eWXrtdFi16+LR0eHq6dO3e6XtvycTIbjW8AgHlw1jYAAMGPvAYAwBwCmNlFixZVdHS0x+vbbDav1s8Nh+IBAObhyxOnOfsMAIDAIK8BADAHH/La4XDo9OnTbovD4chzql27dqlixYqqUaOGevfurYMHD162tIyMDMXExKhKlSrq1q2bfvjhB683j39VAADMg3t8AwAQ/MhrAADMwYe8Tk5OVkREhNuSnJyc6zQtW7ZUSkqKPvvsM82aNUv79u1TmzZt9Oeff+a6fmxsrN544w0tW7ZMb775prKzs9WqVSsdOnTIq83jVicAAAAAAAAAAI8lJSUpMTHRbcxut+e6bqdOnVz/v2HDhmrZsqViYmL07rvvqn///jnWj4uLU1xcnOt1q1atVLduXc2ZM0fjx4/3uEYa3wAA08jPwywAAEBgkdcAAJiDL5ltt9vzbHRfSenSpVW7dm3t3r3bo/WLFSumJk2aeLz+RdzqBABgGjabzacFAAD4H3kNAIA5GJXXGRkZ2rNnjypUqODR+llZWdq+fbvH619E4xsAYB42HxcAAOB/5DUAAOYQoLweNmyY1qxZo/3792vdunW68847VaRIEfXq1UuS1KdPHyUlJbnWHzdunL744gvt3btXW7Zs0X333acDBw5owIABXs3LrU4AAKbBWWAAAAQ/8hoAAHMIVGYfOnRIvXr10okTJxQZGakbbrhBGzZsUGRkpCTp4MGDCgn53/nZJ0+e1IMPPqi0tDSVKVNGzZo107p161SvXj2v5qXxDQAwDXakAQAIfuQ1AADmEKjMXrx48WXfX716tdvradOmadq0aT7Py61OAAAAAAAAAACWwhnfAADT4AwyAACCH3kNAIA5WD2zOeMbAGAavjxx2ttA/+2333TfffepXLlyCg0N1bXXXqtNmzb5acsAALCOQOY1AADIP6vnNWd8AwDMI0DZevLkSbVu3Vrt27fXihUrFBkZqV27dqlMmTKBKQAAADMzx74wAACweGbT+AYAmEagjiq/8MILqlKliubPn+8aq169ekDmBgDA7MxyFhgAAIWd1TObW50AAEzD10unHQ6HTp8+7bY4HI4c83z00Udq3ry5evToofLly6tJkyaaN2+eAVsMAID5cKsTAADMwep5TeMbAGAavu5IJycnKyIiwm1JTk7OMc/evXs1a9Ys1apVS59//rkeeeQRPfHEE1qwYIEBWw0AgLnQ+AYAwBysntfc6gQAUGgkJSUpMTHRbcxut+dYLzs7W82bN9eECRMkSU2aNNGOHTs0e/ZsJSQkBKRWAAAAAACQfzS+AQCm4etRZbvdnmuj+1IVKlRQvXr13Mbq1q2rDz74wKf5AQAoDMxyFhgAAIWd1TObxjcAwDwClMmtW7fWzp073cZ++eUXxcTEBKYAAADMzNr70AAAWIfFM5vGNwDANAJ1NHro0KFq1aqVJkyYoJ49e+rbb7/V3LlzNXfu3IDMDwCAmVn97DEAAKzC6plN4xsAYBqBCuUWLVpoyZIlSkpK0rhx41S9enVNnz5dvXv3Dsj8AACYmdV3ogEAsAqrZzaNbwCAaQQylLt06aIuXboEbD4AAKzC6jvRAABYhdUzO8ToAgAAAAAAAAAAKEic8Q0AMA9rH4wGAMAayGsAAMzB4plN4xsAYBpWvwwLAAArIK8BADAHq2c2jW8AgGlYPZQBALAC8hoAAHOwembT+AYAmIbVQxkAACsgrwEAMAerZzaNbwCAaVg9lAEAsALyGgAAc7B6ZocYXQAAAAAAAAAAAAWJM74BAOZh7YPRAABYA3kNAIA5WDyzaXwDAEzD6pdhAQBgBeQ1AADmYPXMpvENADANq4cyAABWQF4DAGAOVs9sGt8AANOweigDAGAF5DUAAOZg9cym8Q0AMA9rZzIAANZAXgMAYA4Wz2wa3/DYz5+OVUzFcjnGZ7+zVkMnvmtARYB3Nm/aqJQ3XtdPP+7QsWPHNO2lV3TTzR2MLgtesPrRaCA/Wje9RkP7dFDTelVVITJCPYfO1cerv3e93+2mRhpw1w1qUreqypUuqZZ3J+v7X34zsGLgyhYveksL5r+u48ePqXZsHT098hld27Ch0WXBQ+Q1cGWrPv1Aq5Z/qONHfpckVYqpoW69+qth81YGVwZ45vV5c7Qy9Qvt27dX9hIl1LhxEw1JHKZq1WsYXRq8YPXMDjG6AJjHDfdNVrUOSa7l9oEvS5I+TN1qcGWAZ86ePaPY2FgljRptdCkAUGBKhtq1/ZffNCT5nVzfvyq0uNZt26NRLy0NbGFAPn22YrlenJSshx8dpMXvLVFsbB098nB/nThxwujSAKDAlLm6vHr0fVRjZizQmBkLVLdhc80YP1y/HdhrdGmARzZt/FZ39+qthW+/qznz5uuvv/7SwAf768yZM0aXBrhwxjc8dvxkhtvrYf0aaM/BY/rP5l0GVQR454Y2bXVDm7ZGlwEfWP1oNJAfX/z3R33x3x/zfP/tTzdKkqpWKBuokgCfLFwwX93v6qn4O/9PkjRq9FitXbtaSz/8QP0ffMjg6uAJ8hq4siYt27i9vivhEX21/EPt/nmHKsVwxiyC36y5r7u9Hvf8RLVvE6effvxBzZq3MKgqeCtQmT1mzBiNHTvWbSw2NlY///xznp9577339Mwzz2j//v2qVauWXnjhBd1+++1ezcsZ38iXYkWL6J7bW2jBsvVGlwKgELHZbD4tAIDgduH8ef304w+6Pu5/l/qHhITo+utb6fvvuMrQLMhrwDvZWVnasOYLOc6dVc26DYwuB8iXjD//lCSFR0QYXAm8Eci8rl+/vg4fPuxavv766zzXXbdunXr16qX+/ftr69atio+PV3x8vHbs2OHVnIae8X38+HG98cYbWr9+vdLS0iRJ0dHRatWqlfr27avIyEgjy8Nl3NG+oUqHherNj78xuhQAhQg7w8YhswEEwsn0k8rKylK5cu7PlSlXrpz27ePyf7Mgr41DXpvLr/t367knB+jC+fOyh4bq8VEvqFJVzvaG+WRnZ2vSCxPUuElT1apV2+hy4IVAZnbRokUVHR3t0bozZszQbbfdpuHDh0uSxo8fr9TUVM2cOVOzZ8/2eE7DzvjeuHGjateurZdeekkRERG68cYbdeONNyoiIkIvvfSS6tSpo02bNl3xexwOh06fPu22OLOzArAFhVtCfCt9/t8fdfjYKaNLAVCY2HxckC8FkdnkNQAUIuS1Ify5j33e4QjAFhQ+FSrFaNzLC/Xs1Nd10+3d9drUcfrtIAf5YD4TnhurPbt2adKL04wuBd7yIa9zywvHZfJi165dqlixomrUqKHevXvr4MGDea67fv16dejQwW2sY8eOWr/euztPGHbG9+OPP64ePXpo9uzZOY4uOJ1ODRw4UI8//vgVNyg5OTnHPWKKRLVQsQrXFXjN+FvVCmV0U8tY3TNsntGlAChkOIPMGAWR2eQ1AE+UKV1GRYoUyfEgyxMnTujqq682qCp4i7w2hj/3sR94fIQGPPF0gddc2BUtVkxRFatIkqrVqqt9v/yk1GXvqO/jSQZXBnhuwnPjtHbNar2x4E1FeXg2L4KHL5mdW16MHj1aY8aMybFuy5YtlZKSotjYWB0+fFhjx45VmzZttGPHDoWFheVYPy0tTVFRUW5jUVFRrquZPGXYGd/fffedhg4dmusP2GazaejQodq2bdsVvycpKUmnTp1yW4pGNfNDxbjo/jvidPSPP7XiPz8YXQoAIAAKIrPJawCeKFa8uOrWq69vNvyvMZedna1vvlmvho2aGFgZEPz8uY/d5+GhfqgYl3I6s3XhwgWjywA84nQ6NeG5cVq1MlXz3ligypWrGF0SAiy3vEhKyv3AXadOndSjRw81bNhQHTt21PLly5Wenq53333XrzUadsZ3dHS0vv32W9WpUyfX97/99tscnf3c2O122e12tzFbSJECqRE52Ww29el2vd765BtlZWUbXQ7glTOZmW6X0vx26JB+/uknRUREqELFigZWBk9xBpkxCiKzyWv/KRlaXNdU+d89W6tVKqeGtSvp5Okz+jXtpMqEX6Uq0WVUofzfDxqqXe3vP6sjJ07ryIk/DakZuJz7E/rpmZEjVL9+AzW4tqHeXLhAZ8+eVfyd3Y0uDR4ir43hz33s4nb2/QraeymvqGHzViobGaVzZ89ow+rP9fP2LXpy/AyjSwM8MmH8WK1Y/ommv/yqSl5VUsePHZMklQoLU4kSJQyuDp7yJbNzywtPlS5dWrVr19bu3btzfT86OlpHjhxxGzty5IjH9wi/yLDG97Bhw/TQQw9p8+bNuvnmm10BfOTIEa1cuVLz5s3Tiy++aFR5yMNNLWNVtUJZLVi6wehSAK/98MMODejXx/X6xUnJkqQ7ut2p8RMmGlUWvMB+tDHI7ODWtF6MvnhtsOv1pGH/J0la+NEGPTT6TXVue63mjbvf9f7CFx6QJD03e7men7M8sMUCHrit0+06+ccfenXmSzp+/Jhi69TVq3NeUzludWIagcrrrKwsjRkzRm+++abS0tJUsWJF9e3bV6NGjSqUzXfy2lxOp5/U3CljdeqP4wotWUpVqtXUk+NnqEGTlkaXBnjk3XfeliT173u/2/i455LVjYPVpmFUXGZkZGjPnj26//77c30/Li5OK1eu1JAhQ1xjqampiouL82oem9PpdPpSqC/eeecdTZs2TZs3b1ZW1t8PuCpSpIiaNWumxMRE9ezZM1/fG9rksYIsEwi4kxtnGl0C4JMSfjqsWmv4Zz59ftfk2wqoksLHH5lNXsPsyGuYndnzesKECZo6daoWLFig+vXra9OmTerXr5+ef/55PfHEEz7VYFb+2sdevzu9AKsEAq9JtdJGlwD4JBgz25v962HDhqlr166KiYnR77//rtGjR2vbtm368ccfFRkZqT59+qhSpUpKTv77BMV169apbdu2mjhxojp37qzFixdrwoQJ2rJlixo0aODxvIad8S1Jd999t+6++25duHBBx48flyRdffXVKlasmJFlAQCCVCE8eStokNkAAE8FKq/XrVunbt26qXPnzpKkatWq6e2339a3334bmAKCEHkNAPBGoDL70KFD6tWrl06cOKHIyEjdcMMN2rBhgyIj/75l48GDBxUS8r9HUbZq1UqLFi3SqFGjNHLkSNWqVUtLly71quktGdz4vqhYsWKqUKGC0WUAAIJcYbxsOdiQ2QCAK/E1rx0OhxwOh9tYbvcRbdWqlebOnatffvlFtWvX1nfffaevv/5aU6dO9Wl+KyCvAQCeCNQ+9uLFiy/7/urVq3OM9ejRQz169PBp3pArrwIAAAAAQGAkJycrIiLCbbl46fM/Pf3007rnnntUp04dFStWTE2aNNGQIUPUu3dvA6oGAADBJijO+AYAwBOc8A0AQPDzNa+TkpKUmJjoNnbp2d6S9O677+qtt97SokWLVL9+fW3btk1DhgxRxYoVlZCQ4FsRAAAUAlbfx6bxDQAwjZAQi6cyAAAW4Gte53Zbk9wMHz7cdda3JF177bU6cOCAkpOTaXwDAOABq+9j0/gGAJiG1Y9GAwBgBYHK6zNnzrg9CEuSihQpouzs7MAUAACAyVl9H5vGNwDANHi4JQAAwS9Qed21a1c9//zzqlq1qurXr6+tW7dq6tSpeuCBBwIyPwAAZmf1fWwa3wAA07B4JgMAYAmByuuXX35ZzzzzjB599FEdPXpUFStW1MMPP6xnn302MAUAAGByVt/HpvENAAAAADCdsLAwTZ8+XdOnTze6FAAAEIRofAMATMPql2EBAGAF5DUAAOZg9cym8Q0AMA2rhzIAAFZAXgMAYA5Wz2wa3wAA07B4JgMAYAnkNQAA5mD1zKbxDQAwDasfjQYAwArIawAAzMHqmU3jGwBgGhbPZAAALIG8BgDAHKye2TS+AQCmYfWj0QAAWAF5DQCAOVg9s0OMLgAAAAAAAAAAgIJE4xsAYBo2m2+Lp8aMGSObzea21KlTx38bBgCAhQQqrwEAgG+sntfc6gQAYBqBvAyrfv36+vLLL12vixYlMgEA8ITVL5sGAMAqrJ7Z7MUDAEwjkJlctGhRRUdHB25CAAAswuL70AAAWIbVM5tbnQAATOPS2494u3hj165dqlixomrUqKHevXvr4MGDftoqAACsJZB5DQAA8s/qec0Z3wAA0/A1Wx0OhxwOh9uY3W6X3W53G2vZsqVSUlIUGxurw4cPa+zYsWrTpo127NihsLAw34oAAMDiTLIvDABAoWf1zOaMbwBAoZGcnKyIiAi3JTk5Ocd6nTp1Uo8ePdSwYUN17NhRy5cvV3p6ut59910DqgYAAAAAAN7ijG8AgGn4ejlVUlKSEhMT3cYuPds7N6VLl1bt2rW1e/dun+YHAKAwMMvlzwAAFHZWz2wa3wAA0/A1k3O7rYknMjIytGfPHt1///2+FQAAQCFg8X1oAAAsw+qZTeMbAGAagToaPWzYMHXt2lUxMTH6/fffNXr0aBUpUkS9evUKyPwAAJiZ1c8eAwDAKqye2TS+AQCmEahMPnTokHr16qUTJ04oMjJSN9xwgzZs2KDIyMjAFAAAgIlZfB8aAADLsHpm0/gGAJhGoI5GL168OCDzAABgRVY/ewwAAKuwemaHGF0AAAAAAAAAAAAFiTO+AQCmYfWj0QAAWAF5DQCAOVg9sznjGwBgGjabbwsAAPA/8hoAAHMwIq8nTpwom82mIUOG5LlOSkqKbDab21KiRAmv5+KMbwCAaVj9aDQAAFZAXgMAYA6BzuyNGzdqzpw5atiw4RXXDQ8P186dO12v81MrZ3wDAEyDM8gAAAh+5DUAAOYQyLzOyMhQ7969NW/ePJUpU8aD2myKjo52LVFRUV7PSeMbAGAal17q5O0CAAD8j7wGAMAcfMlrh8Oh06dPuy0OhyPPuQYNGqTOnTurQ4cOHtWWkZGhmJgYValSRd26ddMPP/zg9fbR+AYAmAZnkAEAEPzIawAAzMGXvE5OTlZERITbkpycnOs8ixcv1pYtW/J8/1KxsbF64403tGzZMr355pvKzs5Wq1atdOjQIa+2j3t8AwAAAAAAAAA8lpSUpMTERLcxu92eY71ff/1VgwcPVmpqqscPqIyLi1NcXJzrdatWrVS3bl3NmTNH48eP97hGGt8AANMI4TQwAACCHnkNAIA5+JLZdrs910b3pTZv3qyjR4+qadOmrrGsrCytXbtWM2fOlMPhUJEiRS77HcWKFVOTJk20e/dur2qk8Q0AMA32owEACH7kNQAA5hCIzL755pu1fft2t7F+/fqpTp06GjFixBWb3tLfjfLt27fr9ttv92puGt8AANPggVcAAAQ/8hoAAHMIRGaHhYWpQYMGbmMlS5ZUuXLlXON9+vRRpUqVXPcAHzdunK6//nrVrFlT6enpmjx5sg4cOKABAwZ4NTeNbwCAaYSwHw0AQNAjrwEAMIdgyeyDBw8qJCTE9frkyZN68MEHlZaWpjJlyqhZs2Zat26d6tWr59X30vgGAJgGZ5ABABD8yGsAAMzBqMxevXr1ZV9PmzZN06ZN83mekCuvAgAAAAAAAACAeXDGNwDANDiBDACA4EdeAwBgDlbPbBrfAADTsMniqQwAgAWQ1wAAmIPVM5vGNwDANILlwRsAACBv5DUAAOZg9cym8Q0AMA0elgUAQPAjrwEAMAerZzaNbwCAaVg8kwEAsATyGgAAc7B6ZocYXQAAAAAAAAAAAAWJM74BAKYRYvXD0QAAWAB5DQCAOVg9s2l8AwBMw+KZDACAJZDXAACYg9Uzm8Y3AMA0rP7gDQAArIC8BgDAHKye2TS+AQCmYfFMBgDAEshrAADMweqZTeMbAGAaVr//GAAAVkBeAwBgDlbPbI8a3x999JHHX3jHHXfkuxgAAJB/5DUAAMGPvAYAIDA8anzHx8d79GU2m01ZWVm+1AMAQJ6sfSzad+Q1ACAYBDKvf/vtN40YMUIrVqzQmTNnVLNmTc2fP1/NmzcPYBXeIa8BAMHC6vvYHjW+s7Oz/V0HAABXZPUHb/iKvAYABINA5fXJkyfVunVrtW/fXitWrFBkZKR27dqlMmXKBGT+/CKvAQDBwur72NzjGwBgGiHWzmQAACwhUHn9wgsvqEqVKpo/f75rrHr16oGZHAAAC7D6Pna+Gt+ZmZlas2aNDh48qPPnz7u998QTTxRIYQAAXMrqR6MLGnkNADBCoPL6o48+UseOHdWjRw+tWbNGlSpV0qOPPqoHH3wwIPMXFPIaAGAUq+9je9343rp1q26//XadOXNGmZmZKlu2rI4fP66rrrpK5cuXJ5gBAH5j8UwuUOQ1AMAovua1w+GQw+FwG7Pb7bLb7W5je/fu1axZs5SYmKiRI0dq48aNeuKJJ1S8eHElJCT4VkSAkNcAACNZfR87xNsPDB06VF27dtXJkycVGhqqDRs26MCBA2rWrJlefPFFf9QIAICkv49G+7IUJuQ1AMAovuZ1cnKyIiIi3Jbk5OQc82RnZ6tp06aaMGGCmjRpooceekgPPvigZs+ebcBW5w95DQAwktX3r71ufG/btk1PPvmkQkJCVKRIETkcDlWpUkWTJk3SyJEj/VEjAADwEnkNADCrpKQknTp1ym1JSkrKsV6FChVUr149t7G6devq4MGDgSrVZ+Q1AAD+43Xju1ixYgoJ+ftj5cuXd/2jIiIiQr/++mvBVgcAwD+E2HxbChPyGgBgFF/z2m63Kzw83G259DYnktS6dWvt3LnTbeyXX35RTExMoDbVZ+Q1AMBIVt+/9voe302aNNHGjRtVq1YttW3bVs8++6yOHz+uhQsXqkGDBv6oEQAASdZ/8EZBIq8BAEYJVF4PHTpUrVq10oQJE9SzZ099++23mjt3rubOnRuQ+QsCeQ0AMJLV97G9PuN7woQJqlChgiTp+eefV5kyZfTII4/o2LFjpvoHBgDAfGw+LoUJeQ0AMEqg8rpFixZasmSJ3n77bTVo0EDjx4/X9OnT1bt374LbGD8jrwEARrL6/rXXZ3w3b97c9f/Lly+vzz77rEALAgAgLyEWPxpdkMhrAIBRApnXXbp0UZcuXQI2X0EjrwEARrL6PrbXjW8AAIxi8UwGAMASyGsAAMzB6pntdeO7evXql73/y969e30qCAAA+I68BgAg+JHXAAD4j9eN7yFDhri9vnDhgrZu3arPPvtMw4cPL6i6AADIweoP3ihI5DUAwCjktefIawCAkaye2V43vgcPHpzr+CuvvKJNmzb5XBAAAHkxKpMnTpyopKQkDR48WNOnTzemCC+R1wAAo1h8H7pAkdcAACMZkdme7l+/9957euaZZ7R//37VqlVLL7zwgm6//Xav5grxsVaXTp066YMPPiiorwMAIIcQm82nJT82btyoOXPmqGHDhgW8NcYgrwEA/mZEXlsNeQ0ACIRg3b9et26devXqpf79+2vr1q2Kj49XfHy8duzY4d325avKXLz//vsqW7ZsQX0dAAA52Gy+Ld7KyMhQ7969NW/ePJUpU6bgN8gA5DUAwN8CnddWRF4DAAIhWPevZ8yYodtuu03Dhw9X3bp1NX78eDVt2lQzZ870ak6vb3XSpEkTt/u/OJ1OpaWl6dixY3r11Ve9/ToAADwW6PuPDRo0SJ07d1aHDh303HPPBXRuX5HXAACjWP1+oQWJvAYAGCmQme3N/vX69euVmJjoNtaxY0ctXbrUqzm9bnx369bN7YcSEhKiyMhItWvXTnXq1PH26wAACBiHwyGHw+E2ZrfbZbfbc6y7ePFibdmyRRs3bgxUeQWKvAYAIPiR1wAAs/Ln/nVaWpqioqLcxqKiopSWluZVjV43vseMGePtRwJuYcq/jC4B8MknPxw2ugTAJ3c1quCX7/X1/lzJyckaO3as29jo0aNzZNuvv/6qwYMHKzU1VSVKlPBxVmOYIa/3fDXV6BIAn+w+kmF0CYBPGlQq5ZfvLbD7aRYCZshrSbqpxyijSwB8suo9c129CVwqrmZpv3yvL5lthv1rrxvfRYoU0eHDh1W+fHm38RMnTqh8+fLKysoqsOIAAPgnXy/DSkpKynG5VG5Hozdv3qyjR4+qadOmrrGsrCytXbtWM2fOlMPhUJEiRXyqxd/IawCAUbjViefIawCAkXzJbH/uX0dHR+vIkSNuY0eOHFF0dLRXNXrd+HY6nbmOOxwOFS9e3NuvAwDAYyE+7kfnddnVpW6++WZt377dbaxfv36qU6eORowYEfRNb4m8BgAYx9e8LkzIawCAkXzJbH/uX8fFxWnlypUaMmSIayw1NVVxcXFe1ehx4/ull16S9PeRgNdee02lSv3vsriLXXruQQYA8KdA7UiHhYWpQYMGbmMlS5ZUuXLlcowHG/IaAGA0Gt9XRl4DAIJBIDLbk/3rPn36qFKlSkpOTpYkDR48WG3bttWUKVPUuXNnLV68WJs2bdLcuXO9mtvjxve0adMk/X1Eevbs2W7d+OLFi6tatWqaPXu2V5MDAOANLp2+MvIaAGA08vrKyGsAQDAIlsw+ePCgQkL+d8fxVq1aadGiRRo1apRGjhypWrVqaenSpV6fiOZx43vfvn2SpPbt2+vDDz9UmTJlvJoIAABfGXkG2erVq42b3AvkNQDAaJzxfWXkNQAgGBiV2ZfuX+e2v92jRw/16NHDp3m8vsf3V1995dOEAADA/8hrAACCH3kNAID/hFx5FXf/93//pxdeeCHH+KRJk3zuwgMAcDk2m29LYUJeAwCMQl57jrwGABjJ6nntdeN77dq1uv3223OMd+rUSWvXri2QogAAyE2IzebTUpiQ1wAAo5DXniOvAQBGsnpee32rk4yMDBUvXjzHeLFixXT69OkCKQoAgNx4fbS2ECOvAQBGIa89R14DAIxk9cz2evuuvfZavfPOOznGFy9erHr16hVIUQAA5IZLpz1HXgMAjEJee468BgAYyep57fUZ388884y6d++uPXv26KabbpIkrVy5UosWLdL7779f4AUCAHCRWS6nCgbkNQDAKOS158hrAICRrJ7ZXje+u3btqqVLl2rChAl6//33FRoaqkaNGmnVqlUqW7asP2oEAABeIq8BAAh+5DUAAP7jdeNbkjp37qzOnTtLkk6fPq23335bw4YN0+bNm5WVlVWgBQIAcJHFD0YXOPIaAGAE8to75DUAwChWz+x838N87dq1SkhIUMWKFTVlyhTddNNN2rBhQ0HWBgCAmxCbb0thRF4DAAKNvPYeeQ0AMILV89qrM77T0tKUkpKi119/XadPn1bPnj3lcDi0dOlSHrwBAPA7q99/rKCQ1wAAI5HXniGvAQBGs3pme3zGd9euXRUbG6vvv/9e06dP1++//66XX37Zn7UBAODGlydOWzzPXchrAIDRyOsrI68BAMHA6nnt8RnfK1as0BNPPKFHHnlEtWrV8mdNAADkyiyXUxmJvAYAGI28vjLyGgAQDKye2R6f8f3111/rzz//VLNmzdSyZUvNnDlTx48f92dtAADAS+Q1AADBj7wGAMD/PG58X3/99Zo3b54OHz6shx9+WIsXL1bFihWVnZ2t1NRU/fnnn/6sEwAA2Xz8X2FAXgMAjEZeXxl5DQAIBlbPa48b3xeVLFlSDzzwgL7++mtt375dTz75pCZOnKjy5cvrjjvu8EeNAABI8u2J01a/hOtS5DUAwCjktefIawCAkaye1143vv8pNjZWkyZN0qFDh/T2228XVE0AAOSKHen8Ia8BAIFEXucPeQ0ACDSr57XHD7e8nCJFiig+Pl7x8fEF8XUAAOTKZpZHRwcp8hoAEAjktW/IawBAoFg9swuk8Q0AQCCY5agyAACFGXkNAIA5WD2zaXwDAEzD4gejAQCwBPIaAABzsHpm+3SPbwAAAAAAAAAAgg1nfAMATCPE6oejAQCwAPIaAABzsHpm0/gGAJiG1e8/BgCAFZDXAACYg9Uzm8Y3AMA0LH4wGgAASyCvAQAwB6tnNo1vAIBphMjiqQwAgAWQ1wAAmIPVM5vGNwDANKx+NBoAACsgrwEAMAerZ3aI0QUAAAAAAAAAAFCQOOMbAGAaVn/wBgAAVkBeAwBgDlbPbM74BgCYRojN5tMCAAD8j7wGAMAcApXXs2bNUsOGDRUeHq7w8HDFxcVpxYoVea6fkpIim83mtpQoUcLr7eOMbwCAabAvDABA8COvAQAwh0BlduXKlTVx4kTVqlVLTqdTCxYsULdu3bR161bVr18/18+Eh4dr586d/6jV+2JpfAMATIOzwAAACH7kNQAA5hCozO7atavb6+eff16zZs3Shg0b8mx822w2RUdH+zQvtzoBAJiGzebbAgAA/I+8BgDAHIzI66ysLC1evFiZmZmKi4vLc72MjAzFxMSoSpUq6tatm3744Qev56LxDQAAAAAwvYkTJ8pms2nIkCFGlwIAgOU5HA6dPn3abXE4HHmuv337dpUqVUp2u10DBw7UkiVLVK9evVzXjY2N1RtvvKFly5bpzTffVHZ2tlq1aqVDhw55VSONbwCAaYT4uAAAAP8zIq83btyoOXPmqGHDhr4VDwBAIeJLXicnJysiIsJtSU5OznOu2NhYbdu2Td98840eeeQRJSQk6Mcff8x13bi4OPXp00eNGzdW27Zt9eGHHyoyMlJz5szxavu4xzcAwDTy8zALAAAQWIHO64yMDPXu3Vvz5s3Tc889F9C5AQAwM18yOykpSYmJiW5jdrs9z/WLFy+umjVrSpKaNWumjRs3asaMGR41s4sVK6YmTZpo9+7dXtXICXAAANOw+bgAAAD/8zWvvb10etCgQercubM6dOjgx60CAMB6fMlru92u8PBwt+Vyje9LZWdnXzbf/ykrK0vbt29XhQoVPP5+icY3AMBEQmw2nxYAAOB/vua1N5dOL168WFu2bLnspdUAACB3gdq/TkpK0tq1a7V//35t375dSUlJWr16tXr37i1J6tOnj5KSklzrjxs3Tl988YX27t2rLVu26L777tOBAwc0YMAAr+blVicAANOgdQ0AQPDzNa89vXT6119/1eDBg5WamqoSJUr4OCsAAIVPoPaxjx49qj59+ujw4cOKiIhQw4YN9fnnn+uWW26RJB08eFAhIf87P/vkyZN68MEHlZaWpjJlyqhZs2Zat25dng/DzAuNbwAAAABA0LDb7R5dKr1582YdPXpUTZs2dY1lZWVp7dq1mjlzphwOh4oUKeLPUgEAgAdef/31y76/evVqt9fTpk3TtGnTfJ6XxjcAwDS4WwkAAMEvUHl98803a/v27W5j/fr1U506dTRixAia3gAAXIHV97FpfAMATMOXJ04DAIDACFReh4WFqUGDBm5jJUuWVLly5XKMAwCAnKy+j83DLQEAphHi4+KpWbNmqWHDhq4nU8fFxWnFihUFtyEAAFhYoPIaAAD4xup5zRnfAADTCNTR6MqVK2vixImqVauWnE6nFixYoG7dumnr1q2qX79+QGoAAMCsjDx77NJ7hAIAgLxZ/YxvGt8AANMIVCR37drV7fXzzz+vWbNmacOGDTS+AQC4AmvvQgMAYB1Wz2wa3wAA0/D1aLTD4ZDD4XAbs9vtstvteX4mKytL7733njIzMxUXF+fT/AAAFAZWP3sMAACrsHpmm+WWLAAA+Cw5OVkRERFuS3Jycq7rbt++XaVKlZLdbtfAgQO1ZMkS1atXL8AVAwAAAACA/OCMbwCAafh6tDYpKUmJiYluY3md7R0bG6tt27bp1KlTev/995WQkKA1a9bQ/AYA4Ao4uwoAAHOwembT+AYAmIavl2Fd6bYm/1S8eHHVrFlTktSsWTNt3LhRM2bM0Jw5c3yqAQAAq7P6ZdMAAFiF1TObxjcAwDSMjOTs7Owc9wcHAAA5WXsXGgAA67B6ZtP4BgCYRqAORiclJalTp06qWrWq/vzzTy1atEirV6/W559/HpgCAAAwMYufPAYAgGVYPbNpfAMATCMkQMejjx49qj59+ujw4cOKiIhQw4YN9fnnn+uWW24JyPwAAJhZoPIaAAD4xuqZTeMbAIBLvP7660aXAAAAAAAAfEDjGwBgGla/DAsAACsgrwEAMAerZzaNbwCAadgsfhkWAABWQF4DAGAOVs9sGt8AANOw+tFoAACsgLwGAMAcrJ7ZNL4BAKZh9QdvAABgBeQ1AADmYPXMpvENADANqx+NBgDACshrAADMweqZHWJ0AQAAAAAAAAAAFCTO+AYAmIbVj0YDAGAF5DUAAOZg9cym8Q0AMA2rP3EaAAArIK8BADAHq2c2jW8AgGmEWDuTAQCwBPIaAABzsHpm0/gGAJiG1Y9GAwBgBeQ1AADmYPXMpvENADANq99/DAAAKyCvAQAwB6tnNo1vAIBpWP1oNAAAVkBeAwBgDlbP7BCjCwAAAAAAAAAAoCBxxjc88s0Xy/TNF8uUfixNklS+cjW1vytBsU1aGlwZ4Bl+h63B6g/eAArCd1s36Z03U/TLzz/qxPFjGj9pum5oe7PRZQEe+3DRG9rwn6/028H9Km63K7Z+Q93/4BOqVLWa0aXBQ+Q14JmKkRF6bnA33dq6vq4qUUx7fj2uh8e8qS0/HjS6NOCKVn36gVYt/1DHj/wuSaoUU0PdevVXw+atDK4M3rB6ZnPGNzwSXjZSHe99SI9OnKtHk+eoRoOmemvSv3Tk131GlwZ4hN9ha7D5+D+gMDh39qyuqVVbg4f/y+hSgHz54bstuq1bDyXPTNHoya8q66+/NO6pQTp39qzRpcFD5DVwZaXDQrUqJVEX/spW/GOvqsn/Pa+np36ok6fPGF0a4JEyV5dXj76PasyMBRozY4HqNmyuGeOH67cDe40uDV4IVF7PmjVLDRs2VHh4uMLDwxUXF6cVK1Zc9jPvvfee6tSpoxIlSujaa6/V8uXLvd4+zviGR+pecsTu1l4D9O0Xy/Trrh8VVaW6QVUBnuN32Bqs/uANoCC0bNVGLVu1MboMIN+eeWGm2+vHRozVA907aM8vP6l+o6YGVQVvkNfAlT3Z7xYdSjuph8e86Ro78PsJAysCvNOkpfu/N+9KeERfLf9Qu3/eoUoxNQyqCt4KVGZXrlxZEydOVK1ateR0OrVgwQJ169ZNW7duVf369XOsv27dOvXq1UvJycnq0qWLFi1apPj4eG3ZskUNGjTweF7O+IbXsrOz9P1/V+q845yq1s75ywkEO36Hzcvm4wIAMJ8zmRmSpLDwcIMrgafIa+DKOre9Vlt+PKi3Jj2gAyuTtf7tEep3J7eIgDllZ2Vpw5ov5Dh3VjXret6UhPECldddu3bV7bffrlq1aql27dp6/vnnVapUKW3YsCHX9WfMmKHbbrtNw4cPV926dTV+/Hg1bdpUM2fOzHX9vAT1Gd+//vqrRo8erTfeeMPoUiAp7eBezfnXo/rrwnkVLxGq3sPGq3zlakaXBXiM32HzC+EUsqBEXgPwl+zsbM1/5UXVadBIVavXNLoceIi8Dk7kdXCpXulqPdijjV56c5Umvf6FmtWP0ZSn7tL5v7L01sffGF0e4JFf9+/Wc08O0IXz52UPDdXjo15Qpaqc7W0mRmR2VlaW3nvvPWVmZiouLi7XddavX6/ExES3sY4dO2rp0qVezRXUZ3z/8ccfWrBgwWXXcTgcOn36tNty4bwjQBUWLldXrKLHJr+mgRNm6bpbu+n9V5J19NB+o8sCPMbvMOAf+c1rh4O8BnB582ZM1MF9e5T4TLLRpQCm50leS7lntjM7KwAVFi4hITZt+/lXjZ75sb7beUhvfPhfzV+yTg/edYPRpQEeq1ApRuNeXqhnp76um27vrtemjtNvB7nHd2Hh7T7e9u3bVapUKdntdg0cOFBLlixRvXr1cl03LS1NUVFRbmNRUVFKS0vzqkZDz/j+6KOPLvv+3r1X/o8lOTlZY8eOdRvr8XCiej4yzKfakFPRosVULrqyJKlSjVj9tudnrVv+geIfetLgygDP8Dtsfpw/Zgx/5XXiiFF68ulnfKoNgHXNm/GCNm/4WuOnz1O5yKgrfwBBg7w2RkHktZR7ZheJaqFiFa7Ld23IKe34af20172B8/O+NMXf3NiYgoB8KFqsmKIqVpEkVatVV/t++Umpy95R38eTDK4MnvIls3PLi9GjR2vMmDG5rh8bG6tt27bp1KlTev/995WQkKA1a9bk2fwuCIY2vuPj42Wz2eR0OvNcx3aFU+6TkpJynPr+6c4/CqQ+XJ4z26m/Lpw3ugwg3/gdNiH2pA3hr7w+cZY/UAA5OZ1OvfbSJH379VcaO22uoipUMrokeIu/3g1REHkt5Z7Z5duM8Lk+uFu/ba9qx5R3G6tVtbwOHqafAfNyOrN14cIFo8uAN3zI7Nzywm6357l+8eLFVbPm37eua9asmTZu3KgZM2Zozpw5OdaNjo7WkSNH3MaOHDmi6Ohor2o09FYnFSpU0Icffqjs7Oxcly1btlzxO+x2u8LDw92WYsXz/iEjfz5fNFf7fvxOJ48eVtrBvf//9TY1bnOL0aUBHuF32BpsPv4P+eOvvL7cP4qQf2fPnNHuX37W7l9+liQd/v037f7lZx1JO2xwZYBn5s2YqLVfLteQUc8r9KqrdPKP4zr5x3E5HOeMLg0eIq+NURB5LeWe2baQIn6uvvB5+c1Vuu7a6hr+wK2qUeVq3X1bcz3wf6015521RpcGeOS9lFe0c8dWHTvyu37dv1vvpbyin7dvUVz7jkaXBi/4kte+7uNlZ2fneWuUuLg4rVy50m0sNTU1z3uC58XQM76bNWumzZs3q1u3brm+f6Wj1QiczFPpev+VCfrz5B8qcVVJRcfUUN9/TVbNhs2NLg3wCL/D1sCzsoxBXpvLzp9+0NBHH3C9fnX6ZElSx8536OlnnzeqLMBjn3/0viTp2aEPuY0Pemq0brrtDiNKgpfIa2OQ1+ay+ceDuvvJeRr3+B0a+VAn7f/thIZP/kCLV2wyujTAI6fTT2rulLE69cdxhZYspSrVaurJ8TPUoElLo0uDFwKV2UlJSerUqZOqVq2qP//8U4sWLdLq1av1+eefS5L69OmjSpUqKTn57+e6DB48WG3bttWUKVPUuXNnLV68WJs2bdLcuXO9mtfQxvfw4cOVmZmZ5/s1a9bUV199FcCKkJfujzxldAmAT/gdtgb2o41BXptL42Yt9NU3240uA8i3D1ZtNroE+Ii8NgZ5bT4r/rNDK/6zw+gygHzpP2SU0SWgAAQqs48ePao+ffro8OHDioiIUMOGDfX555/rllv+vgr/4MGDCgn5341JWrVqpUWLFmnUqFEaOXKkatWqpaVLl6pBgwZezWtzWvCQ7/vfcSkvABjprkYV/PK9G/ee8unzLWpEFFAlKAi/p3OPfZjbH5n8DsPcGlQq5ZfvJa+tJ7TJY0aXAPhk1XvPGV0C4JO4mqX98r2+ZLYZ8trQM74BAPAKp5ABABD8yGsAAMzB4plN4xsAYBo88AoAgOBHXgMAYA5Wz2wa3wAA0+BhWQAABD/yGgAAc7B6ZtP4BgCYhsUzGQAASyCvAQAwB6tnNo1vAIB5WD2VAQCwAvIaAABzsHhmhxhdAAAAAAAAAAAABYkzvgEApmH1B28AAGAF5DUAAOZg9cym8Q0AMA2rP3gDAAArIK8BADAHq2c2jW8AgGlYPJMBALAE8hoAAHOwembT+AYAmIfVUxkAACsgrwEAMAeLZzYPtwQAmIbNx/8BAAD/C1ReJycnq0WLFgoLC1P58uUVHx+vnTt3+nHLAACwFqvvX9P4BgCYhs3m2wIAAPwvUHm9Zs0aDRo0SBs2bFBqaqouXLigW2+9VZmZmf7bOAAALMTq+9fc6gQAAAAAYDqfffaZ2+uUlBSVL19emzdv1o033mhQVQAAIFjQ+AYAmIZJDioDAFCo+ZrXDodDDofDbcxut8tut1/2c6dOnZIklS1b1scKAAAoHKy+j82tTgAA5mHzcfEQ9wwFAMAHPuZ1cnKyIiIi3Jbk5OTLTpmdna0hQ4aodevWatCggb+2DAAAawnA/rWROOMbAGAagXqAxsV7hrZo0UJ//fWXRo4cqVtvvVU//vijSpYsGZAaAAAwK1/zOikpSYmJiW5jVzrbe9CgQdqxY4e+/vprn+YGAKAwMctDKvOLxjcAwDQC9QAN7hkKAED++ZrXntzW5J8ee+wxffLJJ1q7dq0qV67s2+QAABQiZnlIZX7R+AYAmIZRmcw9QwEA8Fyg8trpdOrxxx/XkiVLtHr1alWvXj1AMwMAYA0W73vT+AYAFB75eVgW9wwFACA4DRo0SIsWLdKyZcsUFhamtLQ0SVJERIRCQ0MNrg4AABiNh1sCAMzDgIdlXbxn6OLFi/21VQAAWEuAHkY9a9YsnTp1Su3atVOFChVcyzvvvFOAGwMAgIXxcEsAAIJDoB+WxT1DAQDwXqAelOV0OgMyDwAAVsXDLQEACBKBelgW9wwFACD/rP6gLAAArMLqmU3jGwBgGoHKZO4ZCgBA/ll8HxoAAMuwemZzj28AgHlwz1AAAIJfgPIaAAD4yOJ5zRnfAABcgnuGAgAAAABgbjS+AQCmYfUHbwAAYAXkNQAA5mD1zKbxDQAwDas/eAMAACsgrwEAMAerZzb3+AYAmAa3DAUAIPiR1wAAmEOg8jo5OVktWrRQWFiYypcvr/j4eO3cufOyn0lJSZHNZnNbSpQo4dW8NL4BAObBnjQAAMGPvAYAwBwClNdr1qzRoEGDtGHDBqWmpurChQu69dZblZmZednPhYeH6/Dhw67lwIEDXs3LrU4AAKZh9fuPAQBgBeQ1AADmEKjM/uyzz9xep6SkqHz58tq8ebNuvPHGPD9ns9kUHR2d73k54xsAYBo2m28LAADwP/IaAABzMCqvT506JUkqW7bsZdfLyMhQTEyMqlSpom7duumHH37wah4a3wAAAAAAAAAAjzkcDp0+fdptcTgcV/xcdna2hgwZotatW6tBgwZ5rhcbG6s33nhDy5Yt05tvvqns7Gy1atVKhw4d8rhGGt8AANPglqEAAAQ/8hoAAHPwJa+Tk5MVERHhtiQnJ19xzkGDBmnHjh1avHjxZdeLi4tTnz591LhxY7Vt21YffvihIiMjNWfOHI+3j3t8AwDMg71hAACCH3kNAIA5+JDZSUlJSkxMdBuz2+2X/cxjjz2mTz75RGvXrlXlypW9mq9YsWJq0qSJdu/e7fFnaHwDAEyDh2UBABD8yGsAAMzBl8y22+1XbHRf5HQ69fjjj2vJkiVavXq1qlev7vV8WVlZ2r59u26//XaPP0PjGwBgGjzwCgCA4EdeAwBgDoHK7EGDBmnRokVatmyZwsLClJaWJkmKiIhQaGioJKlPnz6qVKmS63Yp48aN0/XXX6+aNWsqPT1dkydP1oEDBzRgwACP56XxDQAwDfajAQAIfuQ1AADmEKjMnjVrliSpXbt2buPz589X3759JUkHDx5USMj/Hkd58uRJPfjgg0pLS1OZMmXUrFkzrVu3TvXq1fN4XhrfAAAAAAAAAAC/cDqdV1xn9erVbq+nTZumadOm+TQvjW8AgGlw6TQAAMGPvAYAwBysntk0vgEAJmLxVAYAwBLIawAAzMHamU3jGwBgGlY/Gg0AgBWQ1wAAmIPVM5vGNwDANCyeyQAAWAJ5DQCAOVg9s2l8AwBMw+pHowEAsALyGgAAc7B6ZocYXQAAAAAAAAAAAAWJM74BAKZhs/yFWAAAmB95DQCAOVg9s2l8AwDMw9qZDACANZDXAACYg8Uzm8Y3AMA0LJ7JAABYAnkNAIA5WD2zaXwDAEzD6g/eAADACshrAADMweqZTeMbAGAaVr//GAAAVkBeAwBgDlbP7BCjCwAAAAAAAAAAoCBxxjcAwDysfTAaAABrIK8BADAHi2c2jW8AgGlYPJMBALAE8hoAAHOwembT+AYAmIbVH7wBAIAVkNcAAJiD1TObxjcAwDSs/uANAACsgLwGAMAcrJ7ZNL4BAKZh9aPRAABYAXkNAIA5WD2zQ4wuAAAAAAAAAACAgkTjGwAAAAAAAABgKdzqBABgGla/DAsAACsgrwEAMAerZzaNbwCAaVj9wRsAAFgBeQ0AgDlYPbNpfAMATMPqR6MBALAC8hoAAHOwembT+AYAmIbFMxkAAEsgrwEAMAerZzaNbwCAeVg9lQEAsALyGgAAc7B4ZocYXQAAAAAAAAAAAAWJM74BAKZh9QdvAABgBeQ1AADmYPXMpvENADANqz94AwAAKyCvAQAwB6tnNrc6AQCYhs3HxRtr165V165dVbFiRdlsNi1durRAtgEAAKsLZF5L0iuvvKJq1aqpRIkSatmypb799lvfNwIAgEIgUHmdnJysFi1aKCwsTOXLl1d8fLx27tx5xc+99957qlOnjkqUKKFrr71Wy5cv92peGt8AAPMI4J50ZmamGjVqpFdeeaWAigcAoJAIYF6/8847SkxM1OjRo7VlyxY1atRIHTt21NGjRwtoYwAAsLAA5fWaNWs0aNAgbdiwQampqbpw4YJuvfVWZWZm5vmZdevWqVevXurfv7+2bt2q+Ph4xcfHa8eOHZ5vntPpdHpXavB7/7vDRpcAAIXaXY0q+OV7z17w7fOhxfL3OZvNpiVLlig+Pt63AuDm9/TzRpcA+OSPTH6HYW4NKpXyy/cGMq9btmypFi1aaObMmZKk7OxsValSRY8//riefvpp3wqBS2iTx4wuAfDJqveeM7oEwCdxNUv75Xt9yez87l9L0rFjx1S+fHmtWbNGN954Y67r3H333crMzNQnn3ziGrv++uvVuHFjzZ4926N5OOMbAAAAAGA658+f1+bNm9WhQwfXWEhIiDp06KD169cbWBkAALicU6dOSZLKli2b5zrr1693y3hJ6tixo1cZz8MtAQCm4euDNxwOhxwOh9uY3W6X3W737YsBAIBLoPL6+PHjysrKUlRUlNt4VFSUfv75Z9+KAACgEPAls/O7f52dna0hQ4aodevWatCgQZ7rpaWl5ZrxaWlpHtdoyca3vy6xx98cDoeSk5OVlJREswimxO+weZXwMbXGPJessWPHuo2NHj1aY8aM8e2LkS8VSxc3ugRL4+86/+N32L/4HTYv8tp6zm6daXQJlsXfdTA7fofNzZfMzm9eDxo0SDt27NDXX3+d/8k9ZMl7fMO/Tp8+rYiICJ06dUrh4eFGlwN4jd/hwiu/R6S5xzfMiL/rYHb8Dhdenub1+fPnddVVV+n99993y+iEhASlp6dr2bJlgSgX8Al/18Hs+B0uvPKzf/3YY49p2bJlWrt2rapXr37Z769ataoSExM1ZMgQ19jo0aO1dOlSfffddx7VyD2+AQCFht1uV3h4uNvCWQkAAAQXT/O6ePHiatasmVauXOkay87O1sqVKxUXFxfIkgEAKHS82b92Op167LHHtGTJEq1ateqKTW9JiouLc8t4SUpNTfUq4y15qxMAAHyVkZGh3bt3u17v27dP27ZtU9myZVW1alUDKwMAABclJiYqISFBzZs313XXXafp06crMzNT/fr1M7o0AADw/w0aNEiLFi3SsmXLFBYW5rpPd0REhEJDQyVJffr0UaVKlZScnCxJGjx4sNq2baspU6aoc+fOWrx4sTZt2qS5c+d6PC+NbwAAcrFp0ya1b9/e9ToxMVHS35dPp6SkGFQVAAD4p7vvvlvHjh3Ts88+q7S0NDVu3FifffZZjodhAQAA48yaNUuS1K5dO7fx+fPnq2/fvpKkgwcPKiTkfzcnadWqlRYtWqRRo0Zp5MiRqlWrlpYuXXrZB2JeisY3vGa32zV69GhuDwDT4ncYnmjXrp14DAbMjL/rYHb8DsNTjz32mB577DGjywDyhb/rYHb8DsMTnuxbr169OsdYjx491KNHj3zPy8MtAQAAAAAAAACWwsMtAQAAAAAAAACWQuMbAAAAAAAAAGApNL4BAAAAAAAAAJZC4xteeeWVV1StWjWVKFFCLVu21Lfffmt0SYDH1q5dq65du6pixYqy2WxaunSp0SUBgF+Q1zAz8hpAYUJmw6zIa5gBjW947J133lFiYqJGjx6tLVu2qFGjRurYsaOOHj1qdGmARzIzM9WoUSO98sorRpcCAH5DXsPsyGsAhQWZDTMjr2EGNqfT6TS6CJhDy5Yt1aJFC82cOVOSlJ2drSpVqujxxx/X008/bXB1gHdsNpuWLFmi+Ph4o0sBgAJFXsNKyGsAVkZmwyrIawQrzviGR86fP6/NmzerQ4cOrrGQkBB16NBB69evN7AyAABwEXkNAIA5kNkA4H80vuGR48ePKysrS1FRUW7jUVFRSktLM6gqAADwT+Q1AADmQGYDgP/R+AYAAAAAAAAAWAqNb3jk6quvVpEiRXTkyBG38SNHjig6OtqgqgAAwD+R1wAAmAOZDQD+R+MbHilevLiaNWumlStXusays7O1cuVKxcXFGVgZAAC4iLwGAMAcyGwA8L+iRhcA80hMTFRCQoKaN2+u6667TtOnT1dmZqb69etndGmARzIyMrR7927X63379mnbtm0qW7asqlatamBlAFBwyGuYHXkNoLAgs2Fm5DXMwOZ0Op1GFwHzmDlzpiZPnqy0tDQ1btxYL730klq2bGl0WYBHVq9erfbt2+cYT0hIUEpKSuALAgA/Ia9hZuQ1gMKEzIZZkdcwAxrfAAAAAAAAAABL4R7fAAAAAAAAAABLofENAAAAAAAAALAUGt8AAAAAAAAAAEuh8Q0AAAAAAAAAsBQa3wAAAAAAAAAAS6HxDQAAAAAAAACwFBrfAAAAAAAAAABLofENAAAAAAAAALAUGt+Awfr27av4+HjX63bt2mnIkCEBr2P16tWy2WxKT08P+NwAAAQ78hoAgOBHXgP4JxrfQB769u0rm80mm82m4sWLq2bNmho3bpz++usvv8774Ycfavz48R6tS5gCAAo78hoAgOBHXgMwQlGjCwCC2W233ab58+fL4XBo+fLlGjRokIoVK6akpCS39c6fP6/ixYsXyJxly5YtkO8BAKCwIK8BAAh+5DWAQOOMb+Ay7Ha7oqOjFRMTo0ceeUQdOnTQRx995Lp86vnnn1fFihUVGxsrSfr111/Vs2dPlS5dWmXLllW3bt20f/9+1/dlZWUpMTFRpUuXVrly5fTUU0/J6XS6zXnppVgOh0MjRoxQlSpVZLfbVbNmTb3++uvav3+/2rdvL0kqU6aMbDab+vbtK0nKzs5WcnKyqlevrtDQUDVq1Ejvv/++2zzLly9X7dq1FRoaqvbt27vVCQCAmZDXAAAEP/IaQKDR+Aa8EBoaqvPnz0uSVq5cqZ07dyo1NVWffPKJLly4oI4dOyosLEz/+c9/9N///lelSpXSbbfd5vrMlClTlJKSojfeeENff/21/vjjDy1ZsuSyc/bp00dvv/22XnrpJf3000+aM2eOSpUqpSpVquiDDz6QJO3cuVOHDx/WjBkzJEnJycn697//rdmzZ+uHH37Q0KFDdd9992nNmjWS/v4HRPfu3dW1a1dt27ZNAwYM0NNPP+2vHxsAAAFFXgMAEPzIawB+5wSQq4SEBGe3bt2cTqfTmZ2d7UxNTXXa7XbnsGHDnAkJCc6oqCinw+Fwrb9w4UJnbGysMzs72zXmcDicoaGhzs8//9zpdDqdFSpUcE6aNMn1/oULF5yVK1d2zeN0Op1t27Z1Dh482Ol0Op07d+50SnKmpqbmWuNXX33llOQ8efKka+zcuXPOq666yrlu3Tq3dfv37+/s1auX0+l0OpOSkpz16tVze3/EiBE5vgsAgGBHXgMAEPzIawBG4B7fwGV88sknKlWqlC5cuKDs7Gzde++9GjNmjAYNGqRrr73W7b5j3333nXbv3q2wsDC37zh37pz27NmjU6dO6fDhw2rZsqXrvaJFi6p58+Y5Lse6aNu2bSpSpIjatm3rcc27d+/WmTNndMstt7iNnz9/Xk2aNJEk/fTTT251SFJcXJzHcwAAEEzIawAAgh95DSDQaHwDl9G+fXvNmjVLxYsXV8WKFVW06P/+kylZsqTbuhkZGWrWrJneeuutHN8TGRmZr/lDQ0O9/kxGRoYk6dNPP1WlSpXc3rPb7fmqAwCAYEZeAwAQ/MhrAIFG4xu4jJIlS6pmzZoerdu0aVO98847Kl++vMLDw3Ndp0KFCvrmm2904403SpL++usvbd68WU2bNs11/WuvvVbZ2dlas2aNOnTokOP9i0fEs7KyXGP16tWT3W7XwYMH8zySXbduXX300UduYxs2bLjyRgIAEITIawAAgh95DSDQeLglUEB69+6tq6++Wt26ddN//vMf7du3T6tXr9YTTzyhQ4cOSZIGDx6siRMnaunSpfr555/16KOPKj09Pc/vrFatmhISEvTAAw9o6dKlru989913JUkxMTGy2Wz65JNPdOzYMWVkZCgsLEzDhg3T0KFDtWDBAu3Zs0dbtmzRyy+/rAULFkiSBg4cqF27dmn48OHauXOnFi1apJSUFH//iAAAMBx5DQBA8COvARQEGt9AAbnqqqu0du1aVa1aVd27d1fdunXVv39/nTt3znWE+sknn9T999+vhIQExcXFKSwsTHfeeedlv3fWrFm666679Oijj6pOnTp68MEHlZmZKUmqVKmSxo4dq6efflpRUVF67LHHJEnjx4/XM888o+TkZNWtW1e33XabPv30U1WvXl2SVLVqVX3wwQdaunSpGjVqpNmzZ2vChAl+/OkAABAcyGsAAIIfeQ2gINiced31HwAAAAAAAAAAE+KMbwAAAAAAAACApdD4BgAAAAAAAABYCo1vAAAAAAAAAICl0PgGAAAAAAAAAFgKjW8AAAAAAAAAgKXQ+AYAAAAAAAAAWAqNbwAAAAAAAACApdD4BgAAAAAAAABYCo1vAAAAAAAAAICl0PgGAAAAAAAAAFgKjW8AAAAAAAAAgKXQ+AYAAAAAAAAAWMr/A+aoHYrlzZZQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426892a1",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2416eca",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51b7fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 14:49:36.092269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e66b524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(512, kernel_regularizer=regularizers.l1_l2(1e-6)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.01),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(256, kernel_regularizer=regularizers.l1_l2(1e-6)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.01),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, kernel_regularizer=regularizers.l1_l2(1e-6)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.01),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(output_dim, activation='sigmoid')  # sigmoid for multi-label\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=1e-6),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "616ec7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=X.shape[1], output_dim=y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1508d3",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a70b5a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - accuracy: 0.2907 - loss: 0.6938 - val_accuracy: 0.5455 - val_loss: 1.0515 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2652 - loss: 0.6723 - val_accuracy: 0.4545 - val_loss: 0.8812 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2396 - loss: 0.7224 - val_accuracy: 0.4545 - val_loss: 0.8165 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3059 - loss: 0.7609 - val_accuracy: 0.4545 - val_loss: 0.7941 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3826 - loss: 0.6701 - val_accuracy: 0.4545 - val_loss: 0.7847 - learning_rate: 1.0000e-06\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3883 - loss: 0.6789 - val_accuracy: 0.4545 - val_loss: 0.7777 - learning_rate: 1.0000e-06\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2500 - loss: 0.7119 - val_accuracy: 0.4545 - val_loss: 0.7776 - learning_rate: 1.0000e-06\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4186 - loss: 0.6856 - val_accuracy: 0.4545 - val_loss: 0.7676 - learning_rate: 1.0000e-06\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2093 - loss: 0.6923 - val_accuracy: 0.4545 - val_loss: 0.7614 - learning_rate: 1.0000e-06\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3674 - loss: 0.6828 - val_accuracy: 0.4545 - val_loss: 0.7606 - learning_rate: 1.0000e-06\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3475 - loss: 0.7179 - val_accuracy: 0.4545 - val_loss: 0.7572 - learning_rate: 1.0000e-06\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3314 - loss: 0.7039 - val_accuracy: 0.4545 - val_loss: 0.7563 - learning_rate: 1.0000e-06\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3059 - loss: 0.6919 - val_accuracy: 0.4545 - val_loss: 0.7561 - learning_rate: 1.0000e-06\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3674 - loss: 0.6998 - val_accuracy: 0.4545 - val_loss: 0.7535 - learning_rate: 1.0000e-06\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3210 - loss: 0.7631 - val_accuracy: 0.4545 - val_loss: 0.7517 - learning_rate: 1.0000e-06\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2547 - loss: 0.7666 - val_accuracy: 0.4545 - val_loss: 0.7515 - learning_rate: 1.0000e-06\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4394 - loss: 0.7013 - val_accuracy: 0.4545 - val_loss: 0.7518 - learning_rate: 1.0000e-06\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3778 - loss: 0.7147 - val_accuracy: 0.4545 - val_loss: 0.7510 - learning_rate: 1.0000e-06\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3419 - loss: 0.7106 - val_accuracy: 0.4545 - val_loss: 0.7518 - learning_rate: 1.0000e-06\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2500 - loss: 0.7069 - val_accuracy: 0.4545 - val_loss: 0.7514 - learning_rate: 1.0000e-06\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3873 - loss: 0.7704 - val_accuracy: 0.3636 - val_loss: 0.7523 - learning_rate: 1.0000e-06\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3674 - loss: 0.7124 - val_accuracy: 0.3636 - val_loss: 0.7528 - learning_rate: 1.0000e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1875 - loss: 0.7660\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2140 - loss: 0.7631 - val_accuracy: 0.3636 - val_loss: 0.7549 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32,\n",
    "                    callbacks=[\n",
    "                                EarlyStopping(monitor='val_loss',\n",
    "                                             patience=5,\n",
    "                                             restore_best_weights=True),\n",
    "                                ReduceLROnPlateau(\n",
    "                                  monitor='val_loss',\n",
    "                                  factor=0.5,\n",
    "                                  patience=5,\n",
    "                                  verbose=1)\n",
    "                               ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94383c",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66fd8a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_prob = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d623615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_thresholds(y_true, y_pred_prob, metric='f1'):\n",
    "    y_true = np.asarray(y_true)          # Fix: convert to NumPy\n",
    "    y_pred_prob = np.asarray(y_pred_prob)\n",
    "\n",
    "    best_thresholds = []\n",
    "    best_scores = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        label_true = y_true[:, i]\n",
    "        label_probs = y_pred_prob[:, i]  # Fix here too\n",
    "\n",
    "        thresholds = np.linspace(0.0, 1.0, 101)\n",
    "        scores = []\n",
    "\n",
    "        for t in thresholds:\n",
    "            label_pred = (label_probs >= t).astype(int)\n",
    "            if metric == 'f1':\n",
    "                score = f1_score(label_true, label_pred, zero_division=0)\n",
    "            scores.append(score)\n",
    "\n",
    "        best_t = thresholds[np.argmax(scores)]\n",
    "        best_score = np.max(scores)\n",
    "\n",
    "        best_thresholds.append(best_t)\n",
    "        best_scores.append(best_score)\n",
    "\n",
    "        print(f\"Label {i}: Best threshold = {best_t:.2f}, Best {metric} = {best_score:.4f}\")\n",
    "\n",
    "    return best_thresholds, best_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45e44c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: Best threshold = 0.39, Best f1 = 0.7500\n",
      "Label 1: Best threshold = 0.59, Best f1 = 0.8000\n",
      "Label 2: Best threshold = 0.00, Best f1 = 0.7826\n"
     ]
    }
   ],
   "source": [
    "best_thresholds, _ = tune_thresholds(y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b0dfa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) >= best_thresholds).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ee9ba",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "156bf645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mint       0.60      1.00      0.75         6\n",
      "        leak       1.00      0.67      0.80         3\n",
      "       limit       0.64      1.00      0.78         9\n",
      "\n",
      "   micro avg       0.65      0.94      0.77        18\n",
      "   macro avg       0.75      0.89      0.78        18\n",
      "weighted avg       0.69      0.94      0.77        18\n",
      " samples avg       0.62      0.68      0.63        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f289e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f562f09",
   "metadata": {},
   "source": [
    "## Autoencoder + MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0e26d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Autoencoder(input_dim=256):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128),\n",
    "        LeakyReLU(0.01),\n",
    "\n",
    "        Dense(32),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.01),\n",
    "\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.01),\n",
    "\n",
    "        Dense(input_dim, activation='sigmoid')  # sigmoid for multi-label\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(1e-6), loss=MeanSquaredError())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4241992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 19816.1348 - val_loss: 21918.0684\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 19103.1562 - val_loss: 21917.8066\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 21463.3008 - val_loss: 21917.6777\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 19978.0469 - val_loss: 21917.6230\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20201.2520 - val_loss: 21917.6016\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 21124.7910 - val_loss: 21917.5371\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 18982.7891 - val_loss: 21917.5371\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20619.7285 - val_loss: 21917.5078\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 17086.2305 - val_loss: 21917.5430\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20431.1523 - val_loss: 21917.5234\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 20849.9824 - val_loss: 21917.5078\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 19159.9121 - val_loss: 21917.5293\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20805.2285 - val_loss: 21917.5176\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20960.6367 - val_loss: 21917.5078\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20831.3398 - val_loss: 21917.5137\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 21016.3262 - val_loss: 21917.5039\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21723.9453 - val_loss: 21917.5000\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 19572.0938 - val_loss: 21917.5137\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20897.2207 - val_loss: 21917.5176\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 17600.8574 - val_loss: 21917.5234\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 21492.2812 - val_loss: 21917.5117\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 18797.2441 - val_loss: 21917.5234\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 18866.2383 - val_loss: 21917.5195\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 20239.1445 - val_loss: 21917.5195\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21102.8906 - val_loss: 21917.5176\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 20285.1543 - val_loss: 21917.5059\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 21136.7578 - val_loss: 21917.5059\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 20652.3945 - val_loss: 21917.4980\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21729.4824 - val_loss: 21917.4902\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21787.1562 - val_loss: 21917.4863\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 21000.2930 - val_loss: 21917.4746\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21392.5820 - val_loss: 21917.4707\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 18432.8457 - val_loss: 21917.4746\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20427.2773 - val_loss: 21917.4766\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 21887.9883 - val_loss: 21917.4688\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 19574.4863 - val_loss: 21917.4688\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21677.5645 - val_loss: 21917.4668\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 17750.8770 - val_loss: 21917.4688\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21054.1523 - val_loss: 21917.4668\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 20030.7734 - val_loss: 21917.4648\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 19638.1895 - val_loss: 21917.4668\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 17106.1055 - val_loss: 21917.4668\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 20640.4629 - val_loss: 21917.4570\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 19179.7324 - val_loss: 21917.4570\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 21102.9980 - val_loss: 21917.4551\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 19279.0352 - val_loss: 21917.4570\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21059.6445 - val_loss: 21917.4473\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20395.8848 - val_loss: 21917.4453\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 21307.2871 - val_loss: 21917.4395\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 20855.4453 - val_loss: 21917.4316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13bb490d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Autoencoder(input_dim=X.shape[1])\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e09b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = autoencoder.predict(X_train)\n",
    "X_test_encoded = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f2f4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=X_train_encoded.shape[1], output_dim=y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5d51f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 288ms/step - accuracy: 0.3930 - loss: 0.8276 - val_accuracy: 0.5455 - val_loss: 0.6987 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2547 - loss: 0.8547 - val_accuracy: 0.5455 - val_loss: 0.6996 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2756 - loss: 0.8422 - val_accuracy: 0.5455 - val_loss: 0.7010 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3475 - loss: 0.8633 - val_accuracy: 0.4545 - val_loss: 0.7012 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3419 - loss: 0.8598 - val_accuracy: 0.4545 - val_loss: 0.7015 - learning_rate: 1.0000e-06\n",
      "Epoch 6/100\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2812 - loss: 0.8889\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2756 - loss: 0.8718 - val_accuracy: 0.3636 - val_loss: 0.7015 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_encoded, y_train, validation_split=0.2, epochs=100, batch_size=32,\n",
    "                    callbacks=[\n",
    "                                EarlyStopping(monitor='val_loss',\n",
    "                                             patience=5,\n",
    "                                             restore_best_weights=True),\n",
    "                                ReduceLROnPlateau(\n",
    "                                  monitor='val_loss',\n",
    "                                  factor=0.5,\n",
    "                                  patience=5,\n",
    "                                  verbose=1)\n",
    "                               ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1190a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d81a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: Best threshold = 0.39, Best f1 = 0.7500\n",
      "Label 1: Best threshold = 0.59, Best f1 = 0.8000\n",
      "Label 2: Best threshold = 0.00, Best f1 = 0.7826\n"
     ]
    }
   ],
   "source": [
    "best_thresholds, _ = tune_thresholds(y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f2ba424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) >= best_thresholds).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bc629",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5368b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mint       0.43      1.00      0.60         6\n",
      "        leak       0.20      0.33      0.25         3\n",
      "       limit       0.64      1.00      0.78         9\n",
      "\n",
      "   micro avg       0.48      0.89      0.63        18\n",
      "   macro avg       0.42      0.78      0.54        18\n",
      "weighted avg       0.50      0.89      0.63        18\n",
      " samples avg       0.50      0.65      0.55        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff1df504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_multilabel_confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
