{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c550f716",
   "metadata": {},
   "source": [
    "# Baseline Random Forest Training on CRPWarner Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f55ad7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1ba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae177c1",
   "metadata": {},
   "source": [
    "## Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e77594",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd().parents[1]\n",
    "DATA_PATH = os.path.join(PATH, 'data/processed')\n",
    "MODEL_PATH = os.path.join(PATH, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f456e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'feature-opcode-freq_list.json')) as f:\n",
    "    feature_list = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'labels-opcode-freq.json')) as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed9621f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train-opcode-freq.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test-opcode-freq.csv'))\n",
    "\n",
    "X_train = train_df[feature_list]\n",
    "y_train = train_df[labels]\n",
    "\n",
    "X_test = test_df[feature_list]\n",
    "y_test = test_df[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8ec0d",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": OneVsRestClassifier(LogisticRegression(max_iter=1000)),\n",
    "    \"Random Forest\": OneVsRestClassifier(RandomForestClassifier()),\n",
    "    \"Gradient Boosting\": OneVsRestClassifier(GradientBoostingClassifier()),\n",
    "    \"AdaBoost\": OneVsRestClassifier(AdaBoostClassifier()),\n",
    "    \"SVM (Linear)\": OneVsRestClassifier(SVC(kernel=\"linear\")),\n",
    "    \"KNN\": OneVsRestClassifier(KNeighborsClassifier()),\n",
    "    \"Naive Bayes\": OneVsRestClassifier(GaussianNB()),\n",
    "    \"MLP Classifier\": OneVsRestClassifier(MLPClassifier(max_iter=300)),\n",
    "    \"XGBoost\": OneVsRestClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    \"LightGBM\": OneVsRestClassifier(LGBMClassifier()),\n",
    "    \"DecisionTree\": OneVsRestClassifier(DecisionTreeClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb4cad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14, number of negative: 41\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 946\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 81\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254545 -> initscore=-1.074515\n",
      "[LightGBM] [Info] Start training from score -1.074515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6, number of negative: 49\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 946\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 81\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109091 -> initscore=-2.100061\n",
      "[LightGBM] [Info] Start training from score -2.100061\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 21, number of negative: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 946\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 81\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381818 -> initscore=-0.481838\n",
      "[LightGBM] [Info] Start training from score -0.481838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average=\"macro\"),  # change to 'macro' if multi-class\n",
    "        \"Recall\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"Training Time\": round(end - start, 3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d85fb9",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e20caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Classifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Training Time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a1d55e84-f6c0-4924-9e57-76306c68bded",
       "rows": [
        [
         "10",
         "DecisionTree",
         "0.42857142857142855",
         "0.9047619047619048",
         "0.40740740740740744",
         "0.5416666666666666",
         "0.016"
        ],
        [
         "3",
         "AdaBoost",
         "0.42857142857142855",
         "0.75",
         "0.4444444444444444",
         "0.5352941176470588",
         "0.241"
        ],
        [
         "7",
         "MLP Classifier",
         "0.2857142857142857",
         "0.7638888888888888",
         "0.40740740740740744",
         "0.5108932461873638",
         "0.477"
        ],
        [
         "1",
         "Random Forest",
         "0.35714285714285715",
         "0.9047619047619048",
         "0.35185185185185186",
         "0.4702380952380952",
         "0.317"
        ],
        [
         "2",
         "Gradient Boosting",
         "0.42857142857142855",
         "0.5833333333333334",
         "0.38888888888888884",
         "0.4519607843137255",
         "0.485"
        ],
        [
         "8",
         "XGBoost",
         "0.42857142857142855",
         "0.7380952380952381",
         "0.35185185185185186",
         "0.4369047619047619",
         "0.427"
        ],
        [
         "5",
         "KNN",
         "0.21428571428571427",
         "0.4621212121212121",
         "0.4259259259259259",
         "0.4333333333333333",
         "0.011"
        ],
        [
         "9",
         "LightGBM",
         "0.42857142857142855",
         "0.7222222222222222",
         "0.3148148148148148",
         "0.4063492063492064",
         "0.04"
        ],
        [
         "0",
         "Logistic Regression",
         "0.2857142857142857",
         "0.5",
         "0.27777777777777773",
         "0.35384615384615387",
         "0.422"
        ],
        [
         "4",
         "SVM (Linear)",
         "0.2857142857142857",
         "0.5",
         "0.27777777777777773",
         "0.35384615384615387",
         "0.021"
        ],
        [
         "6",
         "Naive Bayes",
         "0.2857142857142857",
         "0.4444444444444444",
         "0.2037037037037037",
         "0.2792022792022792",
         "0.012"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.510893</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.451961</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.436905</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.406349</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.279202</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier  Accuracy  Precision    Recall  F1-Score  \\\n",
       "10         DecisionTree  0.428571   0.904762  0.407407  0.541667   \n",
       "3              AdaBoost  0.428571   0.750000  0.444444  0.535294   \n",
       "7        MLP Classifier  0.285714   0.763889  0.407407  0.510893   \n",
       "1         Random Forest  0.357143   0.904762  0.351852  0.470238   \n",
       "2     Gradient Boosting  0.428571   0.583333  0.388889  0.451961   \n",
       "8               XGBoost  0.428571   0.738095  0.351852  0.436905   \n",
       "5                   KNN  0.214286   0.462121  0.425926  0.433333   \n",
       "9              LightGBM  0.428571   0.722222  0.314815  0.406349   \n",
       "0   Logistic Regression  0.285714   0.500000  0.277778  0.353846   \n",
       "4          SVM (Linear)  0.285714   0.500000  0.277778  0.353846   \n",
       "6           Naive Bayes  0.285714   0.444444  0.203704  0.279202   \n",
       "\n",
       "    Training Time  \n",
       "10          0.016  \n",
       "3           0.241  \n",
       "7           0.477  \n",
       "1           0.317  \n",
       "2           0.485  \n",
       "8           0.427  \n",
       "5           0.011  \n",
       "9           0.040  \n",
       "0           0.422  \n",
       "4           0.021  \n",
       "6           0.012  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.sort_values(by=\"F1-Score\", ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b5756",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b283cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 15:29:15,444] A new study created in memory with name: no-name-88172442-3788-4a70-b3ef-7f4f16048c4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 15:29:16,312] Trial 0 finished with value: 0.4416433239962652 and parameters: {'n_estimators': 138, 'learning_rate': 0.14476662589428113}. Best is trial 0 with value: 0.4416433239962652.\n",
      "[I 2025-07-11 15:29:17,124] Trial 1 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 125, 'learning_rate': 1.645810049943014e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:17,432] Trial 2 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 56, 'learning_rate': 2.1923830083189858e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:17,998] Trial 3 finished with value: 0.38888888888888884 and parameters: {'n_estimators': 106, 'learning_rate': 0.006091898342428539}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:18,380] Trial 4 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 69, 'learning_rate': 4.9125266084885585e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:19,567] Trial 5 finished with value: 0.4656084656084656 and parameters: {'n_estimators': 189, 'learning_rate': 0.08896564500622207}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:20,336] Trial 6 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 121, 'learning_rate': 4.908643284723296e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:21,238] Trial 7 finished with value: 0.3703703703703704 and parameters: {'n_estimators': 153, 'learning_rate': 0.0018448189841735138}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:21,989] Trial 8 finished with value: 0.3703703703703704 and parameters: {'n_estimators': 140, 'learning_rate': 0.00022836131959006218}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:22,827] Trial 9 finished with value: 0.4148148148148148 and parameters: {'n_estimators': 160, 'learning_rate': 6.16848066284069e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:23,358] Trial 10 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 97, 'learning_rate': 2.2841586743079473e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:23,792] Trial 11 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 58, 'learning_rate': 1.1174332324057827e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:24,418] Trial 12 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 81, 'learning_rate': 1.2902078662654194e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:25,552] Trial 13 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 199, 'learning_rate': 7.122439238883384e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:25,881] Trial 14 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 55, 'learning_rate': 4.383907338675549e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:26,966] Trial 15 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 175, 'learning_rate': 8.876602145553703e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:27,516] Trial 16 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 89, 'learning_rate': 1.0215582753332042e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:28,460] Trial 17 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 117, 'learning_rate': 3.8726434800798147e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:29,035] Trial 18 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 70, 'learning_rate': 7.585955495889702e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:29,787] Trial 19 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 108, 'learning_rate': 2.587762906858677e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:30,589] Trial 20 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 135, 'learning_rate': 1.0264481483185785e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:30,991] Trial 21 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 71, 'learning_rate': 3.0097965821342336e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:31,283] Trial 22 finished with value: 0.3703703703703704 and parameters: {'n_estimators': 50, 'learning_rate': 0.0007126438361784853}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:31,781] Trial 23 finished with value: 0.38888888888888884 and parameters: {'n_estimators': 74, 'learning_rate': 0.010887687865253712}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:32,274] Trial 24 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 89, 'learning_rate': 1.5442108195511522e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:32,646] Trial 25 finished with value: 0.4246498599439776 and parameters: {'n_estimators': 62, 'learning_rate': 0.9025180023642762}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:33,117] Trial 26 finished with value: 0.4148148148148148 and parameters: {'n_estimators': 82, 'learning_rate': 0.00016152585874796676}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:33,725] Trial 27 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 106, 'learning_rate': 1.7877375347579822e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:34,219] Trial 28 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 65, 'learning_rate': 3.264837697209245e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:34,972] Trial 29 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 137, 'learning_rate': 2.9185744981029277e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:35,933] Trial 30 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 157, 'learning_rate': 1.9819059751437946e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:36,689] Trial 31 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 133, 'learning_rate': 4.2204308685270347e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:37,393] Trial 32 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 122, 'learning_rate': 4.171047608639654e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:38,190] Trial 33 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 117, 'learning_rate': 6.768570653174892e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:39,038] Trial 34 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 146, 'learning_rate': 2.1732706403764333e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:39,593] Trial 35 finished with value: 0.4507936507936508 and parameters: {'n_estimators': 102, 'learning_rate': 0.021920351450732213}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:40,548] Trial 36 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 172, 'learning_rate': 1.1175764058628976e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:41,065] Trial 37 finished with value: 0.3703703703703704 and parameters: {'n_estimators': 93, 'learning_rate': 0.0005185790311326637}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:41,761] Trial 38 finished with value: 0.4148148148148148 and parameters: {'n_estimators': 124, 'learning_rate': 6.580063780107207e-05}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:42,622] Trial 39 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 148, 'learning_rate': 9.249014360969098e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:44,126] Trial 40 finished with value: 0.38888888888888884 and parameters: {'n_estimators': 169, 'learning_rate': 0.0027499841349159586}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:44,723] Trial 41 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 99, 'learning_rate': 4.0117728327867774e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:45,301] Trial 42 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 82, 'learning_rate': 2.4627365878506157e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:46,181] Trial 43 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 130, 'learning_rate': 7.799463524498092e-08}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:46,950] Trial 44 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 115, 'learning_rate': 2.910565664766449e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:47,486] Trial 45 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 76, 'learning_rate': 8.044530125924781e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:48,131] Trial 46 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 96, 'learning_rate': 1.229770671760941e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:48,456] Trial 47 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 55, 'learning_rate': 4.3482205315591564e-07}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:49,156] Trial 48 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 109, 'learning_rate': 1.635818502027484e-06}. Best is trial 1 with value: 0.4666666666666666.\n",
      "[I 2025-07-11 15:29:49,566] Trial 49 finished with value: 0.4666666666666666 and parameters: {'n_estimators': 63, 'learning_rate': 2.067519110185592e-05}. Best is trial 1 with value: 0.4666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned AdaBoostClassifier (OneVsRestClassifier):\n",
      "Accuracy: 0.42857142857142855\n",
      "Precision: 0.49242424242424243\n",
      "Recall: 0.46296296296296297\n",
      "F1 Score: 0.4666666666666666\n"
     ]
    }
   ],
   "source": [
    "# 1. Optuna objective with AdaBoost inside MultiOutputClassifier\n",
    "def objective(trial):\n",
    "    model = OneVsRestClassifier(AdaBoostClassifier(\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.00000001, 1.0, log=True),\n",
    "        random_state=42\n",
    "    ))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "# 2. Optimize AdaBoost\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 3. Build base classifiers\n",
    "model = OneVsRestClassifier(AdaBoostClassifier(**study.best_params, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Tuned AdaBoostClassifier (OneVsRestClassifier):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\", zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e44c06f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/napatcholthaipanich/Dev/master/dissertation/workspace/ml/models/best_ada-ovr_model_on_crpwarner_opcode_freq.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, os.path.join(MODEL_PATH, f'best_ada-ovr_model_on_crpwarner_opcode_freq.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0357c56",
   "metadata": {},
   "source": [
    "### K-Fold (K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc7afbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 3\n",
    "results = []\n",
    "best_model = OneVsRestClassifier(AdaBoostClassifier(**study.best_params, random_state=42))\n",
    "best_f1 = 0\n",
    "best_fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8f51b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Fold-0 ===========\n",
      "Accuracy: 0.5217391304347826\n",
      "Precision: 0.47685185185185186\n",
      "Recall: 0.611111111111111\n",
      "F1 Score: 0.5142857142857142\n",
      "=========== Fold-1 ===========\n",
      "Accuracy: 0.5652173913043478\n",
      "Precision: 0.47142857142857136\n",
      "Recall: 0.6015873015873016\n",
      "F1 Score: 0.5238095238095238\n",
      "=========== Fold-2 ===========\n",
      "Accuracy: 0.43478260869565216\n",
      "Precision: 0.1851851851851852\n",
      "Recall: 0.3333333333333333\n",
      "F1 Score: 0.2380952380952381\n",
      "\n",
      "===== Overall Summary =====\n",
      "Average Accuracy: 0.5072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/napatcholthaipanich/Dev/master/dissertation/workspace/ml/models/best_ada-ovr_model_on_crpwarner_opcode_freq_from_fold2.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for fold in range(NUM_FOLDS):\n",
    "    print(f\"=========== Fold-{fold} ===========\")\n",
    "    train_path = os.path.join(DATA_PATH, f'train_fold_{fold}-opcode-freq.csv')\n",
    "    val_path = os.path.join(DATA_PATH, f'val_fold_{fold}-opcode-freq.csv')\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df   = pd.read_csv(val_path)\n",
    "\n",
    "    X_train = train_df[feature_list]\n",
    "    y_train = train_df[labels]\n",
    "\n",
    "    X_val = val_df[feature_list]\n",
    "    y_val = val_df[labels]\n",
    "\n",
    "    # Train model\n",
    "    model = OneVsRestClassifier(AdaBoostClassifier(**study.best_params, random_state=42))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    report = classification_report(y_val, y_pred, target_names=labels, output_dict=True)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    results.append({'fold': fold, 'accuracy': acc, 'report': report})\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(\"Precision:\", precision_score(y_val, y_pred, average=\"macro\", zero_division=0))\n",
    "    print(\"Recall:\", recall_score(y_val, y_pred, average=\"macro\", zero_division=0))\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    if best_f1 < f1:\n",
    "        best_model = model\n",
    "        best_fold = fold\n",
    "## Step 6: Average Performance Summary\n",
    "print(\"\\n===== Overall Summary =====\")\n",
    "avg_acc = sum([r['accuracy'] for r in results]) / NUM_FOLDS\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, os.path.join(MODEL_PATH, f'best_ada-ovr_model_on_crpwarner_opcode_freq_from_fold{best_fold}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
