{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c550f716",
      "metadata": {},
      "source": [
        "# Baseline Random Forest Training on CRPWarner Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f55ad7",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ca1ba9da",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1fdbeeb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "\n",
        "import optuna\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae177c1",
      "metadata": {},
      "source": [
        "## Const"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "60e77594",
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = Path.cwd().parents[1]\n",
        "DATA_PATH = os.path.join(PATH, 'data/processed')\n",
        "MODEL_PATH = os.path.join(PATH, 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f456e60b",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(os.path.join(DATA_PATH, 'feature-opcode-n-gram_list.json')) as f:\n",
        "    feature_list = json.load(f)\n",
        "\n",
        "with open(os.path.join(DATA_PATH, 'labels-opcode-n-gram.json')) as f:\n",
        "    labels = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ed9621f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train-opcode-n-gram.csv'))\n",
        "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test-opcode-n-gram.csv'))\n",
        "\n",
        "X_train = train_df[feature_list]\n",
        "y_train = train_df[labels]\n",
        "\n",
        "X_test = test_df[feature_list]\n",
        "y_test = test_df[labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea8ec0d",
      "metadata": {},
      "source": [
        "## Traditional Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9f923bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": MultiOutputClassifier(LogisticRegression(max_iter=1000)),\n",
        "    \"Random Forest\": MultiOutputClassifier(RandomForestClassifier()),\n",
        "    \"Gradient Boosting\": MultiOutputClassifier(GradientBoostingClassifier()),\n",
        "    \"AdaBoost\": MultiOutputClassifier(AdaBoostClassifier()),\n",
        "    \"SVM (Linear)\": MultiOutputClassifier(SVC(kernel=\"linear\")),\n",
        "    \"KNN\": MultiOutputClassifier(KNeighborsClassifier()),\n",
        "    \"Naive Bayes\": MultiOutputClassifier(GaussianNB()),\n",
        "    \"MLP Classifier\": MultiOutputClassifier(MLPClassifier(max_iter=300)),\n",
        "    \"XGBoost\": MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
        "    \"LightGBM\": MultiOutputClassifier(LGBMClassifier()),\n",
        "    \"DecisionTree\": MultiOutputClassifier(DecisionTreeClassifier())\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bb4cad41",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 14, number of negative: 41\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9007\n",
            "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 1157\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254545 -> initscore=-1.074515\n",
            "[LightGBM] [Info] Start training from score -1.074515\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 6, number of negative: 49\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9007\n",
            "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 1157\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109091 -> initscore=-2.100061\n",
            "[LightGBM] [Info] Start training from score -2.100061\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 21, number of negative: 34\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 9007\n",
            "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 1157\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381818 -> initscore=-0.481838\n",
            "[LightGBM] [Info] Start training from score -0.481838\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end = time.time()\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    results.append({\n",
        "        \"Classifier\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, average=\"macro\"),  # change to 'macro' if multi-class\n",
        "        \"Recall\": recall_score(y_test, y_pred, average=\"macro\"),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
        "        \"Training Time\": round(end - start, 3)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20d85fb9",
      "metadata": {},
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "32e20caa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Classifier",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Accuracy",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Precision",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Recall",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "F1-Score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Training Time",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "8e33c2b2-a62a-4c76-885b-220a7ce32d50",
              "rows": [
                [
                  "8",
                  "XGBoost",
                  "0.42857142857142855",
                  "0.7555555555555555",
                  "0.4259259259259259",
                  "0.5262626262626262",
                  "20.293"
                ],
                [
                  "2",
                  "Gradient Boosting",
                  "0.5",
                  "0.8333333333333334",
                  "0.38888888888888884",
                  "0.5205128205128206",
                  "5.744"
                ],
                [
                  "9",
                  "LightGBM",
                  "0.2857142857142857",
                  "0.6071428571428571",
                  "0.4259259259259259",
                  "0.5",
                  "0.459"
                ],
                [
                  "5",
                  "KNN",
                  "0.21428571428571427",
                  "0.4444444444444445",
                  "0.4259259259259259",
                  "0.4222222222222222",
                  "0.144"
                ],
                [
                  "6",
                  "Naive Bayes",
                  "0.5",
                  "0.6666666666666666",
                  "0.2962962962962963",
                  "0.4047619047619048",
                  "0.192"
                ],
                [
                  "1",
                  "Random Forest",
                  "0.42857142857142855",
                  "0.6111111111111112",
                  "0.2962962962962963",
                  "0.38888888888888884",
                  "0.547"
                ],
                [
                  "10",
                  "DecisionTree",
                  "0.5",
                  "0.4666666666666666",
                  "0.3148148148148148",
                  "0.3722943722943723",
                  "0.219"
                ],
                [
                  "0",
                  "Logistic Regression",
                  "0.35714285714285715",
                  "0.5",
                  "0.2962962962962963",
                  "0.3703703703703704",
                  "3.964"
                ],
                [
                  "4",
                  "SVM (Linear)",
                  "0.35714285714285715",
                  "0.5",
                  "0.2962962962962963",
                  "0.3703703703703704",
                  "0.216"
                ],
                [
                  "7",
                  "MLP Classifier",
                  "0.35714285714285715",
                  "0.5",
                  "0.24074074074074073",
                  "0.32142857142857145",
                  "10.438"
                ],
                [
                  "3",
                  "AdaBoost",
                  "0.21428571428571427",
                  "0.5416666666666666",
                  "0.24074074074074073",
                  "0.2913165266106443",
                  "1.996"
                ]
              ],
              "shape": {
                "columns": 6,
                "rows": 11
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.526263</td>\n",
              "      <td>20.293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.520513</td>\n",
              "      <td>5.744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.422222</td>\n",
              "      <td>0.144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.314815</td>\n",
              "      <td>0.372294</td>\n",
              "      <td>0.219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>3.964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM (Linear)</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.240741</td>\n",
              "      <td>0.321429</td>\n",
              "      <td>10.438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.240741</td>\n",
              "      <td>0.291317</td>\n",
              "      <td>1.996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Classifier  Accuracy  Precision    Recall  F1-Score  \\\n",
              "8               XGBoost  0.428571   0.755556  0.425926  0.526263   \n",
              "2     Gradient Boosting  0.500000   0.833333  0.388889  0.520513   \n",
              "9              LightGBM  0.285714   0.607143  0.425926  0.500000   \n",
              "5                   KNN  0.214286   0.444444  0.425926  0.422222   \n",
              "6           Naive Bayes  0.500000   0.666667  0.296296  0.404762   \n",
              "1         Random Forest  0.428571   0.611111  0.296296  0.388889   \n",
              "10         DecisionTree  0.500000   0.466667  0.314815  0.372294   \n",
              "0   Logistic Regression  0.357143   0.500000  0.296296  0.370370   \n",
              "4          SVM (Linear)  0.357143   0.500000  0.296296  0.370370   \n",
              "7        MLP Classifier  0.357143   0.500000  0.240741  0.321429   \n",
              "3              AdaBoost  0.214286   0.541667  0.240741  0.291317   \n",
              "\n",
              "    Training Time  \n",
              "8          20.293  \n",
              "2           5.744  \n",
              "9           0.459  \n",
              "5           0.144  \n",
              "6           0.192  \n",
              "1           0.547  \n",
              "10          0.219  \n",
              "0           3.964  \n",
              "4           0.216  \n",
              "7          10.438  \n",
              "3           1.996  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(results)\n",
        "df.sort_values(by=\"F1-Score\", ascending=False, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f21b5756",
      "metadata": {},
      "source": [
        "### Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7b283cd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-11 15:40:21,395] A new study created in memory with name: no-name-15a720d9-70b3-4a50-bb58-23385f3c2e44\n",
            "[I 2025-07-11 15:41:36,474] Trial 0 finished with value: 0.19047619047619047 and parameters: {'n_estimators': 473, 'max_depth': 9, 'learning_rate': 0.011726041161503362, 'subsample': 0.957880615883327, 'colsample_bytree': 0.9440304270806165, 'gamma': 3.2088062594611944, 'reg_alpha': 0.9675683117131462, 'reg_lambda': 5.739353997869854}. Best is trial 0 with value: 0.19047619047619047.\n",
            "[I 2025-07-11 15:42:44,647] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 448, 'max_depth': 8, 'learning_rate': 0.000387856230251917, 'subsample': 0.33448199665102757, 'colsample_bytree': 0.4074011433157676, 'gamma': 1.8326977651520282, 'reg_alpha': 3.971388546599961, 'reg_lambda': 4.17054119756182}. Best is trial 0 with value: 0.19047619047619047.\n",
            "[I 2025-07-11 15:44:52,211] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 997, 'max_depth': 2, 'learning_rate': 0.0002385242541228425, 'subsample': 0.3867607236085868, 'colsample_bytree': 0.2879988043412627, 'gamma': 4.54958549058357, 'reg_alpha': 1.5260568602288438, 'reg_lambda': 0.31948126562386214}. Best is trial 0 with value: 0.19047619047619047.\n",
            "[I 2025-07-11 15:46:44,847] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 972, 'max_depth': 10, 'learning_rate': 8.666991639976884e-07, 'subsample': 0.9257492908762125, 'colsample_bytree': 0.7551063093449721, 'gamma': 6.673890331680441, 'reg_alpha': 9.299959740815346, 'reg_lambda': 6.264192925786315}. Best is trial 0 with value: 0.19047619047619047.\n",
            "[I 2025-07-11 15:48:05,936] Trial 4 finished with value: 0.37789661319073087 and parameters: {'n_estimators': 637, 'max_depth': 1, 'learning_rate': 0.04569914315032304, 'subsample': 0.9433938269643327, 'colsample_bytree': 0.5554788670408887, 'gamma': 0.5678344321478435, 'reg_alpha': 1.9361193666731114, 'reg_lambda': 0.40931642128977264}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:49:49,033] Trial 5 finished with value: 0.06666666666666667 and parameters: {'n_estimators': 850, 'max_depth': 5, 'learning_rate': 0.0004656885247290797, 'subsample': 0.6649930539371568, 'colsample_bytree': 0.8074725711758047, 'gamma': 2.869922206920984, 'reg_alpha': 0.3285859595363594, 'reg_lambda': 1.3492710259479468}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:50:14,412] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 65, 'max_depth': 6, 'learning_rate': 0.00013698466000956617, 'subsample': 0.17473875108217068, 'colsample_bytree': 0.36365933104772663, 'gamma': 6.962008434289604, 'reg_alpha': 3.5068939569291304, 'reg_lambda': 3.5077771690971415}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:51:05,749] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 359, 'max_depth': 1, 'learning_rate': 0.15191864209091804, 'subsample': 0.49642685369825024, 'colsample_bytree': 0.5268323610848002, 'gamma': 8.65516776947141, 'reg_alpha': 8.654503129216964, 'reg_lambda': 8.73252933366518}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:52:42,809] Trial 8 finished with value: 0.273015873015873 and parameters: {'n_estimators': 821, 'max_depth': 10, 'learning_rate': 0.021249540004290232, 'subsample': 0.7682914576167322, 'colsample_bytree': 0.41946533799103936, 'gamma': 2.315981535163364, 'reg_alpha': 0.6934959123696349, 'reg_lambda': 5.722805951808862}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:54:09,257] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 726, 'max_depth': 4, 'learning_rate': 0.00027711953759511956, 'subsample': 0.9387566252801223, 'colsample_bytree': 0.11714658583448465, 'gamma': 9.818772662835498, 'reg_alpha': 5.1168488170161766, 'reg_lambda': 0.11831283890624933}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:55:27,902] Trial 10 finished with value: 0.1568627450980392 and parameters: {'n_estimators': 642, 'max_depth': 3, 'learning_rate': 0.7222073839712502, 'subsample': 0.7331062282552514, 'colsample_bytree': 0.6660726183503898, 'gamma': 0.7963681898771053, 'reg_alpha': 6.433882938215746, 'reg_lambda': 2.251330956640506}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:56:47,660] Trial 11 finished with value: 0.3444444444444444 and parameters: {'n_estimators': 638, 'max_depth': 7, 'learning_rate': 0.017376109092424197, 'subsample': 0.7552218939930404, 'colsample_bytree': 0.5563775355134585, 'gamma': 0.13813933894723984, 'reg_alpha': 2.0391851917699944, 'reg_lambda': 7.435976150397867}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:58:12,085] Trial 12 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 598, 'max_depth': 7, 'learning_rate': 0.010498880175278048, 'subsample': 0.8267712074933155, 'colsample_bytree': 0.5774280405560743, 'gamma': 0.004338031069960668, 'reg_alpha': 2.6451382177487384, 'reg_lambda': 8.575371389159628}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 15:58:59,666] Trial 13 finished with value: 0.17777777777777778 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.07767415351728786, 'subsample': 0.6145086759263413, 'colsample_bytree': 0.566132962020259, 'gamma': 1.0132593944856327, 'reg_alpha': 2.1799736556603824, 'reg_lambda': 7.755329099067546}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:00:26,731] Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 603, 'max_depth': 4, 'learning_rate': 0.0019758231973196574, 'subsample': 0.8343225063540476, 'colsample_bytree': 0.7121285963523076, 'gamma': 4.006142127486858, 'reg_alpha': 6.261176368687402, 'reg_lambda': 7.466150601472193}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:02:09,145] Trial 15 finished with value: 0.0 and parameters: {'n_estimators': 749, 'max_depth': 8, 'learning_rate': 1.0135700857339861e-05, 'subsample': 0.9978854555524371, 'colsample_bytree': 0.8644084139936621, 'gamma': 1.2313948149801628, 'reg_alpha': 4.006000817066037, 'reg_lambda': 9.985352215887334}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:02:51,429] Trial 16 finished with value: 0.37777777777777777 and parameters: {'n_estimators': 246, 'max_depth': 1, 'learning_rate': 0.807885123409541, 'subsample': 0.5170021661509029, 'colsample_bytree': 0.21606622262685915, 'gamma': 0.05859016165159854, 'reg_alpha': 2.449163105837093, 'reg_lambda': 4.040892606589957}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:03:30,268] Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 177, 'max_depth': 1, 'learning_rate': 0.8369788469101204, 'subsample': 0.5146265736617882, 'colsample_bytree': 0.10360721554579552, 'gamma': 5.749063612300904, 'reg_alpha': 3.0293003237704568, 'reg_lambda': 2.741020773350344}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:03:51,619] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 12, 'max_depth': 2, 'learning_rate': 0.12167592939203274, 'subsample': 0.40574355239667037, 'colsample_bytree': 0.24174144092935843, 'gamma': 3.715548904613372, 'reg_alpha': 5.094399248817247, 'reg_lambda': 4.578592806191665}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:04:42,749] Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 335, 'max_depth': 2, 'learning_rate': 0.002823358525457144, 'subsample': 0.18649374868028756, 'colsample_bytree': 0.24200568365822983, 'gamma': 2.4149211070974888, 'reg_alpha': 7.589378357982292, 'reg_lambda': 1.5416063067065586}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:05:17,504] Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 151, 'max_depth': 3, 'learning_rate': 1.5528042612089948e-07, 'subsample': 0.279993471691259, 'colsample_bytree': 0.47848884583967877, 'gamma': 5.4118505197820514, 'reg_alpha': 1.6612870028597837, 'reg_lambda': 3.4671003169629517}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:06:32,708] Trial 21 finished with value: 0.36274509803921573 and parameters: {'n_estimators': 547, 'max_depth': 1, 'learning_rate': 0.2243969963609561, 'subsample': 0.6114041205947701, 'colsample_bytree': 0.6291917275329204, 'gamma': 0.5818937009905097, 'reg_alpha': 2.1682248423003965, 'reg_lambda': 6.812873190819592}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:07:45,551] Trial 22 finished with value: 0.20833333333333334 and parameters: {'n_estimators': 510, 'max_depth': 1, 'learning_rate': 0.4071005589603062, 'subsample': 0.5882557449832098, 'colsample_bytree': 0.6279321644310922, 'gamma': 1.4393714826750486, 'reg_alpha': 2.904699577893436, 'reg_lambda': 6.582168237967112}. Best is trial 4 with value: 0.37789661319073087.\n",
            "[I 2025-07-11 16:08:45,951] Trial 23 finished with value: 0.5444444444444444 and parameters: {'n_estimators': 392, 'max_depth': 3, 'learning_rate': 0.0649257027874224, 'subsample': 0.4694874004835078, 'colsample_bytree': 0.4677750166415253, 'gamma': 0.31183074634193536, 'reg_alpha': 0.04221684426300776, 'reg_lambda': 5.3608537495802295}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:09:40,487] Trial 24 finished with value: 0.2611111111111111 and parameters: {'n_estimators': 364, 'max_depth': 3, 'learning_rate': 0.03673623435937208, 'subsample': 0.4431159949591201, 'colsample_bytree': 0.3313154771447868, 'gamma': 1.8810119203110278, 'reg_alpha': 0.06417858751131152, 'reg_lambda': 4.472062760601853}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:10:23,995] Trial 25 finished with value: 0.0 and parameters: {'n_estimators': 241, 'max_depth': 2, 'learning_rate': 0.0031267717535821606, 'subsample': 0.27113187635518454, 'colsample_bytree': 0.18510187183476529, 'gamma': 0.1076655401302452, 'reg_alpha': 1.2033286744541076, 'reg_lambda': 5.069190223142948}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:11:23,855] Trial 26 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 421, 'max_depth': 4, 'learning_rate': 0.0734237872683393, 'subsample': 0.4830377861084159, 'colsample_bytree': 0.4071017948911084, 'gamma': 0.9911318750353587, 'reg_alpha': 0.10769075351136559, 'reg_lambda': 3.1822311377295036}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:12:23,814] Trial 27 finished with value: 0.0 and parameters: {'n_estimators': 401, 'max_depth': 4, 'learning_rate': 2.0832568788756718e-05, 'subsample': 0.6769702195782803, 'colsample_bytree': 0.4676203135364021, 'gamma': 2.871285641422878, 'reg_alpha': 0.1589328085170551, 'reg_lambda': 0.9643986256428061}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:13:25,829] Trial 28 finished with value: 0.37777777777777777 and parameters: {'n_estimators': 440, 'max_depth': 5, 'learning_rate': 0.07239845212676774, 'subsample': 0.456575535739427, 'colsample_bytree': 0.4860222348185601, 'gamma': 1.5792201860584858, 'reg_alpha': 0.7439775663080224, 'reg_lambda': 2.1285868988934196}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:14:34,511] Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 514, 'max_depth': 3, 'learning_rate': 0.006778802695729577, 'subsample': 0.29243440149721045, 'colsample_bytree': 0.39309191164367485, 'gamma': 3.786918274010432, 'reg_alpha': 1.0266547223917044, 'reg_lambda': 5.178386297697945}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:15:26,352] Trial 30 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.039126472107469265, 'subsample': 0.10246489645438583, 'colsample_bytree': 0.3207068434466458, 'gamma': 2.307599116453493, 'reg_alpha': 1.2993835901124755, 'reg_lambda': 3.2317421188275195}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:16:03,695] Trial 31 finished with value: 0.49259259259259264 and parameters: {'n_estimators': 197, 'max_depth': 2, 'learning_rate': 0.3415431239444654, 'subsample': 0.5411934034028981, 'colsample_bytree': 0.19999989587066977, 'gamma': 0.7411478748320107, 'reg_alpha': 0.08169471724290006, 'reg_lambda': 4.04542276898653}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:16:39,061] Trial 32 finished with value: 0.5262626262626262 and parameters: {'n_estimators': 171, 'max_depth': 2, 'learning_rate': 0.24116014489165646, 'subsample': 0.5672010514643794, 'colsample_bytree': 0.995965922100445, 'gamma': 0.808758801725718, 'reg_alpha': 0.11410694095661418, 'reg_lambda': 5.926275834748058}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:17:14,136] Trial 33 finished with value: 0.48148148148148145 and parameters: {'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.19364095154826108, 'subsample': 0.5580861953688395, 'colsample_bytree': 0.9335846921540821, 'gamma': 1.0900080682664532, 'reg_alpha': 0.11770466939736267, 'reg_lambda': 5.716945333532309}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:17:40,786] Trial 34 finished with value: 0.3416666666666666 and parameters: {'n_estimators': 74, 'max_depth': 2, 'learning_rate': 0.27145703742514377, 'subsample': 0.3666118920374322, 'colsample_bytree': 0.9834899793542612, 'gamma': 1.79223294109423, 'reg_alpha': 0.7606318935245193, 'reg_lambda': 3.8799416677956975}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:18:42,487] Trial 35 finished with value: 0.2916666666666667 and parameters: {'n_estimators': 430, 'max_depth': 5, 'learning_rate': 0.3693027118631029, 'subsample': 0.4566550196208842, 'colsample_bytree': 0.4371311132670146, 'gamma': 0.7259814312196247, 'reg_alpha': 1.4573749059888004, 'reg_lambda': 5.369571205703031}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:19:20,320] Trial 36 finished with value: 0.0 and parameters: {'n_estimators': 188, 'max_depth': 3, 'learning_rate': 0.0012502332942608554, 'subsample': 0.6629810531404416, 'colsample_bytree': 0.2863361445836383, 'gamma': 1.9842006900112275, 'reg_alpha': 0.4550381191994955, 'reg_lambda': 6.163380365599121}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:19:51,822] Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.007437199432956691, 'subsample': 0.5621438735398735, 'colsample_bytree': 0.15987657943711228, 'gamma': 3.1202411873314313, 'reg_alpha': 1.0025166243116983, 'reg_lambda': 2.8379236323561736}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:20:40,291] Trial 38 finished with value: 0.0 and parameters: {'n_estimators': 305, 'max_depth': 2, 'learning_rate': 0.08218979251567797, 'subsample': 0.3535040911787017, 'colsample_bytree': 0.8511615225078257, 'gamma': 6.653591761077567, 'reg_alpha': 3.6812207523135907, 'reg_lambda': 4.716899609273973}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:21:24,231] Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 221, 'max_depth': 5, 'learning_rate': 5.9196911237279196e-05, 'subsample': 0.4958593215875259, 'colsample_bytree': 0.3591409657112361, 'gamma': 4.659033552356053, 'reg_alpha': 9.9522280187943, 'reg_lambda': 3.879913259407009}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:21:54,496] Trial 40 finished with value: 0.0 and parameters: {'n_estimators': 114, 'max_depth': 2, 'learning_rate': 0.0008154155049038646, 'subsample': 0.4200261661923701, 'colsample_bytree': 0.7582959905883021, 'gamma': 0.6115804609791903, 'reg_alpha': 1.7080381192258354, 'reg_lambda': 5.937779743583304}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:22:29,848] Trial 41 finished with value: 0.48148148148148145 and parameters: {'n_estimators': 147, 'max_depth': 3, 'learning_rate': 0.1734767749922849, 'subsample': 0.5581235200932901, 'colsample_bytree': 0.9332922922044049, 'gamma': 0.9295243031663081, 'reg_alpha': 0.008223590730373674, 'reg_lambda': 5.459297277499649}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:23:28,006] Trial 42 finished with value: 0.3148148148148148 and parameters: {'n_estimators': 384, 'max_depth': 3, 'learning_rate': 0.02790776015658881, 'subsample': 0.5322389538888413, 'colsample_bytree': 0.9373088780346015, 'gamma': 1.2339142862805994, 'reg_alpha': 0.4970715387494162, 'reg_lambda': 6.365210261436371}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:23:49,025] Trial 43 finished with value: 0.34422657952069713 and parameters: {'n_estimators': 10, 'max_depth': 4, 'learning_rate': 0.39963973143976467, 'subsample': 0.6379009777136025, 'colsample_bytree': 0.9887275639144518, 'gamma': 1.4113545904637714, 'reg_alpha': 0.025604115883157932, 'reg_lambda': 7.118293542211971}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:24:38,031] Trial 44 finished with value: 0.4083333333333334 and parameters: {'n_estimators': 320, 'max_depth': 3, 'learning_rate': 0.12853363726392644, 'subsample': 0.716019564960764, 'colsample_bytree': 0.8856258990916828, 'gamma': 2.2906701350443717, 'reg_alpha': 0.5655356093701687, 'reg_lambda': 5.710444722524236}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:25:46,372] Trial 45 finished with value: 0.0 and parameters: {'n_estimators': 475, 'max_depth': 2, 'learning_rate': 0.012651923087680152, 'subsample': 0.4731042998949336, 'colsample_bytree': 0.8010142313477828, 'gamma': 0.40519274138270156, 'reg_alpha': 4.46715589403187, 'reg_lambda': 4.347717061040306}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:26:25,539] Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.06570212522059059, 'subsample': 0.5598954038540082, 'colsample_bytree': 0.5004936874123074, 'gamma': 8.183575717484832, 'reg_alpha': 1.0331640699746512, 'reg_lambda': 4.732527511670135}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:27:11,832] Trial 47 finished with value: 0.396078431372549 and parameters: {'n_estimators': 278, 'max_depth': 4, 'learning_rate': 0.47757278320181656, 'subsample': 0.5902887279190582, 'colsample_bytree': 0.390927961670238, 'gamma': 0.9266042012512816, 'reg_alpha': 0.5466927977420244, 'reg_lambda': 8.410027199164611}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:27:35,760] Trial 48 finished with value: 0.0 and parameters: {'n_estimators': 44, 'max_depth': 6, 'learning_rate': 0.020370420414707206, 'subsample': 0.3233052169891315, 'colsample_bytree': 0.6081204818766831, 'gamma': 0.41521079338022415, 'reg_alpha': 5.665235433381079, 'reg_lambda': 3.180969990404789}. Best is trial 23 with value: 0.5444444444444444.\n",
            "[I 2025-07-11 16:28:04,910] Trial 49 finished with value: 0.32941176470588235 and parameters: {'n_estimators': 98, 'max_depth': 1, 'learning_rate': 0.9603495613878401, 'subsample': 0.4890908039538544, 'colsample_bytree': 0.682348942892874, 'gamma': 2.6537781820284607, 'reg_alpha': 1.7725884592112973, 'reg_lambda': 2.3639944840883107}. Best is trial 23 with value: 0.5444444444444444.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned XGBClassifier (MultiOutput):\n",
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.8055555555555555\n",
            "Recall: 0.4259259259259259\n",
            "F1 Score: 0.5444444444444444\n"
          ]
        }
      ],
      "source": [
        "# 1. Optuna objective with AdaBoost inside MultiOutputClassifier\n",
        "def objective(trial):\n",
        "    model = MultiOutputClassifier(XGBClassifier(\n",
        "        n_estimators=trial.suggest_int(\"n_estimators\", 10, 1000),\n",
        "        max_depth=trial.suggest_int(\"max_depth\", 1, 10),\n",
        "        learning_rate=trial.suggest_float(\"learning_rate\", 0.0000001, 1.0, log=True),\n",
        "        subsample=trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
        "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
        "        gamma=trial.suggest_float(\"gamma\", 0, 10),\n",
        "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
        "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "    ))\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "# 2. Optimize AdaBoost\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 3. Build base classifiers\n",
        "model = MultiOutputClassifier(XGBClassifier(**study.best_params, random_state=42))\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Tuned XGBClassifier (MultiOutput):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\", zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e44c06f1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/Users/napatcholthaipanich/Dev/master/dissertation/workspace/ml/models/best_xgboost_model_on_crpwarner_opcode_n-gram.pkl']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(model, os.path.join(MODEL_PATH, f'best_xgboost_model_on_crpwarner_opcode_n-gram.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0357c56",
      "metadata": {},
      "source": [
        "### K-Fold (K=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "dc7afbd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_FOLDS = 3\n",
        "results = []\n",
        "best_model = MultiOutputClassifier(XGBClassifier(**study.best_params, random_state=42))\n",
        "best_f1 = 0\n",
        "best_fold = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a8f51b21",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========== Fold-0 ===========\n",
            "Accuracy: 0.5217391304347826\n",
            "Precision: 0.4484848484848485\n",
            "Recall: 0.3904761904761904\n",
            "F1 Score: 0.41269841269841273\n",
            "=========== Fold-1 ===========\n",
            "Accuracy: 0.5652173913043478\n",
            "Precision: 0.375\n",
            "Recall: 0.5\n",
            "F1 Score: 0.4230769230769231\n",
            "=========== Fold-2 ===========\n",
            "Accuracy: 0.6521739130434783\n",
            "Precision: 0.5185185185185185\n",
            "Recall: 0.4047619047619048\n",
            "F1 Score: 0.4305555555555555\n",
            "\n",
            "===== Overall Summary =====\n",
            "Average Accuracy: 0.5797\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/Users/napatcholthaipanich/Dev/master/dissertation/workspace/ml/models/best_xgboost_model_on_crpwarner_opcode_n_gram_from_fold2.pkl']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for fold in range(NUM_FOLDS):\n",
        "    print(f\"=========== Fold-{fold} ===========\")\n",
        "    train_path = os.path.join(DATA_PATH, f'train_fold_{fold}-opcode-n-gram.csv')\n",
        "    val_path = os.path.join(DATA_PATH, f'val_fold_{fold}-opcode-n-gram.csv')\n",
        "\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    val_df   = pd.read_csv(val_path)\n",
        "\n",
        "    X_train = train_df[feature_list]\n",
        "    y_train = train_df[labels]\n",
        "\n",
        "    X_val = val_df[feature_list]\n",
        "    y_val = val_df[labels]\n",
        "\n",
        "    # Train model\n",
        "    model = MultiOutputClassifier(XGBClassifier(**study.best_params, random_state=42))\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_val)\n",
        "    report = classification_report(y_val, y_pred, target_names=labels, output_dict=True)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "    results.append({'fold': fold, 'accuracy': acc, 'report': report})\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(\"Precision:\", precision_score(y_val, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"Recall:\", recall_score(y_val, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "    if best_f1 < f1:\n",
        "        best_model = model\n",
        "        best_fold = fold\n",
        "## Step 6: Average Performance Summary\n",
        "print(\"\\n===== Overall Summary =====\")\n",
        "avg_acc = sum([r['accuracy'] for r in results]) / NUM_FOLDS\n",
        "print(f\"Average Accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "joblib.dump(best_model, os.path.join(MODEL_PATH, f'best_xgboost_model_on_crpwarner_opcode_n_gram_from_fold{best_fold}.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b63c8af",
      "metadata": {},
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea61f523",
      "metadata": {},
      "source": [
        "### Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8d694457",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-11 16:32:00.146436: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opcode_dim = len(feature_list)\n",
        "\n",
        "def MLClassifier():\n",
        "    return Sequential([\n",
        "        Dense(512, input_dim=opcode_dim, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Dense(256, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(128, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(64),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(len(labels), activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model = MLClassifier()\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',  # important for multi-label!\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy', 'AUC']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c53ba4",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7a77cd6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - AUC: 0.4797 - accuracy: 0.2391 - loss: 2.2225"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - AUC: 0.4797 - accuracy: 0.2391 - loss: 2.2225 - val_AUC: 0.3935 - val_accuracy: 0.1429 - val_loss: 4.3075 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - AUC: 0.6368 - accuracy: 0.2826 - loss: 2.0788 - val_AUC: 0.3970 - val_accuracy: 0.1429 - val_loss: 4.3338 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.6703 - accuracy: 0.3696 - loss: 1.9806"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - AUC: 0.6703 - accuracy: 0.3696 - loss: 1.9806 - val_AUC: 0.3958 - val_accuracy: 0.1429 - val_loss: 3.8304 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - AUC: 0.7222 - accuracy: 0.3696 - loss: 1.8692 - val_AUC: 0.3889 - val_accuracy: 0.1429 - val_loss: 3.8490 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.7606 - accuracy: 0.5000 - loss: 1.7865"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - AUC: 0.7606 - accuracy: 0.5000 - loss: 1.7865 - val_AUC: 0.4051 - val_accuracy: 0.1429 - val_loss: 3.5774 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.7450 - accuracy: 0.3696 - loss: 1.7029"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - AUC: 0.7450 - accuracy: 0.3696 - loss: 1.7029 - val_AUC: 0.4051 - val_accuracy: 0.1429 - val_loss: 3.3522 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.8068 - accuracy: 0.4130 - loss: 1.6179"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - AUC: 0.8068 - accuracy: 0.4130 - loss: 1.6179 - val_AUC: 0.4039 - val_accuracy: 0.1429 - val_loss: 3.1444 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.8711 - accuracy: 0.5000 - loss: 1.5155"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - AUC: 0.8711 - accuracy: 0.5000 - loss: 1.5155 - val_AUC: 0.3935 - val_accuracy: 0.1429 - val_loss: 3.0610 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - AUC: 0.9013 - accuracy: 0.4783 - loss: 1.4307"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - AUC: 0.9013 - accuracy: 0.4783 - loss: 1.4307 - val_AUC: 0.3831 - val_accuracy: 0.1429 - val_loss: 2.9878 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - AUC: 0.9016 - accuracy: 0.5000 - loss: 1.3941"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - AUC: 0.9016 - accuracy: 0.5000 - loss: 1.3941 - val_AUC: 0.3796 - val_accuracy: 0.1429 - val_loss: 2.8483 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - AUC: 0.8837 - accuracy: 0.5435 - loss: 1.3651"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - AUC: 0.8837 - accuracy: 0.5435 - loss: 1.3651 - val_AUC: 0.4028 - val_accuracy: 0.1429 - val_loss: 2.6511 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.9139 - accuracy: 0.5217 - loss: 1.3080"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - AUC: 0.9139 - accuracy: 0.5217 - loss: 1.3080 - val_AUC: 0.4387 - val_accuracy: 0.1429 - val_loss: 2.4643 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.9236 - accuracy: 0.5217 - loss: 1.2603"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - AUC: 0.9236 - accuracy: 0.5217 - loss: 1.2603 - val_AUC: 0.4444 - val_accuracy: 0.0714 - val_loss: 2.3113 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - AUC: 0.8875 - accuracy: 0.5000 - loss: 1.2514"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - AUC: 0.8875 - accuracy: 0.5000 - loss: 1.2514 - val_AUC: 0.4687 - val_accuracy: 0.0714 - val_loss: 2.1663 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - AUC: 0.9310 - accuracy: 0.5217 - loss: 1.1824"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - AUC: 0.9310 - accuracy: 0.5217 - loss: 1.1824 - val_AUC: 0.4861 - val_accuracy: 0.0714 - val_loss: 2.0420 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - AUC: 0.9351 - accuracy: 0.4348 - loss: 1.1400"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - AUC: 0.9351 - accuracy: 0.4348 - loss: 1.1400 - val_AUC: 0.4931 - val_accuracy: 0.0714 - val_loss: 1.9576 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - AUC: 0.9628 - accuracy: 0.5870 - loss: 1.1003"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - AUC: 0.9628 - accuracy: 0.5870 - loss: 1.1003 - val_AUC: 0.4942 - val_accuracy: 0.0714 - val_loss: 1.8979 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - AUC: 0.9279 - accuracy: 0.5000 - loss: 1.1045"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - AUC: 0.9279 - accuracy: 0.5000 - loss: 1.1045 - val_AUC: 0.4931 - val_accuracy: 0.0714 - val_loss: 1.8528 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - AUC: 0.9472 - accuracy: 0.6087 - loss: 1.0776"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - AUC: 0.9472 - accuracy: 0.6087 - loss: 1.0776 - val_AUC: 0.5093 - val_accuracy: 0.1429 - val_loss: 1.8134 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.9627 - accuracy: 0.6304 - loss: 1.0263"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - AUC: 0.9627 - accuracy: 0.6304 - loss: 1.0263 - val_AUC: 0.5324 - val_accuracy: 0.1429 - val_loss: 1.7640 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.9617 - accuracy: 0.5652 - loss: 1.0119"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - AUC: 0.9617 - accuracy: 0.5652 - loss: 1.0119 - val_AUC: 0.5405 - val_accuracy: 0.0714 - val_loss: 1.7491 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - AUC: 0.9498 - accuracy: 0.6522 - loss: 1.0331"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - AUC: 0.9498 - accuracy: 0.6522 - loss: 1.0331 - val_AUC: 0.5463 - val_accuracy: 0.0714 - val_loss: 1.7473 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.9635 - accuracy: 0.6739 - loss: 0.9808"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - AUC: 0.9635 - accuracy: 0.6739 - loss: 0.9808 - val_AUC: 0.5451 - val_accuracy: 0.1429 - val_loss: 1.7444 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - AUC: 0.9793 - accuracy: 0.5870 - loss: 0.9575 - val_AUC: 0.5405 - val_accuracy: 0.1429 - val_loss: 1.7451 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - AUC: 0.9648 - accuracy: 0.6087 - loss: 0.9663 - val_AUC: 0.5370 - val_accuracy: 0.2143 - val_loss: 1.7475 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.9676 - accuracy: 0.6957 - loss: 0.9223\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - AUC: 0.9676 - accuracy: 0.6957 - loss: 0.9223 - val_AUC: 0.5336 - val_accuracy: 0.2143 - val_loss: 1.7561 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - AUC: 0.9614 - accuracy: 0.5870 - loss: 0.9350 - val_AUC: 0.5370 - val_accuracy: 0.2143 - val_loss: 1.7475 - learning_rate: 5.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.9736 - accuracy: 0.6522 - loss: 0.8980"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - AUC: 0.9736 - accuracy: 0.6522 - loss: 0.8980 - val_AUC: 0.5301 - val_accuracy: 0.2143 - val_loss: 1.7357 - learning_rate: 5.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - AUC: 0.9696 - accuracy: 0.5652 - loss: 0.9088"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - AUC: 0.9696 - accuracy: 0.5652 - loss: 0.9088 - val_AUC: 0.5301 - val_accuracy: 0.2143 - val_loss: 1.7189 - learning_rate: 5.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - AUC: 0.9841 - accuracy: 0.6304 - loss: 0.8864"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - AUC: 0.9841 - accuracy: 0.6304 - loss: 0.8864 - val_AUC: 0.5359 - val_accuracy: 0.2143 - val_loss: 1.7020 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "model_file = os.path.join(MODEL_PATH, \"cnn_best_model_on_crpwarner_opcode_n_gram.h5\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    ModelCheckpoint(model_file, save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b3a35451",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "mode = load_model(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "839f038e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a53d1779",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 0s - 55ms/step - AUC: 0.5359 - accuracy: 0.2143 - loss: 1.7020\n",
            "Restored model, accuracy: 21.43%\n"
          ]
        }
      ],
      "source": [
        "loss, acc, auc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "17fdbc0c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "CNN:\n",
            "Accuracy: 0.14285714285714285\n",
            "Precision: 0.3055555555555555\n",
            "Recall: 0.48148148148148145\n",
            "F1 Score: 0.3111111111111111\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mint       0.00      0.00      0.00         6\n",
            "        leak       0.25      1.00      0.40         3\n",
            "       limit       0.67      0.44      0.53         9\n",
            "\n",
            "   micro avg       0.37      0.39      0.38        18\n",
            "   macro avg       0.31      0.48      0.31        18\n",
            "weighted avg       0.38      0.39      0.33        18\n",
            " samples avg       0.29      0.24      0.25        18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Apply threshold to get binary predictions\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"CNN:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\", zero_division=0))\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f5b125",
      "metadata": {},
      "source": [
        "## CNN With Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "93420cf2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 148.7385\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 148.2956\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 147.9968\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 147.8628\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 147.8289\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 147.8234\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 147.8228\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 147.8216\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 147.8207\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 147.8197\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 147.8183\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 147.8171\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8158\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8149\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8147\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 147.8140\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 147.8134\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 147.8126\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8119\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 147.8117\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 147.8108\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 147.8105\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 147.8100\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 147.8096\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 147.8092\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8089\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 147.8086\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 147.8083\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 147.8081\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 147.8078\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x14071f6e0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "X_unlabeled = np.concatenate([X_train, X_test], axis=0)\n",
        "# Input\n",
        "input_layer = Input(shape=(opcode_dim,))\n",
        "\n",
        "# Encoder\n",
        "encoded = Dense(256, activation='relu')(input_layer)\n",
        "encoded = Dense(128, activation='relu')(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = Dense(256, activation='relu')(encoded)\n",
        "decoded = Dense(opcode_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
        "encoder = Model(inputs=input_layer, outputs=encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(X_unlabeled, X_unlabeled, epochs=30, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3361ddf9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        }
      ],
      "source": [
        "X_encoded = encoder.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fd4c327c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c7226d09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1667 - loss: 1.1818"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1667 - loss: 1.1818 - val_accuracy: 0.1000 - val_loss: 5.1538 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3333 - loss: 1.0334"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.3333 - loss: 1.0334 - val_accuracy: 0.1000 - val_loss: 4.4045 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3611 - loss: 0.9740"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.3611 - loss: 0.9740 - val_accuracy: 0.1000 - val_loss: 4.0733 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5278 - loss: 0.8941"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5278 - loss: 0.8941 - val_accuracy: 0.1000 - val_loss: 3.6430 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5556 - loss: 0.8455"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5556 - loss: 0.8455 - val_accuracy: 0.1000 - val_loss: 3.2775 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.8658"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5000 - loss: 0.8658 - val_accuracy: 0.1000 - val_loss: 3.0838 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4444 - loss: 0.8709"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4444 - loss: 0.8709 - val_accuracy: 0.1000 - val_loss: 2.8670 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.8048"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5000 - loss: 0.8048 - val_accuracy: 0.1000 - val_loss: 2.7871 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5556 - loss: 0.8160"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5556 - loss: 0.8160 - val_accuracy: 0.1000 - val_loss: 2.7528 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4722 - loss: 0.7721"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4722 - loss: 0.7721 - val_accuracy: 0.1000 - val_loss: 2.7040 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5278 - loss: 0.8278"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5278 - loss: 0.8278 - val_accuracy: 0.1000 - val_loss: 2.6127 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4444 - loss: 0.7475"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4444 - loss: 0.7475 - val_accuracy: 0.1000 - val_loss: 2.4597 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5556 - loss: 0.7560"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5556 - loss: 0.7560 - val_accuracy: 0.1000 - val_loss: 2.3080 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5278 - loss: 0.7466"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5278 - loss: 0.7466 - val_accuracy: 0.1000 - val_loss: 2.2011 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5278 - loss: 0.7168"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5278 - loss: 0.7168 - val_accuracy: 0.1000 - val_loss: 2.1146 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4722 - loss: 0.7289"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4722 - loss: 0.7289 - val_accuracy: 0.1000 - val_loss: 2.0739 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6389 - loss: 0.6966"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6389 - loss: 0.6966 - val_accuracy: 0.1000 - val_loss: 1.9739 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7294"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5000 - loss: 0.7294 - val_accuracy: 0.1000 - val_loss: 1.9212 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7162"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5000 - loss: 0.7162 - val_accuracy: 0.1000 - val_loss: 1.8796 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5278 - loss: 0.6878"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5278 - loss: 0.6878 - val_accuracy: 0.1000 - val_loss: 1.8470 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4444 - loss: 0.6891"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4444 - loss: 0.6891 - val_accuracy: 0.1000 - val_loss: 1.7998 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.7051"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5000 - loss: 0.7051 - val_accuracy: 0.1000 - val_loss: 1.7697 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5833 - loss: 0.6999"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5833 - loss: 0.6999 - val_accuracy: 0.1000 - val_loss: 1.7153 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6910"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5000 - loss: 0.6910 - val_accuracy: 0.1000 - val_loss: 1.6635 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5556 - loss: 0.6692"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.5556 - loss: 0.6692 - val_accuracy: 0.1000 - val_loss: 1.6243 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5278 - loss: 0.6907"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5278 - loss: 0.6907 - val_accuracy: 0.1000 - val_loss: 1.5659 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6803"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5000 - loss: 0.6803 - val_accuracy: 0.1000 - val_loss: 1.5073 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5833 - loss: 0.6389"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5833 - loss: 0.6389 - val_accuracy: 0.1000 - val_loss: 1.4759 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5278 - loss: 0.6954"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5278 - loss: 0.6954 - val_accuracy: 0.1000 - val_loss: 1.4419 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5278 - loss: 0.6378"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5278 - loss: 0.6378 - val_accuracy: 0.1000 - val_loss: 1.4228 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "def EncodedMLClassifier():\n",
        "    return Sequential([\n",
        "        Dense(256, input_dim=128, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(128, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(64),\n",
        "        LeakyReLU(alpha=0.01),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(len(labels), activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "classifier = EncodedMLClassifier()\n",
        "\n",
        "classifier.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_file = os.path.join(MODEL_PATH, \"encoded_cnn_best_model_on_crpwarner_opcode_n_gram.h5\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    ModelCheckpoint(model_file, save_best_only=True)\n",
        "]\n",
        "\n",
        "history = classifier.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3d016c0b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b1614f62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mint       0.20      1.00      0.33         2\n",
            "        leak       0.20      1.00      0.33         2\n",
            "       limit       0.11      1.00      0.20         1\n",
            "\n",
            "   micro avg       0.17      1.00      0.29         5\n",
            "   macro avg       0.17      1.00      0.29         5\n",
            "weighted avg       0.18      1.00      0.31         5\n",
            " samples avg       0.17      0.40      0.23         5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob = classifier.predict(X_val)\n",
        "y_pred = (y_pred_prob >= 0.05).astype(int)\n",
        "\n",
        "print(classification_report(y_val, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da95f9d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml-algo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
