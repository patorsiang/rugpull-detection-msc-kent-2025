{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d8ab9e",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency) Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0711d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69eb25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.sparse import save_npz\n",
    "import joblib\n",
    "from evmdasm import EvmBytecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07b31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd().parents[1]\n",
    "DATA_PATH = os.path.join(PATH, 'data')\n",
    "NAME = 'crpwarner'\n",
    "IN_PATH = os.path.join(DATA_PATH, f'external/{NAME}/groundtruth')\n",
    "HEX_PATH = os.path.join(IN_PATH, 'hex')\n",
    "SOL_PATH = os.path.join(IN_PATH, 'sol')\n",
    "OUT_PATH = os.path.join(DATA_PATH, f'interim/{NAME}')\n",
    "PRO_PATH = os.path.join(DATA_PATH, 'processed/tf_idf')\n",
    "df = pd.read_csv(os.path.join(OUT_PATH, 'dataset-modified.csv')).set_index('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164498db",
   "metadata": {},
   "source": [
    "## Load Bytecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b26662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bytecode(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539961c",
   "metadata": {},
   "source": [
    "## Disassemble to Opcode List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d565ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opcodes(bytecode):\n",
    "    evm_code = EvmBytecode(bytecode)\n",
    "    opcodes = []\n",
    "    for instr in evm_code.disassemble():\n",
    "        opcode = instr.name\n",
    "        # Extract the first alphanumeric-only word (no digits, no special characters)\n",
    "        match = re.match(r'^[a-zA-Z]+', opcode)\n",
    "\n",
    "        if match:\n",
    "            opcode_group = match.group()\n",
    "            opcodes.append(opcode_group)\n",
    "        else:\n",
    "            opcodes.append(opcode)\n",
    "    return opcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69b6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opcode_seq_from_file(hex_file):\n",
    "    bytecode = load_bytecode(hex_file)\n",
    "    opcodes = get_opcodes(bytecode)\n",
    "    return \" \".join(opcodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c212a",
   "metadata": {},
   "source": [
    "## Compute TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef25a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_all_files = list(Path(HEX_PATH).glob('*.hex'))\n",
    "sol_all_files = list(Path(SOL_PATH).glob('*.sol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c601d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_sol = []\n",
    "addresses_sol = []\n",
    "\n",
    "for file in sol_all_files:\n",
    "    address = file.stem.lower()\n",
    "    if address in df.index:\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "            documents_sol.append(content)\n",
    "            addresses_sol.append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74b456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid instruction: PUSH30\n",
      "invalid instruction: PUSH16\n",
      "invalid instruction: PUSH30\n",
      "invalid instruction: PUSH24\n",
      "invalid instruction: PUSH30\n",
      "invalid instruction: PUSH16\n",
      "invalid instruction: PUSH15\n",
      "invalid instruction: PUSH13\n",
      "invalid instruction: PUSH25\n",
      "invalid instruction: PUSH16\n",
      "invalid instruction: PUSH13\n",
      "invalid instruction: PUSH25\n",
      "invalid instruction: PUSH21\n",
      "invalid instruction: PUSH16\n",
      "invalid instruction: PUSH15\n",
      "invalid instruction: PUSH19\n",
      "invalid instruction: PUSH29\n",
      "invalid instruction: PUSH26\n",
      "invalid instruction: PUSH20\n",
      "invalid instruction: PUSH17\n",
      "invalid instruction: PUSH16\n",
      "invalid instruction: PUSH20\n",
      "invalid instruction: PUSH13\n",
      "invalid instruction: PUSH13\n",
      "invalid instruction: PUSH13\n",
      "invalid instruction: PUSH24\n",
      "invalid instruction: PUSH27\n",
      "invalid instruction: PUSH32\n",
      "invalid instruction: PUSH29\n"
     ]
    }
   ],
   "source": [
    "documents_hex = []\n",
    "addresses_hex = []\n",
    "\n",
    "for file in hex_all_files:\n",
    "    address = file.stem.lower()\n",
    "    if address in df.index:\n",
    "        opcode_seq = get_opcode_seq_from_file(file)\n",
    "        documents_hex.append(opcode_seq)\n",
    "        addresses_hex.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12e51b",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b44bbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_sol = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\b\\w+\\b',\n",
    "    max_features=10000  # tune as needed\n",
    ")\n",
    "X_sol = vectorizer_sol.fit_transform(documents_sol)\n",
    "y_sol = df.loc[addresses_sol][['mint', 'leak', 'limit']].fillna(0).astype(int).values\n",
    "\n",
    "y_sol[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98d133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_hex = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\b\\w+\\b',\n",
    "    max_features=10000  # tune as needed\n",
    ")\n",
    "X_hex = vectorizer_hex.fit_transform(documents_hex)\n",
    "y_hex = df.loc[addresses_hex][['mint', 'leak', 'limit']].fillna(0).astype(int).values\n",
    "\n",
    "y_hex[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01bf78",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba19b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(os.path.join(PRO_PATH, \"tfidf_vector_sol.npz\"), X_sol)\n",
    "np.save(os.path.join(PRO_PATH, \"labels_sol.npy\"), y_sol)\n",
    "\n",
    "with open(os.path.join(PRO_PATH, \"feature_sol.json\"), \"w\") as f:\n",
    "    json.dump(vectorizer_sol.get_feature_names_out().tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27156dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(os.path.join(PRO_PATH, \"tfidf_vector_hex.npz\"), X_sol)\n",
    "np.save(os.path.join(PRO_PATH, \"labels_hex.npy\"), y_sol)\n",
    "\n",
    "with open(os.path.join(PRO_PATH, \"feature_hex.json\"), \"w\") as f:\n",
    "    json.dump(vectorizer_hex.get_feature_names_out().tolist(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
